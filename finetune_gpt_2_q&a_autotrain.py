# -*- coding: utf-8 -*-
"""FineTune-GPT-2-Q&A-AutoTrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19jE6BJYcSyXUAkHMMUx87GDLwKmf8m5Y
"""

!pip install autotrain-advanced
!pip install huggingface_hub

!autotrain setup --update-torch

from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModelForCausalLM

"""https://discuss.huggingface.co/t/difference-between-causallm-and-lmheadmodel/17135"""

from huggingface_hub import notebook_login
notebook_login()

!autotrain --help

!autotrain llm --help

!autotrain llm \
  --train \
  --project-name "gpt2-autotrain-llm-finetuned-vff" \
  --model gpt2 \
  --data-path timdettmers/openassistant-guanaco \
  --lr 2e-4 \
  --batch-size 1 \
  --epochs 2 \
  --trainer sft \
  --model_max_length 1024 \
  --push-to-hub  \
  --repo-id "kr-manish/gpt2-autotrain-finetuned-vff" \
  --token "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"

from transformers import GPT2Tokenizer, GPT2LMHeadModel

# Load the fine-tuned model and tokenizer from the Hugging Face Model Hub
model_name = "kr-manish/gpt2-autotrain-finetuned-vff"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# Input text
input_text = "explain the difference between GAN and generative ai?"

# Tokenize input text
input_ids = tokenizer.encode(input_text, return_tensors="pt")

# Generate output text
output = model.generate(input_ids, max_length=100, num_return_sequences=1, do_sample=True)

# Decode and print output
generated_text = tokenizer.decode(output[0], skip_special_tokens=True, src_lang="en")
print(generated_text)

#explain the difference between GAN and generative ai?### Assistant: GAN is a deep learning model that uses neural networks to learn natural language and generate text. Generative ai works by training the model on a set of natural tasks, such as recognizing faces or playing games, to generate a complete model of language. GAN trains on two inputs: a set of tokens for words and input images into a GAN tree, which represents the learning process. GAN then trains on

