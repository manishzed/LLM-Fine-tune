{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nV0KpDfuzWVb",
        "outputId": "bbd531bc-4036-4e70-92b1-eac529e36bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autotrain-advanced\n",
            "  Downloading autotrain_advanced-0.7.45-py3-none-any.whl (248 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/248.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m245.8/248.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.8/248.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (1.3.1)\n",
            "Collecting codecarbon==2.2.3 (from autotrain-advanced)\n",
            "  Downloading codecarbon-2.2.3-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets[vision]~=2.14.0 (from autotrain-advanced)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.3.0 (from autotrain-advanced)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipadic==1.0.0 (from autotrain-advanced)\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jiwer==3.0.2 (from autotrain-advanced)\n",
            "  Downloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n",
            "Collecting joblib==1.3.1 (from autotrain-advanced)\n",
            "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru==0.7.0 (from autotrain-advanced)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.0.3)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (3.8.1)\n",
            "Collecting optuna==3.3.0 (from autotrain-advanced)\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==10.0.0 (from autotrain-advanced)\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==4.23.4 (from autotrain-advanced)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.53 (from autotrain-advanced)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==1.3.0 (from autotrain-advanced)\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (0.1.99)\n",
            "Collecting tqdm==4.65.0 (from autotrain-advanced)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug==2.3.6 (from autotrain-advanced)\n",
            "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.7.6 (from autotrain-advanced)\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.22.2 (from autotrain-advanced)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.31.0)\n",
            "Collecting einops==0.6.1 (from autotrain-advanced)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting invisible-watermark==0.2.0 (from autotrain-advanced)\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.1 (from autotrain-advanced)\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.15.2)\n",
            "Collecting peft==0.10.0 (from autotrain-advanced)\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl==0.8.1 (from autotrain-advanced)\n",
            "  Downloading trl-0.8.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken==0.6.0 (from autotrain-advanced)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.39.3 (from autotrain-advanced)\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.29.1 (from autotrain-advanced)\n",
            "  Downloading accelerate-0.29.1-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers==0.27.2 (from autotrain-advanced)\n",
            "  Downloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.43.0 (from autotrain-advanced)\n",
            "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score==0.1.2 (from autotrain-advanced)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py7zr==0.20.6 (from autotrain-advanced)\n",
            "  Downloading py7zr-0.20.6-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi==0.104.1 (from autotrain-advanced)\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn==0.22.0 (from autotrain-advanced)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart==0.0.6 (from autotrain-advanced)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.41.0 (from autotrain-advanced)\n",
            "  Downloading gradio-3.41.0-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==2.4.2 (from autotrain-advanced)\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hf-transfer (from autotrain-advanced)\n",
            "  Downloading hf_transfer-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok==7.0.3 (from autotrain-advanced)\n",
            "  Downloading pyngrok-7.0.3-py3-none-any.whl (21 kB)\n",
            "Collecting authlib==1.3.0 (from autotrain-advanced)\n",
            "  Downloading Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous==2.1.2 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.1.2)\n",
            "Collecting seqeval==1.2.2 (from autotrain-advanced)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.1->autotrain-advanced) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.1->autotrain-advanced) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.1->autotrain-advanced) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.1->autotrain-advanced) (2.2.1+cu121)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.1->autotrain-advanced) (0.4.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (0.19.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (4.9.0.80)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib==1.3.0->autotrain-advanced) (42.0.5)\n",
            "Collecting arrow (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (9.0.0)\n",
            "Collecting fuzzywuzzy (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.2->autotrain-advanced) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.2->autotrain-advanced) (3.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.2->autotrain-advanced) (2023.12.25)\n",
            "Collecting datasets>=2.0.0 (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.104.1->autotrain-advanced) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi==0.104.1->autotrain-advanced)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.104.1->autotrain-advanced) (4.10.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (4.2.2)\n",
            "Collecting ffmpy (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (1.6.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (4.8.0.76)\n",
            "Collecting rapidfuzz==2.13.7 (from jiwer==3.0.2->autotrain-advanced)\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.3.0->autotrain-advanced) (2.0.29)\n",
            "Collecting texttable (from py7zr==0.20.6->autotrain-advanced)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6 (from py7zr==0.20.6->autotrain-advanced)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr==0.20.6->autotrain-advanced)\n",
            "  Downloading pyzstd-0.15.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (411 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr==0.20.6->autotrain-advanced)\n",
            "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr==0.20.6->autotrain-advanced)\n",
            "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr==0.20.6->autotrain-advanced)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting brotli>=1.0.9 (from py7zr==0.20.6->autotrain-advanced)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr==0.20.6->autotrain-advanced)\n",
            "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.4.2->autotrain-advanced) (0.6.0)\n",
            "Collecting pydantic-core==2.10.1 (from pydantic==2.4.2->autotrain-advanced)\n",
            "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (2024.2.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->autotrain-advanced) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->autotrain-advanced) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->autotrain-advanced) (3.4.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.3->autotrain-advanced) (0.15.2)\n",
            "Collecting tyro>=0.5.11 (from trl==0.8.1->autotrain-advanced)\n",
            "  Downloading tyro-0.8.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8 (from uvicorn==0.22.0->autotrain-advanced)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced) (0.6)\n",
            "Collecting dill (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced) (3.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced) (2024.1)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (0.7.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.12.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi==0.104.1->autotrain-advanced) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi==0.104.1->autotrain-advanced) (1.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->autotrain-advanced) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (3.1.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced) (2024.2.12)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna==3.3.0->autotrain-advanced) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced) (1.12)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.1->autotrain-advanced) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.1->autotrain-advanced)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.1->autotrain-advanced) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.1->autotrain-advanced) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.8.1->autotrain-advanced)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow->codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib==1.3.0->autotrain-advanced) (1.16.0)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.27.2->autotrain-advanced) (3.18.1)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib==1.3.0->autotrain-advanced) (2.22)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.18.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->autotrain-advanced) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.1->autotrain-advanced) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.1->autotrain-advanced) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.29.1->autotrain-advanced) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.1->autotrain-advanced) (0.1.2)\n",
            "Building wheels for collected packages: ipadic, rouge-score, sacremoses, seqeval, ffmpy\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=2eb60181fbfdc997c0d9fca706587ca881855b2ab35e2e7e9a829160145020d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=cdbff2bb3dee1067ecedff7812c282f1b487e9d1fb5fcd9eba4e63932729cd7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895240 sha256=3ef6cbee7f0daf3e41cc9e2b3366252387b2fcbff625e9b7aa2fdc1a4664173a\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=1d376c139b742aebe6b24892def6600b6fe94b3726d1d4439b1dc942e871b6b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=bb200205dad7231b185ba8f7921f7ca3dc80024633b2ad24107ea1e62b536ba7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ipadic rouge-score sacremoses seqeval ffmpy\n",
            "Installing collected packages: texttable, pydub, ipadic, fuzzywuzzy, ffmpy, brotli, xxhash, werkzeug, websockets, types-python-dateutil, tqdm, shtab, semantic-version, rapidfuzz, pyzstd, python-multipart, pyppmd, pynvml, pyngrok, pydantic-core, pycryptodomex, pybcj, protobuf, Pillow, packaging, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multivolumefile, Mako, loguru, joblib, inflate64, hf-transfer, h11, einops, dill, colorlog, cmaes, aiofiles, xgboost, uvicorn, tiktoken, starlette, scikit-learn, sacremoses, responses, pydantic, py7zr, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jiwer, huggingface-hub, httpcore, arrow, alembic, tyro, seqeval, rouge-score, optuna, nvidia-cusolver-cu12, httpx, fastapi, diffusers, codecarbon, authlib, transformers, gradio-client, datasets, invisible-watermark, gradio, evaluate, bitsandbytes, accelerate, trl, peft, autotrain-advanced\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.2\n",
            "    Uninstalling Werkzeug-3.0.2:\n",
            "      Successfully uninstalled Werkzeug-3.0.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.2\n",
            "    Uninstalling tqdm-4.66.2:\n",
            "      Successfully uninstalled tqdm-4.66.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.16.3\n",
            "    Uninstalling pydantic_core-2.16.3:\n",
            "      Successfully uninstalled pydantic_core-2.16.3\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.4\n",
            "    Uninstalling pydantic-2.6.4:\n",
            "      Successfully uninstalled pydantic-2.6.4\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.2 Pillow-10.0.0 accelerate-0.29.1 aiofiles-23.2.1 alembic-1.13.1 arrow-1.3.0 authlib-1.3.0 autotrain-advanced-0.7.45 bitsandbytes-0.43.0 brotli-1.1.0 cmaes-0.10.0 codecarbon-2.2.3 colorlog-6.8.2 datasets-2.14.7 diffusers-0.27.2 dill-0.3.7 einops-0.6.1 evaluate-0.3.0 fastapi-0.104.1 ffmpy-0.3.2 fuzzywuzzy-0.18.0 gradio-3.41.0 gradio-client-0.5.0 h11-0.14.0 hf-transfer-0.1.6 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.22.2 inflate64-1.0.0 invisible-watermark-0.2.0 ipadic-1.0.0 jiwer-3.0.2 joblib-1.3.1 loguru-0.7.0 multiprocess-0.70.15 multivolumefile-0.2.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 optuna-3.3.0 orjson-3.10.0 packaging-23.1 peft-0.10.0 protobuf-4.23.4 py7zr-0.20.6 pybcj-1.0.2 pycryptodomex-3.20.0 pydantic-2.4.2 pydantic-core-2.10.1 pydub-0.25.1 pyngrok-7.0.3 pynvml-11.5.0 pyppmd-1.0.0 python-multipart-0.0.6 pyzstd-0.15.10 rapidfuzz-2.13.7 responses-0.18.0 rouge-score-0.1.2 sacremoses-0.0.53 scikit-learn-1.3.0 semantic-version-2.10.0 seqeval-1.2.2 shtab-1.7.1 starlette-0.27.0 texttable-1.7.0 tiktoken-0.6.0 tqdm-4.65.0 transformers-4.39.3 trl-0.8.1 types-python-dateutil-2.9.0.20240316 tyro-0.8.2 uvicorn-0.22.0 websockets-11.0.3 werkzeug-2.3.6 xgboost-1.7.6 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "68122836419345828e4f179a04d8e574"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4891, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4800, in parseImpl\n",
            "    loc, tmptokens = self_expr_parse(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 821, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4891, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4790, in parseImpl\n",
            "    loc, tokens = self_expr_parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 821, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 2857, in parseImpl\n",
            "    raise ParseException(instring, loc, self.errmsg, self)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1732, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1523, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1740, in isEnabledFor\n",
            "    level >= self.getEffectiveLevel()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install autotrain-advanced\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ-n-dz2znmz",
        "outputId": "588cace0-86a6-4a7a-ed50-a96997f02cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 12:47:09\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mInstalling latest xformers\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 12:47:09\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mSuccessfully installed latest xformers\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 12:47:09\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mInstalling latest PyTorch\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 12:47:15\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mSuccessfully installed latest PyTorch\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain setup --update-torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgMzmDE85RZP"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ujr1LGFl8m"
      },
      "source": [
        "https://discuss.huggingface.co/t/difference-between-causallm-and-lmheadmodel/17135"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "70cceeb8f9164c84b5f08961c0f74eae",
            "55fc4d9933e04a06a7c0899f3741cf29",
            "a4b9f38eba0643ca80ee81b6200096fe",
            "c61310e1a19a4a3aa0445951226b8583",
            "79be5252f8fa40bea365d2f1dcc0f66a",
            "0703f2c9a55b41aca8c8bf5563a8782a",
            "29ca8dea1d63478f99f256b572d8b3ae",
            "1ce8cac112ee4ac79ef31e3fe6f9ad55",
            "a0425bdfe66a4456a307093608ffa621",
            "c854be8fdbf7413c854ea0ebc552c09f",
            "7814eb59f914422e974a0f2e051f3a20",
            "08f182e28379494b91dc5ceb58147736",
            "76a0ac00684e4da08f9d621271be3d73",
            "64bb59c6f18c434795981f0a1be06113",
            "cc74a5d835e54d5b90c0214245eb45ca",
            "2cc57280ca6d4524adc17d354991862f",
            "c450ad6f522e4440b1b1ff09a8f93702",
            "97d286db544b458aaa28f755edaf0868",
            "9c1d04d13ce0424a8cd5a6a3a3a5ba26",
            "f3f3e3ca4d6a4e858ecfaf5aa6e61703",
            "8506762658714888b29fdbea67d6a224",
            "1d043460adb840098744f3df8d09d90e",
            "01d819b8f45f4c40bf8bbf8a483b5d2c",
            "05a172bc5c394827845392e69c758ca4",
            "196bb75d83224f7cb7ebe3d019b6b938",
            "443b366c8fe34b98af83dbe99a94b165",
            "c3b3ba27c88746bcbd5999828b6dd38c",
            "7f46fc6e8f5548638cd1ff3b8f73fd5c",
            "28955f7e28e8401b82abb617b0ae312e",
            "7487ef2396884ae2b1b9153eb9e7cb67",
            "4aeaf6457b174988befa7b1155fd6681",
            "5f67c00dc95d40dc81cbe598f35d5966"
          ]
        },
        "id": "9W74FkVvzzbF",
        "outputId": "4146ddd4-62ad-460d-e69b-4d644529e112"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70cceeb8f9164c84b5f08961c0f74eae"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NdKsJdgQ5AK",
        "outputId": "6d6f7a84-6397-4ccb-f77f-9b7637f11702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: autotrain <command> [<args>]\n",
            "\n",
            "positional arguments:\n",
            "  {app,llm,setup,dreambooth,api,text-classification,image-classification,tabular,spacerunner,seq2seq,token-classification}\n",
            "                        commands\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --version, -v         Display AutoTrain version\n",
            "\n",
            "For more information about a command, run: `autotrain <command> --help`\n"
          ]
        }
      ],
      "source": [
        "!autotrain --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sBw7y2JQ6V5",
        "outputId": "081bef2f-4cc8-4b4c-cb9e-c85592acb884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: autotrain <command> [<args>] llm [-h] [--text_column TEXT_COLUMN]\n",
            "                                        [--rejected_text_column REJECTED_TEXT_COLUMN]\n",
            "                                        [--prompt-text-column PROMPT_TEXT_COLUMN]\n",
            "                                        [--model-ref MODEL_REF] [--warmup_ratio WARMUP_RATIO]\n",
            "                                        [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n",
            "                                        [--weight_decay WEIGHT_DECAY]\n",
            "                                        [--max_grad_norm MAX_GRAD_NORM] [--add_eos_token]\n",
            "                                        [--block_size BLOCK_SIZE] [--peft] [--lora_r LORA_R]\n",
            "                                        [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]\n",
            "                                        [--logging_steps LOGGING_STEPS]\n",
            "                                        [--evaluation_strategy EVALUATION_STRATEGY]\n",
            "                                        [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "                                        [--save_strategy SAVE_STRATEGY] [--auto_find_batch_size]\n",
            "                                        [--mixed-precision MIXED_PRECISION]\n",
            "                                        [--quantization QUANTIZATION]\n",
            "                                        [--model_max_length MODEL_MAX_LENGTH] [--trainer TRAINER]\n",
            "                                        [--target_modules TARGET_MODULES] [--merge_adapter]\n",
            "                                        [--use_flash_attention_2] [--dpo-beta DPO_BETA]\n",
            "                                        [--chat_template CHAT_TEMPLATE] [--padding PADDING]\n",
            "                                        [--train] [--deploy] [--inference] [--username USERNAME]\n",
            "                                        [--backend BACKEND] [--token TOKEN] [--repo-id REPO_ID]\n",
            "                                        [--push-to-hub] --model MODEL --project-name PROJECT_NAME\n",
            "                                        [--seed SEED] [--epochs EPOCHS]\n",
            "                                        [--gradient-accumulation GRADIENT_ACCUMULATION]\n",
            "                                        [--disable_gradient_checkpointing] [--lr LR] [--log LOG]\n",
            "                                        [--data-path DATA_PATH] [--train-split TRAIN_SPLIT]\n",
            "                                        [--valid-split VALID_SPLIT] [--batch-size BATCH_SIZE]\n",
            "\n",
            "✨ Run AutoTrain LLM\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n",
            "                        Text column to use\n",
            "  --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n",
            "                        Rejected text column to use\n",
            "  --prompt-text-column PROMPT_TEXT_COLUMN, --prompt-text-column PROMPT_TEXT_COLUMN\n",
            "                        Prompt text column to use\n",
            "  --model-ref MODEL_REF\n",
            "                        Reference model to use for DPO when not using PEFT\n",
            "  --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n",
            "                        Warmup proportion to use\n",
            "  --optimizer OPTIMIZER\n",
            "                        Optimizer to use\n",
            "  --scheduler SCHEDULER\n",
            "                        Scheduler to use\n",
            "  --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n",
            "                        Weight decay to use\n",
            "  --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n",
            "                        Max gradient norm to use\n",
            "  --add_eos_token, --add-eos-token\n",
            "                        Add EOS token to use\n",
            "  --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n",
            "                        Block size to use\n",
            "  --peft, --use-peft    Use PEFT\n",
            "  --lora_r LORA_R, --lora-r LORA_R\n",
            "                        Lora r to use\n",
            "  --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n",
            "                        Lora alpha to use\n",
            "  --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n",
            "                        Lora dropout to use\n",
            "  --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n",
            "                        Logging steps to use\n",
            "  --evaluation_strategy EVALUATION_STRATEGY, --evaluation-strategy EVALUATION_STRATEGY\n",
            "                        Evaluation strategy to use\n",
            "  --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n",
            "                        Save total limit to use\n",
            "  --save_strategy SAVE_STRATEGY, --save-strategy SAVE_STRATEGY\n",
            "                        Save strategy to use\n",
            "  --auto_find_batch_size, --auto-find-batch-size\n",
            "                        Auto find batch size True/False\n",
            "  --mixed-precision MIXED_PRECISION, --mixed-precision MIXED_PRECISION, --mp MIXED_PRECISION\n",
            "                        fp16, bf16, or None\n",
            "  --quantization QUANTIZATION, --quantization QUANTIZATION\n",
            "                        int4, int8, or None\n",
            "  --model_max_length MODEL_MAX_LENGTH, --max-len MODEL_MAX_LENGTH, --max-length MODEL_MAX_LENGTH\n",
            "                        Model max length to use\n",
            "  --trainer TRAINER     Trainer type to use\n",
            "  --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n",
            "                        Target modules to use\n",
            "  --merge_adapter, --merge-adapter\n",
            "                        Use this flag to merge PEFT adapter with the model\n",
            "  --use_flash_attention_2, --use-flash-attention-2, --use-fa2\n",
            "                        Use flash attention 2\n",
            "  --dpo-beta DPO_BETA, --dpo-beta DPO_BETA\n",
            "                        Beta for DPO trainer\n",
            "  --chat_template CHAT_TEMPLATE, --chat-template CHAT_TEMPLATE\n",
            "                        Apply chat template\n",
            "  --padding PADDING, --padding PADDING\n",
            "                        Padding side\n",
            "  --train               Train the model\n",
            "  --deploy              Deploy the model\n",
            "  --inference           Run inference\n",
            "  --username USERNAME   Hugging Face Hub Username\n",
            "  --backend BACKEND     Backend to use: default or spaces. Spaces backend requires push_to_hub and\n",
            "                        repo_id\n",
            "  --token TOKEN         Hub token\n",
            "  --repo-id REPO_ID     Hub repo id\n",
            "  --push-to-hub         Push to hub\n",
            "  --model MODEL         Model to use for training\n",
            "  --project-name PROJECT_NAME\n",
            "                        Output directory or repo id\n",
            "  --seed SEED           Seed\n",
            "  --epochs EPOCHS       Number of training epochs\n",
            "  --gradient-accumulation GRADIENT_ACCUMULATION\n",
            "                        Gradient accumulation steps\n",
            "  --disable_gradient_checkpointing, --disable-gradient-checkpointing, --disable-gc\n",
            "                        Disable gradient checkpointing\n",
            "  --lr LR               Learning rate\n",
            "  --log LOG             Use experiment tracking\n",
            "  --data-path DATA_PATH\n",
            "                        Train dataset to use\n",
            "  --train-split TRAIN_SPLIT\n",
            "                        Test dataset split to use\n",
            "  --valid-split VALID_SPLIT\n",
            "                        Validation dataset split to use\n",
            "  --batch-size BATCH_SIZE, --train-batch-size BATCH_SIZE\n",
            "                        Training batch size to use\n"
          ]
        }
      ],
      "source": [
        "!autotrain llm --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxdmHIg3z9AL",
        "outputId": "9132914f-07a9-47fe-caea-366504c328e4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:16\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mRunning LLM\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-04-08 13:03:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: inference, version, func, backend, train, deploy\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:16\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:16\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'gpt2-autotrain-llm-finetuned-vff/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:16\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m339\u001b[0m - \u001b[1m{'model': 'gpt2', 'project_name': 'gpt2-autotrain-llm-finetuned-vff', 'data_path': 'timdettmers/openassistant-guanaco', 'train_split': 'train', 'valid_split': None, 'add_eos_token': False, 'block_size': -1, 'model_max_length': 1024, 'padding': None, 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'none', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'evaluation_strategy': 'epoch', 'save_total_limit': 1, 'save_strategy': 'epoch', 'auto_find_batch_size': False, 'mixed_precision': None, 'lr': 0.0002, 'epochs': 2, 'batch_size': 1, 'warmup_ratio': 0.1, 'gradient_accumulation': 1, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.0, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': None, 'target_modules': None, 'merge_adapter': False, 'peft': False, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'prompt_text_column': 'prompt', 'text_column': 'text', 'rejected_text_column': 'rejected', 'push_to_hub': True, 'repo_id': 'kr-manish/gpt2-autotrain-finetuned-vff', 'username': None, 'token': '*****'}\u001b[0m\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:30\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mTrain data: Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 9846\n",
            "})\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:30\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:31\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mcreating training arguments...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:31\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1mLogging steps: 25\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:31\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mloading model config...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:31\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m272\u001b[0m - \u001b[1mloading model...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:31\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mmodel dtype: torch.float32\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:32\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m399\u001b[0m - \u001b[1mUsing block size 1024\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:32\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m461\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
            "  0% 25/10838 [00:04<27:20,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 79.8167, 'grad_norm': 359.2948913574219, 'learning_rate': 4.612546125461255e-06, 'epoch': 0.0}\u001b[0m\n",
            "{'loss': 79.8167, 'grad_norm': 359.2948913574219, 'learning_rate': 4.612546125461255e-06, 'epoch': 0.0}\n",
            "  0% 50/10838 [00:08<27:17,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:42\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 37.2108, 'grad_norm': 398.67376708984375, 'learning_rate': 9.22509225092251e-06, 'epoch': 0.01}\u001b[0m\n",
            "{'loss': 37.2108, 'grad_norm': 398.67376708984375, 'learning_rate': 9.22509225092251e-06, 'epoch': 0.01}\n",
            "  1% 75/10838 [00:12<27:11,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 7.9044, 'grad_norm': 16.766769409179688, 'learning_rate': 1.3837638376383766e-05, 'epoch': 0.01}\u001b[0m\n",
            "{'loss': 7.9044, 'grad_norm': 16.766769409179688, 'learning_rate': 1.3837638376383766e-05, 'epoch': 0.01}\n",
            "  1% 100/10838 [00:15<27:07,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 4.1342, 'grad_norm': 10.146249771118164, 'learning_rate': 1.845018450184502e-05, 'epoch': 0.02}\u001b[0m\n",
            "{'loss': 4.1342, 'grad_norm': 10.146249771118164, 'learning_rate': 1.845018450184502e-05, 'epoch': 0.02}\n",
            "  1% 125/10838 [00:19<27:05,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.7713, 'grad_norm': 22.499189376831055, 'learning_rate': 2.3062730627306276e-05, 'epoch': 0.02}\u001b[0m\n",
            "{'loss': 3.7713, 'grad_norm': 22.499189376831055, 'learning_rate': 2.3062730627306276e-05, 'epoch': 0.02}\n",
            "  1% 150/10838 [00:23<27:02,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:03:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.5342, 'grad_norm': 5.041182041168213, 'learning_rate': 2.767527675276753e-05, 'epoch': 0.03}\u001b[0m\n",
            "{'loss': 3.5342, 'grad_norm': 5.041182041168213, 'learning_rate': 2.767527675276753e-05, 'epoch': 0.03}\n",
            "  2% 175/10838 [00:27<26:54,  6.61it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.1584, 'grad_norm': 23.35421371459961, 'learning_rate': 3.2287822878228784e-05, 'epoch': 0.03}\u001b[0m\n",
            "{'loss': 3.1584, 'grad_norm': 23.35421371459961, 'learning_rate': 3.2287822878228784e-05, 'epoch': 0.03}\n",
            "  2% 200/10838 [00:31<26:55,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:05\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.294, 'grad_norm': 8.146917343139648, 'learning_rate': 3.690036900369004e-05, 'epoch': 0.04}\u001b[0m\n",
            "{'loss': 3.294, 'grad_norm': 8.146917343139648, 'learning_rate': 3.690036900369004e-05, 'epoch': 0.04}\n",
            "  2% 225/10838 [00:35<26:48,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.9968, 'grad_norm': 5.847854137420654, 'learning_rate': 4.151291512915129e-05, 'epoch': 0.04}\u001b[0m\n",
            "{'loss': 2.9968, 'grad_norm': 5.847854137420654, 'learning_rate': 4.151291512915129e-05, 'epoch': 0.04}\n",
            "  2% 250/10838 [00:38<26:44,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.2959, 'grad_norm': 7.981499671936035, 'learning_rate': 4.612546125461255e-05, 'epoch': 0.05}\u001b[0m\n",
            "{'loss': 3.2959, 'grad_norm': 7.981499671936035, 'learning_rate': 4.612546125461255e-05, 'epoch': 0.05}\n",
            "  3% 275/10838 [00:42<26:44,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.0149, 'grad_norm': 5.223936080932617, 'learning_rate': 5.073800738007381e-05, 'epoch': 0.05}\u001b[0m\n",
            "{'loss': 3.0149, 'grad_norm': 5.223936080932617, 'learning_rate': 5.073800738007381e-05, 'epoch': 0.05}\n",
            "  3% 300/10838 [00:46<26:38,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.0284, 'grad_norm': 4.710224151611328, 'learning_rate': 5.535055350553506e-05, 'epoch': 0.06}\u001b[0m\n",
            "{'loss': 3.0284, 'grad_norm': 4.710224151611328, 'learning_rate': 5.535055350553506e-05, 'epoch': 0.06}\n",
            "  3% 325/10838 [00:50<26:34,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:24\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8144, 'grad_norm': 9.142123222351074, 'learning_rate': 5.996309963099631e-05, 'epoch': 0.06}\u001b[0m\n",
            "{'loss': 2.8144, 'grad_norm': 9.142123222351074, 'learning_rate': 5.996309963099631e-05, 'epoch': 0.06}\n",
            "  3% 350/10838 [00:54<26:35,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.214, 'grad_norm': 4.353789329528809, 'learning_rate': 6.457564575645757e-05, 'epoch': 0.06}\u001b[0m\n",
            "{'loss': 3.214, 'grad_norm': 4.353789329528809, 'learning_rate': 6.457564575645757e-05, 'epoch': 0.06}\n",
            "  3% 375/10838 [00:58<38:24,  4.54it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:32\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.081, 'grad_norm': 4.2582244873046875, 'learning_rate': 6.918819188191882e-05, 'epoch': 0.07}\u001b[0m\n",
            "{'loss': 3.081, 'grad_norm': 4.2582244873046875, 'learning_rate': 6.918819188191882e-05, 'epoch': 0.07}\n",
            "  4% 400/10838 [01:02<26:30,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:36\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.14, 'grad_norm': 21.963388442993164, 'learning_rate': 7.380073800738008e-05, 'epoch': 0.07}\u001b[0m\n",
            "{'loss': 3.14, 'grad_norm': 21.963388442993164, 'learning_rate': 7.380073800738008e-05, 'epoch': 0.07}\n",
            "  4% 425/10838 [01:06<26:23,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8682, 'grad_norm': 4.926302433013916, 'learning_rate': 7.841328413284134e-05, 'epoch': 0.08}\u001b[0m\n",
            "{'loss': 2.8682, 'grad_norm': 4.926302433013916, 'learning_rate': 7.841328413284134e-05, 'epoch': 0.08}\n",
            "  4% 450/10838 [01:10<26:18,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.9468, 'grad_norm': 4.563528060913086, 'learning_rate': 8.302583025830258e-05, 'epoch': 0.08}\u001b[0m\n",
            "{'loss': 2.9468, 'grad_norm': 4.563528060913086, 'learning_rate': 8.302583025830258e-05, 'epoch': 0.08}\n",
            "  4% 475/10838 [01:13<26:16,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6664, 'grad_norm': 3.755681037902832, 'learning_rate': 8.763837638376384e-05, 'epoch': 0.09}\u001b[0m\n",
            "{'loss': 2.6664, 'grad_norm': 3.755681037902832, 'learning_rate': 8.763837638376384e-05, 'epoch': 0.09}\n",
            "  5% 500/10838 [01:17<26:13,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:51\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8429, 'grad_norm': 4.226354122161865, 'learning_rate': 9.22509225092251e-05, 'epoch': 0.09}\u001b[0m\n",
            "{'loss': 2.8429, 'grad_norm': 4.226354122161865, 'learning_rate': 9.22509225092251e-05, 'epoch': 0.09}\n",
            "  5% 525/10838 [01:21<26:07,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:55\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.0467, 'grad_norm': 4.037846088409424, 'learning_rate': 9.686346863468635e-05, 'epoch': 0.1}\u001b[0m\n",
            "{'loss': 3.0467, 'grad_norm': 4.037846088409424, 'learning_rate': 9.686346863468635e-05, 'epoch': 0.1}\n",
            "  5% 550/10838 [01:25<26:05,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:04:59\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8582, 'grad_norm': 3.8403518199920654, 'learning_rate': 0.00010147601476014761, 'epoch': 0.1}\u001b[0m\n",
            "{'loss': 2.8582, 'grad_norm': 3.8403518199920654, 'learning_rate': 0.00010147601476014761, 'epoch': 0.1}\n",
            "  5% 575/10838 [01:29<26:00,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:03\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8904, 'grad_norm': 4.265079975128174, 'learning_rate': 0.00010608856088560885, 'epoch': 0.11}\u001b[0m\n",
            "{'loss': 2.8904, 'grad_norm': 4.265079975128174, 'learning_rate': 0.00010608856088560885, 'epoch': 0.11}\n",
            "  6% 600/10838 [01:33<25:53,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7091, 'grad_norm': 4.88287878036499, 'learning_rate': 0.00011070110701107013, 'epoch': 0.11}\u001b[0m\n",
            "{'loss': 2.7091, 'grad_norm': 4.88287878036499, 'learning_rate': 0.00011070110701107013, 'epoch': 0.11}\n",
            "  6% 625/10838 [01:36<25:54,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8769, 'grad_norm': 3.3740744590759277, 'learning_rate': 0.00011531365313653138, 'epoch': 0.12}\u001b[0m\n",
            "{'loss': 2.8769, 'grad_norm': 3.3740744590759277, 'learning_rate': 0.00011531365313653138, 'epoch': 0.12}\n",
            "  6% 650/10838 [01:41<25:54,  6.55it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8126, 'grad_norm': 3.1118361949920654, 'learning_rate': 0.00011992619926199262, 'epoch': 0.12}\u001b[0m\n",
            "{'loss': 2.8126, 'grad_norm': 3.1118361949920654, 'learning_rate': 0.00011992619926199262, 'epoch': 0.12}\n",
            "  6% 675/10838 [01:44<25:42,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7974, 'grad_norm': 3.409771680831909, 'learning_rate': 0.00012453874538745387, 'epoch': 0.12}\u001b[0m\n",
            "{'loss': 2.7974, 'grad_norm': 3.409771680831909, 'learning_rate': 0.00012453874538745387, 'epoch': 0.12}\n",
            "  6% 700/10838 [01:48<25:41,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8929, 'grad_norm': 3.4208872318267822, 'learning_rate': 0.00012915129151291514, 'epoch': 0.13}\u001b[0m\n",
            "{'loss': 2.8929, 'grad_norm': 3.4208872318267822, 'learning_rate': 0.00012915129151291514, 'epoch': 0.13}\n",
            "  7% 725/10838 [01:52<25:39,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8298, 'grad_norm': 2.7412803173065186, 'learning_rate': 0.0001337638376383764, 'epoch': 0.13}\u001b[0m\n",
            "{'loss': 2.8298, 'grad_norm': 2.7412803173065186, 'learning_rate': 0.0001337638376383764, 'epoch': 0.13}\n",
            "  7% 750/10838 [01:56<25:31,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:30\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8735, 'grad_norm': 2.9482758045196533, 'learning_rate': 0.00013837638376383763, 'epoch': 0.14}\u001b[0m\n",
            "{'loss': 2.8735, 'grad_norm': 2.9482758045196533, 'learning_rate': 0.00013837638376383763, 'epoch': 0.14}\n",
            "  7% 775/10838 [02:00<25:32,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:34\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8463, 'grad_norm': 2.842407464981079, 'learning_rate': 0.0001429889298892989, 'epoch': 0.14}\u001b[0m\n",
            "{'loss': 2.8463, 'grad_norm': 2.842407464981079, 'learning_rate': 0.0001429889298892989, 'epoch': 0.14}\n",
            "  7% 800/10838 [02:04<25:32,  6.55it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.9924, 'grad_norm': 3.160461902618408, 'learning_rate': 0.00014760147601476016, 'epoch': 0.15}\u001b[0m\n",
            "{'loss': 2.9924, 'grad_norm': 3.160461902618408, 'learning_rate': 0.00014760147601476016, 'epoch': 0.15}\n",
            "  8% 825/10838 [02:08<25:20,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.9528, 'grad_norm': 2.8578529357910156, 'learning_rate': 0.0001522140221402214, 'epoch': 0.15}\u001b[0m\n",
            "{'loss': 2.9528, 'grad_norm': 2.8578529357910156, 'learning_rate': 0.0001522140221402214, 'epoch': 0.15}\n",
            "  8% 850/10838 [02:12<25:22,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7574, 'grad_norm': 3.1892621517181396, 'learning_rate': 0.00015682656826568268, 'epoch': 0.16}\u001b[0m\n",
            "{'loss': 2.7574, 'grad_norm': 3.1892621517181396, 'learning_rate': 0.00015682656826568268, 'epoch': 0.16}\n",
            "  8% 875/10838 [02:15<25:21,  6.55it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8158, 'grad_norm': 2.5363433361053467, 'learning_rate': 0.00016143911439114392, 'epoch': 0.16}\u001b[0m\n",
            "{'loss': 2.8158, 'grad_norm': 2.5363433361053467, 'learning_rate': 0.00016143911439114392, 'epoch': 0.16}\n",
            "  8% 900/10838 [02:19<25:10,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7638, 'grad_norm': 2.4465906620025635, 'learning_rate': 0.00016605166051660516, 'epoch': 0.17}\u001b[0m\n",
            "{'loss': 2.7638, 'grad_norm': 2.4465906620025635, 'learning_rate': 0.00016605166051660516, 'epoch': 0.17}\n",
            "  9% 925/10838 [02:23<25:03,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:05:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5429, 'grad_norm': 2.5108518600463867, 'learning_rate': 0.00017066420664206645, 'epoch': 0.17}\u001b[0m\n",
            "{'loss': 2.5429, 'grad_norm': 2.5108518600463867, 'learning_rate': 0.00017066420664206645, 'epoch': 0.17}\n",
            "  9% 950/10838 [02:27<25:07,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.0183, 'grad_norm': 2.526843309402466, 'learning_rate': 0.00017527675276752768, 'epoch': 0.18}\u001b[0m\n",
            "{'loss': 3.0183, 'grad_norm': 2.526843309402466, 'learning_rate': 0.00017527675276752768, 'epoch': 0.18}\n",
            "  9% 975/10838 [02:31<24:56,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:05\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8697, 'grad_norm': 2.653930902481079, 'learning_rate': 0.00017988929889298894, 'epoch': 0.18}\u001b[0m\n",
            "{'loss': 2.8697, 'grad_norm': 2.653930902481079, 'learning_rate': 0.00017988929889298894, 'epoch': 0.18}\n",
            "  9% 1000/10838 [02:35<24:54,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:09\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 3.0051, 'grad_norm': 1.861312985420227, 'learning_rate': 0.0001845018450184502, 'epoch': 0.18}\u001b[0m\n",
            "{'loss': 3.0051, 'grad_norm': 1.861312985420227, 'learning_rate': 0.0001845018450184502, 'epoch': 0.18}\n",
            "  9% 1025/10838 [02:39<24:52,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8836, 'grad_norm': 3.044445514678955, 'learning_rate': 0.00018911439114391144, 'epoch': 0.19}\u001b[0m\n",
            "{'loss': 2.8836, 'grad_norm': 3.044445514678955, 'learning_rate': 0.00018911439114391144, 'epoch': 0.19}\n",
            " 10% 1050/10838 [02:42<24:42,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7911, 'grad_norm': 2.6610188484191895, 'learning_rate': 0.0001937269372693727, 'epoch': 0.19}\u001b[0m\n",
            "{'loss': 2.7911, 'grad_norm': 2.6610188484191895, 'learning_rate': 0.0001937269372693727, 'epoch': 0.19}\n",
            " 10% 1075/10838 [02:46<24:39,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.787, 'grad_norm': 2.496821403503418, 'learning_rate': 0.00019833948339483394, 'epoch': 0.2}\u001b[0m\n",
            "{'loss': 2.787, 'grad_norm': 2.496821403503418, 'learning_rate': 0.00019833948339483394, 'epoch': 0.2}\n",
            " 10% 1100/10838 [02:50<24:43,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:24\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7629, 'grad_norm': 2.6125216484069824, 'learning_rate': 0.00019967192946483494, 'epoch': 0.2}\u001b[0m\n",
            "{'loss': 2.7629, 'grad_norm': 2.6125216484069824, 'learning_rate': 0.00019967192946483494, 'epoch': 0.2}\n",
            " 10% 1125/10838 [02:54<24:37,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8813, 'grad_norm': 2.7133781909942627, 'learning_rate': 0.00019915931925363952, 'epoch': 0.21}\u001b[0m\n",
            "{'loss': 2.8813, 'grad_norm': 2.7133781909942627, 'learning_rate': 0.00019915931925363952, 'epoch': 0.21}\n",
            " 11% 1150/10838 [02:58<24:31,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:32\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6018, 'grad_norm': 2.393848419189453, 'learning_rate': 0.00019864670904244414, 'epoch': 0.21}\u001b[0m\n",
            "{'loss': 2.6018, 'grad_norm': 2.393848419189453, 'learning_rate': 0.00019864670904244414, 'epoch': 0.21}\n",
            " 11% 1175/10838 [03:02<24:31,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:36\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6816, 'grad_norm': 2.7648420333862305, 'learning_rate': 0.00019813409883124875, 'epoch': 0.22}\u001b[0m\n",
            "{'loss': 2.6816, 'grad_norm': 2.7648420333862305, 'learning_rate': 0.00019813409883124875, 'epoch': 0.22}\n",
            " 11% 1200/10838 [03:06<24:35,  6.53it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.9477, 'grad_norm': 2.528402090072632, 'learning_rate': 0.0001976214886200533, 'epoch': 0.22}\u001b[0m\n",
            "{'loss': 2.9477, 'grad_norm': 2.528402090072632, 'learning_rate': 0.0001976214886200533, 'epoch': 0.22}\n",
            " 11% 1225/10838 [03:09<24:19,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.819, 'grad_norm': 2.3227479457855225, 'learning_rate': 0.00019710887840885792, 'epoch': 0.23}\u001b[0m\n",
            "{'loss': 2.819, 'grad_norm': 2.3227479457855225, 'learning_rate': 0.00019710887840885792, 'epoch': 0.23}\n",
            " 12% 1250/10838 [03:13<24:20,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.9138, 'grad_norm': 3.443326234817505, 'learning_rate': 0.0001965962681976625, 'epoch': 0.23}\u001b[0m\n",
            "{'loss': 2.9138, 'grad_norm': 3.443326234817505, 'learning_rate': 0.0001965962681976625, 'epoch': 0.23}\n",
            " 12% 1275/10838 [03:17<24:20,  6.55it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:51\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7905, 'grad_norm': 2.608851909637451, 'learning_rate': 0.0001960836579864671, 'epoch': 0.24}\u001b[0m\n",
            "{'loss': 2.7905, 'grad_norm': 2.608851909637451, 'learning_rate': 0.0001960836579864671, 'epoch': 0.24}\n",
            " 12% 1300/10838 [03:21<24:09,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:55\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6399, 'grad_norm': 2.2918872833251953, 'learning_rate': 0.00019557104777527168, 'epoch': 0.24}\u001b[0m\n",
            "{'loss': 2.6399, 'grad_norm': 2.2918872833251953, 'learning_rate': 0.00019557104777527168, 'epoch': 0.24}\n",
            " 12% 1325/10838 [03:25<24:06,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:06:59\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6723, 'grad_norm': 1.7810522317886353, 'learning_rate': 0.0001950584375640763, 'epoch': 0.24}\u001b[0m\n",
            "{'loss': 2.6723, 'grad_norm': 1.7810522317886353, 'learning_rate': 0.0001950584375640763, 'epoch': 0.24}\n",
            " 12% 1350/10838 [03:29<24:00,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:03\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7153, 'grad_norm': 2.0149779319763184, 'learning_rate': 0.00019454582735288088, 'epoch': 0.25}\u001b[0m\n",
            "{'loss': 2.7153, 'grad_norm': 2.0149779319763184, 'learning_rate': 0.00019454582735288088, 'epoch': 0.25}\n",
            " 13% 1375/10838 [03:33<23:55,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7032, 'grad_norm': 2.924759864807129, 'learning_rate': 0.00019403321714168547, 'epoch': 0.25}\u001b[0m\n",
            "{'loss': 2.7032, 'grad_norm': 2.924759864807129, 'learning_rate': 0.00019403321714168547, 'epoch': 0.25}\n",
            " 13% 1400/10838 [03:36<23:54,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7447, 'grad_norm': 2.5229737758636475, 'learning_rate': 0.00019352060693049005, 'epoch': 0.26}\u001b[0m\n",
            "{'loss': 2.7447, 'grad_norm': 2.5229737758636475, 'learning_rate': 0.00019352060693049005, 'epoch': 0.26}\n",
            " 13% 1425/10838 [03:40<23:51,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.78, 'grad_norm': 2.075315237045288, 'learning_rate': 0.00019300799671929467, 'epoch': 0.26}\u001b[0m\n",
            "{'loss': 2.78, 'grad_norm': 2.075315237045288, 'learning_rate': 0.00019300799671929467, 'epoch': 0.26}\n",
            " 13% 1450/10838 [03:44<23:46,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.9042, 'grad_norm': 43.220420837402344, 'learning_rate': 0.00019249538650809923, 'epoch': 0.27}\u001b[0m\n",
            "{'loss': 2.9042, 'grad_norm': 43.220420837402344, 'learning_rate': 0.00019249538650809923, 'epoch': 0.27}\n",
            " 14% 1475/10838 [03:48<23:41,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7271, 'grad_norm': 1.9476944208145142, 'learning_rate': 0.00019198277629690384, 'epoch': 0.27}\u001b[0m\n",
            "{'loss': 2.7271, 'grad_norm': 1.9476944208145142, 'learning_rate': 0.00019198277629690384, 'epoch': 0.27}\n",
            " 14% 1500/10838 [03:52<23:42,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5751, 'grad_norm': 2.2007853984832764, 'learning_rate': 0.00019147016608570845, 'epoch': 0.28}\u001b[0m\n",
            "{'loss': 2.5751, 'grad_norm': 2.2007853984832764, 'learning_rate': 0.00019147016608570845, 'epoch': 0.28}\n",
            " 14% 1525/10838 [03:56<23:33,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6706, 'grad_norm': 3.4446401596069336, 'learning_rate': 0.00019095755587451304, 'epoch': 0.28}\u001b[0m\n",
            "{'loss': 2.6706, 'grad_norm': 3.4446401596069336, 'learning_rate': 0.00019095755587451304, 'epoch': 0.28}\n",
            " 14% 1550/10838 [04:00<23:34,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:34\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.639, 'grad_norm': 2.1421267986297607, 'learning_rate': 0.00019044494566331763, 'epoch': 0.29}\u001b[0m\n",
            "{'loss': 2.639, 'grad_norm': 2.1421267986297607, 'learning_rate': 0.00019044494566331763, 'epoch': 0.29}\n",
            " 15% 1575/10838 [04:04<23:31,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6331, 'grad_norm': 2.1008548736572266, 'learning_rate': 0.0001899323354521222, 'epoch': 0.29}\u001b[0m\n",
            "{'loss': 2.6331, 'grad_norm': 2.1008548736572266, 'learning_rate': 0.0001899323354521222, 'epoch': 0.29}\n",
            " 15% 1600/10838 [04:07<23:22,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7004, 'grad_norm': 2.2266430854797363, 'learning_rate': 0.00018941972524092683, 'epoch': 0.3}\u001b[0m\n",
            "{'loss': 2.7004, 'grad_norm': 2.2266430854797363, 'learning_rate': 0.00018941972524092683, 'epoch': 0.3}\n",
            " 15% 1625/10838 [04:11<23:20,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6033, 'grad_norm': 1.9650578498840332, 'learning_rate': 0.00018890711502973139, 'epoch': 0.3}\u001b[0m\n",
            "{'loss': 2.6033, 'grad_norm': 1.9650578498840332, 'learning_rate': 0.00018890711502973139, 'epoch': 0.3}\n",
            " 15% 1650/10838 [04:15<23:13,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7184, 'grad_norm': 2.184032678604126, 'learning_rate': 0.000188394504818536, 'epoch': 0.3}\u001b[0m\n",
            "{'loss': 2.7184, 'grad_norm': 2.184032678604126, 'learning_rate': 0.000188394504818536, 'epoch': 0.3}\n",
            " 15% 1675/10838 [04:19<23:14,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6194, 'grad_norm': 2.0491268634796143, 'learning_rate': 0.00018788189460734058, 'epoch': 0.31}\u001b[0m\n",
            "{'loss': 2.6194, 'grad_norm': 2.0491268634796143, 'learning_rate': 0.00018788189460734058, 'epoch': 0.31}\n",
            " 16% 1700/10838 [04:23<23:06,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:07:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5984, 'grad_norm': 1.9940811395645142, 'learning_rate': 0.00018736928439614517, 'epoch': 0.31}\u001b[0m\n",
            "{'loss': 2.5984, 'grad_norm': 1.9940811395645142, 'learning_rate': 0.00018736928439614517, 'epoch': 0.31}\n",
            " 16% 1725/10838 [04:27<23:03,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8371, 'grad_norm': 3.2531747817993164, 'learning_rate': 0.00018685667418494976, 'epoch': 0.32}\u001b[0m\n",
            "{'loss': 2.8371, 'grad_norm': 3.2531747817993164, 'learning_rate': 0.00018685667418494976, 'epoch': 0.32}\n",
            " 16% 1750/10838 [04:31<23:01,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:04\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6436, 'grad_norm': 1.6680819988250732, 'learning_rate': 0.00018634406397375437, 'epoch': 0.32}\u001b[0m\n",
            "{'loss': 2.6436, 'grad_norm': 1.6680819988250732, 'learning_rate': 0.00018634406397375437, 'epoch': 0.32}\n",
            " 16% 1775/10838 [04:34<22:57,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4987, 'grad_norm': 2.0941720008850098, 'learning_rate': 0.00018583145376255896, 'epoch': 0.33}\u001b[0m\n",
            "{'loss': 2.4987, 'grad_norm': 2.0941720008850098, 'learning_rate': 0.00018583145376255896, 'epoch': 0.33}\n",
            " 17% 1800/10838 [04:38<22:53,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8044, 'grad_norm': 11.526918411254883, 'learning_rate': 0.00018531884355136354, 'epoch': 0.33}\u001b[0m\n",
            "{'loss': 2.8044, 'grad_norm': 11.526918411254883, 'learning_rate': 0.00018531884355136354, 'epoch': 0.33}\n",
            " 17% 1825/10838 [04:42<22:50,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7063, 'grad_norm': 2.1924617290496826, 'learning_rate': 0.00018480623334016816, 'epoch': 0.34}\u001b[0m\n",
            "{'loss': 2.7063, 'grad_norm': 2.1924617290496826, 'learning_rate': 0.00018480623334016816, 'epoch': 0.34}\n",
            " 17% 1850/10838 [04:46<22:44,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6318, 'grad_norm': 6.652830123901367, 'learning_rate': 0.00018429362312897274, 'epoch': 0.34}\u001b[0m\n",
            "{'loss': 2.6318, 'grad_norm': 6.652830123901367, 'learning_rate': 0.00018429362312897274, 'epoch': 0.34}\n",
            " 17% 1875/10838 [04:50<22:42,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:24\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6136, 'grad_norm': 2.537393569946289, 'learning_rate': 0.00018378101291777733, 'epoch': 0.35}\u001b[0m\n",
            "{'loss': 2.6136, 'grad_norm': 2.537393569946289, 'learning_rate': 0.00018378101291777733, 'epoch': 0.35}\n",
            " 18% 1900/10838 [04:54<22:41,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6004, 'grad_norm': 1.8972874879837036, 'learning_rate': 0.00018326840270658192, 'epoch': 0.35}\u001b[0m\n",
            "{'loss': 2.6004, 'grad_norm': 1.8972874879837036, 'learning_rate': 0.00018326840270658192, 'epoch': 0.35}\n",
            " 18% 1925/10838 [04:58<22:39,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:32\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6307, 'grad_norm': 1.8269461393356323, 'learning_rate': 0.00018275579249538653, 'epoch': 0.36}\u001b[0m\n",
            "{'loss': 2.6307, 'grad_norm': 1.8269461393356323, 'learning_rate': 0.00018275579249538653, 'epoch': 0.36}\n",
            " 18% 1950/10838 [05:02<22:30,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7769, 'grad_norm': 2.465579032897949, 'learning_rate': 0.00018224318228419112, 'epoch': 0.36}\u001b[0m\n",
            "{'loss': 2.7769, 'grad_norm': 2.465579032897949, 'learning_rate': 0.00018224318228419112, 'epoch': 0.36}\n",
            " 18% 1975/10838 [05:05<22:27,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6026, 'grad_norm': 1.559126853942871, 'learning_rate': 0.0001817305720729957, 'epoch': 0.36}\u001b[0m\n",
            "{'loss': 2.6026, 'grad_norm': 1.559126853942871, 'learning_rate': 0.0001817305720729957, 'epoch': 0.36}\n",
            " 18% 2000/10838 [05:09<22:22,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6096, 'grad_norm': 1.6999183893203735, 'learning_rate': 0.0001812179618618003, 'epoch': 0.37}\u001b[0m\n",
            "{'loss': 2.6096, 'grad_norm': 1.6999183893203735, 'learning_rate': 0.0001812179618618003, 'epoch': 0.37}\n",
            " 19% 2025/10838 [05:13<22:17,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6129, 'grad_norm': 2.230802536010742, 'learning_rate': 0.0001807053516506049, 'epoch': 0.37}\u001b[0m\n",
            "{'loss': 2.6129, 'grad_norm': 2.230802536010742, 'learning_rate': 0.0001807053516506049, 'epoch': 0.37}\n",
            " 19% 2050/10838 [05:17<22:15,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:51\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.567, 'grad_norm': 1.3143064975738525, 'learning_rate': 0.00018019274143940946, 'epoch': 0.38}\u001b[0m\n",
            "{'loss': 2.567, 'grad_norm': 1.3143064975738525, 'learning_rate': 0.00018019274143940946, 'epoch': 0.38}\n",
            " 19% 2075/10838 [05:21<22:12,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:55\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5334, 'grad_norm': 2.5610427856445312, 'learning_rate': 0.00017968013122821407, 'epoch': 0.38}\u001b[0m\n",
            "{'loss': 2.5334, 'grad_norm': 2.5610427856445312, 'learning_rate': 0.00017968013122821407, 'epoch': 0.38}\n",
            " 19% 2100/10838 [05:25<22:05,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:08:59\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3962, 'grad_norm': 1.46962571144104, 'learning_rate': 0.00017916752101701866, 'epoch': 0.39}\u001b[0m\n",
            "{'loss': 2.3962, 'grad_norm': 1.46962571144104, 'learning_rate': 0.00017916752101701866, 'epoch': 0.39}\n",
            " 20% 2125/10838 [05:29<22:03,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6458, 'grad_norm': 1.6388484239578247, 'learning_rate': 0.00017865491080582327, 'epoch': 0.39}\u001b[0m\n",
            "{'loss': 2.6458, 'grad_norm': 1.6388484239578247, 'learning_rate': 0.00017865491080582327, 'epoch': 0.39}\n",
            " 20% 2150/10838 [05:32<22:01,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5498, 'grad_norm': 2.079862356185913, 'learning_rate': 0.00017814230059462786, 'epoch': 0.4}\u001b[0m\n",
            "{'loss': 2.5498, 'grad_norm': 2.079862356185913, 'learning_rate': 0.00017814230059462786, 'epoch': 0.4}\n",
            " 20% 2175/10838 [05:36<26:31,  5.44it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.8156, 'grad_norm': 1.6311651468276978, 'learning_rate': 0.00017762969038343245, 'epoch': 0.4}\u001b[0m\n",
            "{'loss': 2.8156, 'grad_norm': 1.6311651468276978, 'learning_rate': 0.00017762969038343245, 'epoch': 0.4}\n",
            " 20% 2200/10838 [05:40<21:51,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6505, 'grad_norm': 1.7954691648483276, 'learning_rate': 0.00017711708017223706, 'epoch': 0.41}\u001b[0m\n",
            "{'loss': 2.6505, 'grad_norm': 1.7954691648483276, 'learning_rate': 0.00017711708017223706, 'epoch': 0.41}\n",
            " 21% 2225/10838 [05:44<21:53,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6075, 'grad_norm': 1.8981279134750366, 'learning_rate': 0.00017660446996104162, 'epoch': 0.41}\u001b[0m\n",
            "{'loss': 2.6075, 'grad_norm': 1.8981279134750366, 'learning_rate': 0.00017660446996104162, 'epoch': 0.41}\n",
            " 21% 2250/10838 [05:48<21:46,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6558, 'grad_norm': 1.8795700073242188, 'learning_rate': 0.00017609185974984623, 'epoch': 0.42}\u001b[0m\n",
            "{'loss': 2.6558, 'grad_norm': 1.8795700073242188, 'learning_rate': 0.00017609185974984623, 'epoch': 0.42}\n",
            " 21% 2275/10838 [05:52<21:40,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7814, 'grad_norm': 1.6808562278747559, 'learning_rate': 0.00017557924953865082, 'epoch': 0.42}\u001b[0m\n",
            "{'loss': 2.7814, 'grad_norm': 1.6808562278747559, 'learning_rate': 0.00017557924953865082, 'epoch': 0.42}\n",
            " 21% 2300/10838 [05:56<21:42,  6.55it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:30\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6141, 'grad_norm': 1.713810682296753, 'learning_rate': 0.0001750666393274554, 'epoch': 0.42}\u001b[0m\n",
            "{'loss': 2.6141, 'grad_norm': 1.713810682296753, 'learning_rate': 0.0001750666393274554, 'epoch': 0.42}\n",
            " 21% 2325/10838 [06:00<21:32,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:33\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6659, 'grad_norm': 2.021527051925659, 'learning_rate': 0.00017455402911626, 'epoch': 0.43}\u001b[0m\n",
            "{'loss': 2.6659, 'grad_norm': 2.021527051925659, 'learning_rate': 0.00017455402911626, 'epoch': 0.43}\n",
            " 22% 2350/10838 [06:03<21:28,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.879, 'grad_norm': 1.6113274097442627, 'learning_rate': 0.0001740414189050646, 'epoch': 0.43}\u001b[0m\n",
            "{'loss': 2.879, 'grad_norm': 1.6113274097442627, 'learning_rate': 0.0001740414189050646, 'epoch': 0.43}\n",
            " 22% 2375/10838 [06:08<25:01,  5.64it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3574, 'grad_norm': 2.0196139812469482, 'learning_rate': 0.0001735288086938692, 'epoch': 0.44}\u001b[0m\n",
            "{'loss': 2.3574, 'grad_norm': 2.0196139812469482, 'learning_rate': 0.0001735288086938692, 'epoch': 0.44}\n",
            " 22% 2400/10838 [06:11<21:19,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.7547, 'grad_norm': 1.8705394268035889, 'learning_rate': 0.00017301619848267378, 'epoch': 0.44}\u001b[0m\n",
            "{'loss': 2.7547, 'grad_norm': 1.8705394268035889, 'learning_rate': 0.00017301619848267378, 'epoch': 0.44}\n",
            " 22% 2425/10838 [06:15<21:16,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6365, 'grad_norm': 1.6269161701202393, 'learning_rate': 0.00017250358827147836, 'epoch': 0.45}\u001b[0m\n",
            "{'loss': 2.6365, 'grad_norm': 1.6269161701202393, 'learning_rate': 0.00017250358827147836, 'epoch': 0.45}\n",
            " 23% 2450/10838 [06:19<21:14,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.487, 'grad_norm': 2.019139289855957, 'learning_rate': 0.00017199097806028298, 'epoch': 0.45}\u001b[0m\n",
            "{'loss': 2.487, 'grad_norm': 2.019139289855957, 'learning_rate': 0.00017199097806028298, 'epoch': 0.45}\n",
            " 23% 2475/10838 [06:23<21:09,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:09:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3519, 'grad_norm': 2.084233283996582, 'learning_rate': 0.00017147836784908756, 'epoch': 0.46}\u001b[0m\n",
            "{'loss': 2.3519, 'grad_norm': 2.084233283996582, 'learning_rate': 0.00017147836784908756, 'epoch': 0.46}\n",
            " 23% 2500/10838 [06:27<21:04,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.398, 'grad_norm': 1.6697235107421875, 'learning_rate': 0.00017096575763789215, 'epoch': 0.46}\u001b[0m\n",
            "{'loss': 2.398, 'grad_norm': 1.6697235107421875, 'learning_rate': 0.00017096575763789215, 'epoch': 0.46}\n",
            " 23% 2525/10838 [06:31<21:01,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:04\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3756, 'grad_norm': 1.465166449546814, 'learning_rate': 0.00017045314742669676, 'epoch': 0.47}\u001b[0m\n",
            "{'loss': 2.3756, 'grad_norm': 1.465166449546814, 'learning_rate': 0.00017045314742669676, 'epoch': 0.47}\n",
            " 24% 2550/10838 [06:34<20:56,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5204, 'grad_norm': 2.0802528858184814, 'learning_rate': 0.00016994053721550135, 'epoch': 0.47}\u001b[0m\n",
            "{'loss': 2.5204, 'grad_norm': 2.0802528858184814, 'learning_rate': 0.00016994053721550135, 'epoch': 0.47}\n",
            " 24% 2575/10838 [06:38<20:55,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6983, 'grad_norm': 2.7967448234558105, 'learning_rate': 0.00016942792700430593, 'epoch': 0.48}\u001b[0m\n",
            "{'loss': 2.6983, 'grad_norm': 2.7967448234558105, 'learning_rate': 0.00016942792700430593, 'epoch': 0.48}\n",
            " 24% 2600/10838 [06:42<20:49,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4547, 'grad_norm': 1.7470078468322754, 'learning_rate': 0.00016891531679311052, 'epoch': 0.48}\u001b[0m\n",
            "{'loss': 2.4547, 'grad_norm': 1.7470078468322754, 'learning_rate': 0.00016891531679311052, 'epoch': 0.48}\n",
            " 24% 2625/10838 [06:46<20:47,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5589, 'grad_norm': 1.44440758228302, 'learning_rate': 0.00016840270658191513, 'epoch': 0.48}\u001b[0m\n",
            "{'loss': 2.5589, 'grad_norm': 1.44440758228302, 'learning_rate': 0.00016840270658191513, 'epoch': 0.48}\n",
            " 24% 2650/10838 [06:50<20:42,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:24\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4578, 'grad_norm': 1.4121994972229004, 'learning_rate': 0.00016789009637071972, 'epoch': 0.49}\u001b[0m\n",
            "{'loss': 2.4578, 'grad_norm': 1.4121994972229004, 'learning_rate': 0.00016789009637071972, 'epoch': 0.49}\n",
            " 25% 2675/10838 [06:54<20:43,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6375, 'grad_norm': 1.5642650127410889, 'learning_rate': 0.0001673774861595243, 'epoch': 0.49}\u001b[0m\n",
            "{'loss': 2.6375, 'grad_norm': 1.5642650127410889, 'learning_rate': 0.0001673774861595243, 'epoch': 0.49}\n",
            " 25% 2700/10838 [06:58<20:38,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:31\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4391, 'grad_norm': 1.6984424591064453, 'learning_rate': 0.0001668648759483289, 'epoch': 0.5}\u001b[0m\n",
            "{'loss': 2.4391, 'grad_norm': 1.6984424591064453, 'learning_rate': 0.0001668648759483289, 'epoch': 0.5}\n",
            " 25% 2725/10838 [07:01<20:28,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4843, 'grad_norm': 1.4548258781433105, 'learning_rate': 0.0001663522657371335, 'epoch': 0.5}\u001b[0m\n",
            "{'loss': 2.4843, 'grad_norm': 1.4548258781433105, 'learning_rate': 0.0001663522657371335, 'epoch': 0.5}\n",
            " 25% 2750/10838 [07:05<20:29,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5407, 'grad_norm': 1.8680118322372437, 'learning_rate': 0.00016583965552593807, 'epoch': 0.51}\u001b[0m\n",
            "{'loss': 2.5407, 'grad_norm': 1.8680118322372437, 'learning_rate': 0.00016583965552593807, 'epoch': 0.51}\n",
            " 26% 2775/10838 [07:09<20:25,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5249, 'grad_norm': 1.2738454341888428, 'learning_rate': 0.00016532704531474268, 'epoch': 0.51}\u001b[0m\n",
            "{'loss': 2.5249, 'grad_norm': 1.2738454341888428, 'learning_rate': 0.00016532704531474268, 'epoch': 0.51}\n",
            " 26% 2800/10838 [07:13<20:19,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4492, 'grad_norm': 1.8125702142715454, 'learning_rate': 0.00016481443510354726, 'epoch': 0.52}\u001b[0m\n",
            "{'loss': 2.4492, 'grad_norm': 1.8125702142715454, 'learning_rate': 0.00016481443510354726, 'epoch': 0.52}\n",
            " 26% 2825/10838 [07:17<20:17,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:51\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.526, 'grad_norm': 1.7893587350845337, 'learning_rate': 0.00016430182489235185, 'epoch': 0.52}\u001b[0m\n",
            "{'loss': 2.526, 'grad_norm': 1.7893587350845337, 'learning_rate': 0.00016430182489235185, 'epoch': 0.52}\n",
            " 26% 2850/10838 [07:21<20:16,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:55\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.524, 'grad_norm': 1.4486161470413208, 'learning_rate': 0.00016378921468115646, 'epoch': 0.53}\u001b[0m\n",
            "{'loss': 2.524, 'grad_norm': 1.4486161470413208, 'learning_rate': 0.00016378921468115646, 'epoch': 0.53}\n",
            " 27% 2875/10838 [07:25<20:11,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:10:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6119, 'grad_norm': 1.9998064041137695, 'learning_rate': 0.00016327660446996105, 'epoch': 0.53}\u001b[0m\n",
            "{'loss': 2.6119, 'grad_norm': 1.9998064041137695, 'learning_rate': 0.00016327660446996105, 'epoch': 0.53}\n",
            " 27% 2900/10838 [07:28<20:03,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5395, 'grad_norm': 1.6144647598266602, 'learning_rate': 0.00016276399425876566, 'epoch': 0.54}\u001b[0m\n",
            "{'loss': 2.5395, 'grad_norm': 1.6144647598266602, 'learning_rate': 0.00016276399425876566, 'epoch': 0.54}\n",
            " 27% 2925/10838 [07:32<20:02,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5966, 'grad_norm': 1.423141360282898, 'learning_rate': 0.00016225138404757022, 'epoch': 0.54}\u001b[0m\n",
            "{'loss': 2.5966, 'grad_norm': 1.423141360282898, 'learning_rate': 0.00016225138404757022, 'epoch': 0.54}\n",
            " 27% 2950/10838 [07:36<19:58,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4042, 'grad_norm': 1.8098838329315186, 'learning_rate': 0.00016173877383637484, 'epoch': 0.54}\u001b[0m\n",
            "{'loss': 2.4042, 'grad_norm': 1.8098838329315186, 'learning_rate': 0.00016173877383637484, 'epoch': 0.54}\n",
            " 27% 2975/10838 [07:40<19:59,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4556, 'grad_norm': 2.224540948867798, 'learning_rate': 0.00016122616362517942, 'epoch': 0.55}\u001b[0m\n",
            "{'loss': 2.4556, 'grad_norm': 2.224540948867798, 'learning_rate': 0.00016122616362517942, 'epoch': 0.55}\n",
            " 28% 3000/10838 [07:44<19:52,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.469, 'grad_norm': 1.5955069065093994, 'learning_rate': 0.000160713553413984, 'epoch': 0.55}\u001b[0m\n",
            "{'loss': 2.469, 'grad_norm': 1.5955069065093994, 'learning_rate': 0.000160713553413984, 'epoch': 0.55}\n",
            " 28% 3025/10838 [07:48<19:47,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:21\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2121, 'grad_norm': 1.800866723060608, 'learning_rate': 0.0001602009432027886, 'epoch': 0.56}\u001b[0m\n",
            "{'loss': 2.2121, 'grad_norm': 1.800866723060608, 'learning_rate': 0.0001602009432027886, 'epoch': 0.56}\n",
            " 28% 3050/10838 [07:51<19:43,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:25\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5696, 'grad_norm': 2.179147720336914, 'learning_rate': 0.0001596883329915932, 'epoch': 0.56}\u001b[0m\n",
            "{'loss': 2.5696, 'grad_norm': 2.179147720336914, 'learning_rate': 0.0001596883329915932, 'epoch': 0.56}\n",
            " 28% 3075/10838 [07:56<21:50,  5.92it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5329, 'grad_norm': 1.7833948135375977, 'learning_rate': 0.0001591757227803978, 'epoch': 0.57}\u001b[0m\n",
            "{'loss': 2.5329, 'grad_norm': 1.7833948135375977, 'learning_rate': 0.0001591757227803978, 'epoch': 0.57}\n",
            " 29% 3100/10838 [07:59<19:39,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:33\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4638, 'grad_norm': 1.5997506380081177, 'learning_rate': 0.00015866311256920238, 'epoch': 0.57}\u001b[0m\n",
            "{'loss': 2.4638, 'grad_norm': 1.5997506380081177, 'learning_rate': 0.00015866311256920238, 'epoch': 0.57}\n",
            " 29% 3125/10838 [08:03<19:31,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4343, 'grad_norm': 1.556506872177124, 'learning_rate': 0.00015815050235800697, 'epoch': 0.58}\u001b[0m\n",
            "{'loss': 2.4343, 'grad_norm': 1.556506872177124, 'learning_rate': 0.00015815050235800697, 'epoch': 0.58}\n",
            " 29% 3150/10838 [08:07<19:28,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6523, 'grad_norm': 1.8157817125320435, 'learning_rate': 0.00015763789214681158, 'epoch': 0.58}\u001b[0m\n",
            "{'loss': 2.6523, 'grad_norm': 1.8157817125320435, 'learning_rate': 0.00015763789214681158, 'epoch': 0.58}\n",
            " 29% 3175/10838 [08:11<19:23,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4195, 'grad_norm': 1.9137929677963257, 'learning_rate': 0.00015712528193561617, 'epoch': 0.59}\u001b[0m\n",
            "{'loss': 2.4195, 'grad_norm': 1.9137929677963257, 'learning_rate': 0.00015712528193561617, 'epoch': 0.59}\n",
            " 30% 3200/10838 [08:15<19:21,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3698, 'grad_norm': 1.7916414737701416, 'learning_rate': 0.00015661267172442075, 'epoch': 0.59}\u001b[0m\n",
            "{'loss': 2.3698, 'grad_norm': 1.7916414737701416, 'learning_rate': 0.00015661267172442075, 'epoch': 0.59}\n",
            " 30% 3225/10838 [08:19<19:16,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1746, 'grad_norm': 1.3363758325576782, 'learning_rate': 0.00015610006151322537, 'epoch': 0.6}\u001b[0m\n",
            "{'loss': 2.1746, 'grad_norm': 1.3363758325576782, 'learning_rate': 0.00015610006151322537, 'epoch': 0.6}\n",
            " 30% 3250/10838 [08:23<19:14,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:11:56\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6705, 'grad_norm': 1.678961992263794, 'learning_rate': 0.00015558745130202995, 'epoch': 0.6}\u001b[0m\n",
            "{'loss': 2.6705, 'grad_norm': 1.678961992263794, 'learning_rate': 0.00015558745130202995, 'epoch': 0.6}\n",
            " 30% 3275/10838 [08:26<19:05,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:00\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4186, 'grad_norm': 1.6272372007369995, 'learning_rate': 0.00015507484109083454, 'epoch': 0.6}\u001b[0m\n",
            "{'loss': 2.4186, 'grad_norm': 1.6272372007369995, 'learning_rate': 0.00015507484109083454, 'epoch': 0.6}\n",
            " 30% 3300/10838 [08:30<19:07,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:04\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5767, 'grad_norm': 1.4227409362792969, 'learning_rate': 0.00015456223087963913, 'epoch': 0.61}\u001b[0m\n",
            "{'loss': 2.5767, 'grad_norm': 1.4227409362792969, 'learning_rate': 0.00015456223087963913, 'epoch': 0.61}\n",
            " 31% 3325/10838 [08:34<18:59,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4775, 'grad_norm': 1.9332821369171143, 'learning_rate': 0.00015404962066844374, 'epoch': 0.61}\u001b[0m\n",
            "{'loss': 2.4775, 'grad_norm': 1.9332821369171143, 'learning_rate': 0.00015404962066844374, 'epoch': 0.61}\n",
            " 31% 3350/10838 [08:38<18:55,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.525, 'grad_norm': 1.7071151733398438, 'learning_rate': 0.0001535370104572483, 'epoch': 0.62}\u001b[0m\n",
            "{'loss': 2.525, 'grad_norm': 1.7071151733398438, 'learning_rate': 0.0001535370104572483, 'epoch': 0.62}\n",
            " 31% 3375/10838 [08:42<18:54,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2154, 'grad_norm': 1.489615559577942, 'learning_rate': 0.0001530244002460529, 'epoch': 0.62}\u001b[0m\n",
            "{'loss': 2.2154, 'grad_norm': 1.489615559577942, 'learning_rate': 0.0001530244002460529, 'epoch': 0.62}\n",
            " 31% 3400/10838 [08:46<18:47,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:19\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.544, 'grad_norm': 1.7119760513305664, 'learning_rate': 0.0001525117900348575, 'epoch': 0.63}\u001b[0m\n",
            "{'loss': 2.544, 'grad_norm': 1.7119760513305664, 'learning_rate': 0.0001525117900348575, 'epoch': 0.63}\n",
            " 32% 3425/10838 [08:49<18:47,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4322, 'grad_norm': 1.6140453815460205, 'learning_rate': 0.00015199917982366208, 'epoch': 0.63}\u001b[0m\n",
            "{'loss': 2.4322, 'grad_norm': 1.6140453815460205, 'learning_rate': 0.00015199917982366208, 'epoch': 0.63}\n",
            " 32% 3450/10838 [08:54<24:54,  4.94it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4761, 'grad_norm': 1.2448376417160034, 'learning_rate': 0.00015148656961246667, 'epoch': 0.64}\u001b[0m\n",
            "{'loss': 2.4761, 'grad_norm': 1.2448376417160034, 'learning_rate': 0.00015148656961246667, 'epoch': 0.64}\n",
            " 32% 3475/10838 [08:57<18:36,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:31\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5054, 'grad_norm': 1.6598525047302246, 'learning_rate': 0.00015097395940127128, 'epoch': 0.64}\u001b[0m\n",
            "{'loss': 2.5054, 'grad_norm': 1.6598525047302246, 'learning_rate': 0.00015097395940127128, 'epoch': 0.64}\n",
            " 32% 3500/10838 [09:01<18:32,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5092, 'grad_norm': 2.063145875930786, 'learning_rate': 0.0001504613491900759, 'epoch': 0.65}\u001b[0m\n",
            "{'loss': 2.5092, 'grad_norm': 2.063145875930786, 'learning_rate': 0.0001504613491900759, 'epoch': 0.65}\n",
            " 33% 3525/10838 [09:05<18:30,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4225, 'grad_norm': 1.3958808183670044, 'learning_rate': 0.00014994873897888046, 'epoch': 0.65}\u001b[0m\n",
            "{'loss': 2.4225, 'grad_norm': 1.3958808183670044, 'learning_rate': 0.00014994873897888046, 'epoch': 0.65}\n",
            " 33% 3550/10838 [09:09<18:24,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3642, 'grad_norm': 1.6250395774841309, 'learning_rate': 0.00014943612876768507, 'epoch': 0.66}\u001b[0m\n",
            "{'loss': 2.3642, 'grad_norm': 1.6250395774841309, 'learning_rate': 0.00014943612876768507, 'epoch': 0.66}\n",
            " 33% 3575/10838 [09:13<18:20,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4929, 'grad_norm': 1.4321036338806152, 'learning_rate': 0.00014892351855648966, 'epoch': 0.66}\u001b[0m\n",
            "{'loss': 2.4929, 'grad_norm': 1.4321036338806152, 'learning_rate': 0.00014892351855648966, 'epoch': 0.66}\n",
            " 33% 3600/10838 [09:17<18:19,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:50\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5291, 'grad_norm': 2.0724146366119385, 'learning_rate': 0.00014841090834529424, 'epoch': 0.66}\u001b[0m\n",
            "{'loss': 2.5291, 'grad_norm': 2.0724146366119385, 'learning_rate': 0.00014841090834529424, 'epoch': 0.66}\n",
            " 33% 3625/10838 [09:20<18:15,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5008, 'grad_norm': 1.6424646377563477, 'learning_rate': 0.00014789829813409883, 'epoch': 0.67}\u001b[0m\n",
            "{'loss': 2.5008, 'grad_norm': 1.6424646377563477, 'learning_rate': 0.00014789829813409883, 'epoch': 0.67}\n",
            " 34% 3650/10838 [09:24<18:08,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:12:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5394, 'grad_norm': 1.6971657276153564, 'learning_rate': 0.00014738568792290344, 'epoch': 0.67}\u001b[0m\n",
            "{'loss': 2.5394, 'grad_norm': 1.6971657276153564, 'learning_rate': 0.00014738568792290344, 'epoch': 0.67}\n",
            " 34% 3675/10838 [09:28<18:08,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3879, 'grad_norm': 1.8383874893188477, 'learning_rate': 0.00014687307771170803, 'epoch': 0.68}\u001b[0m\n",
            "{'loss': 2.3879, 'grad_norm': 1.8383874893188477, 'learning_rate': 0.00014687307771170803, 'epoch': 0.68}\n",
            " 34% 3700/10838 [09:32<18:01,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4492, 'grad_norm': 1.4785765409469604, 'learning_rate': 0.00014636046750051261, 'epoch': 0.68}\u001b[0m\n",
            "{'loss': 2.4492, 'grad_norm': 1.4785765409469604, 'learning_rate': 0.00014636046750051261, 'epoch': 0.68}\n",
            " 34% 3725/10838 [09:36<18:00,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2312, 'grad_norm': 1.3415011167526245, 'learning_rate': 0.0001458478572893172, 'epoch': 0.69}\u001b[0m\n",
            "{'loss': 2.2312, 'grad_norm': 1.3415011167526245, 'learning_rate': 0.0001458478572893172, 'epoch': 0.69}\n",
            " 35% 3750/10838 [09:40<17:57,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5093, 'grad_norm': 1.7181841135025024, 'learning_rate': 0.00014533524707812181, 'epoch': 0.69}\u001b[0m\n",
            "{'loss': 2.5093, 'grad_norm': 1.7181841135025024, 'learning_rate': 0.00014533524707812181, 'epoch': 0.69}\n",
            " 35% 3775/10838 [09:44<17:50,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6197, 'grad_norm': 1.698586106300354, 'learning_rate': 0.00014482263686692637, 'epoch': 0.7}\u001b[0m\n",
            "{'loss': 2.6197, 'grad_norm': 1.698586106300354, 'learning_rate': 0.00014482263686692637, 'epoch': 0.7}\n",
            " 35% 3800/10838 [09:48<17:48,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:21\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5009, 'grad_norm': 2.1136579513549805, 'learning_rate': 0.000144310026655731, 'epoch': 0.7}\u001b[0m\n",
            "{'loss': 2.5009, 'grad_norm': 2.1136579513549805, 'learning_rate': 0.000144310026655731, 'epoch': 0.7}\n",
            " 35% 3825/10838 [09:51<17:51,  6.55it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:25\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4114, 'grad_norm': 1.8360499143600464, 'learning_rate': 0.0001437974164445356, 'epoch': 0.71}\u001b[0m\n",
            "{'loss': 2.4114, 'grad_norm': 1.8360499143600464, 'learning_rate': 0.0001437974164445356, 'epoch': 0.71}\n",
            " 36% 3850/10838 [09:55<17:39,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4732, 'grad_norm': 1.7356034517288208, 'learning_rate': 0.00014328480623334019, 'epoch': 0.71}\u001b[0m\n",
            "{'loss': 2.4732, 'grad_norm': 1.7356034517288208, 'learning_rate': 0.00014328480623334019, 'epoch': 0.71}\n",
            " 36% 3875/10838 [09:59<17:36,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:33\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3934, 'grad_norm': 1.9193297624588013, 'learning_rate': 0.00014277219602214477, 'epoch': 0.72}\u001b[0m\n",
            "{'loss': 2.3934, 'grad_norm': 1.9193297624588013, 'learning_rate': 0.00014277219602214477, 'epoch': 0.72}\n",
            " 36% 3900/10838 [10:03<17:38,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2801, 'grad_norm': 1.4992318153381348, 'learning_rate': 0.00014225958581094936, 'epoch': 0.72}\u001b[0m\n",
            "{'loss': 2.2801, 'grad_norm': 1.4992318153381348, 'learning_rate': 0.00014225958581094936, 'epoch': 0.72}\n",
            " 36% 3925/10838 [10:07<17:30,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4765, 'grad_norm': 1.5332188606262207, 'learning_rate': 0.00014174697559975397, 'epoch': 0.72}\u001b[0m\n",
            "{'loss': 2.4765, 'grad_norm': 1.5332188606262207, 'learning_rate': 0.00014174697559975397, 'epoch': 0.72}\n",
            " 36% 3950/10838 [10:11<17:25,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2567, 'grad_norm': 1.3204379081726074, 'learning_rate': 0.00014123436538855853, 'epoch': 0.73}\u001b[0m\n",
            "{'loss': 2.2567, 'grad_norm': 1.3204379081726074, 'learning_rate': 0.00014123436538855853, 'epoch': 0.73}\n",
            " 37% 3975/10838 [10:15<17:22,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3954, 'grad_norm': 1.5741968154907227, 'learning_rate': 0.00014072175517736314, 'epoch': 0.73}\u001b[0m\n",
            "{'loss': 2.3954, 'grad_norm': 1.5741968154907227, 'learning_rate': 0.00014072175517736314, 'epoch': 0.73}\n",
            " 37% 4000/10838 [10:19<17:16,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6097, 'grad_norm': 1.459770679473877, 'learning_rate': 0.00014020914496616773, 'epoch': 0.74}\u001b[0m\n",
            "{'loss': 2.6097, 'grad_norm': 1.459770679473877, 'learning_rate': 0.00014020914496616773, 'epoch': 0.74}\n",
            " 37% 4025/10838 [10:22<17:16,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:13:56\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2567, 'grad_norm': 1.4324700832366943, 'learning_rate': 0.00013969653475497232, 'epoch': 0.74}\u001b[0m\n",
            "{'loss': 2.2567, 'grad_norm': 1.4324700832366943, 'learning_rate': 0.00013969653475497232, 'epoch': 0.74}\n",
            " 37% 4050/10838 [10:26<17:12,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:00\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4889, 'grad_norm': 1.7284055948257446, 'learning_rate': 0.0001391839245437769, 'epoch': 0.75}\u001b[0m\n",
            "{'loss': 2.4889, 'grad_norm': 1.7284055948257446, 'learning_rate': 0.0001391839245437769, 'epoch': 0.75}\n",
            " 38% 4075/10838 [10:30<17:06,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:04\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4996, 'grad_norm': 1.5653834342956543, 'learning_rate': 0.00013867131433258152, 'epoch': 0.75}\u001b[0m\n",
            "{'loss': 2.4996, 'grad_norm': 1.5653834342956543, 'learning_rate': 0.00013867131433258152, 'epoch': 0.75}\n",
            " 38% 4100/10838 [10:34<17:01,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1931, 'grad_norm': 2.005552291870117, 'learning_rate': 0.0001381587041213861, 'epoch': 0.76}\u001b[0m\n",
            "{'loss': 2.1931, 'grad_norm': 2.005552291870117, 'learning_rate': 0.0001381587041213861, 'epoch': 0.76}\n",
            " 38% 4125/10838 [10:38<16:58,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3515, 'grad_norm': 1.1817413568496704, 'learning_rate': 0.0001376460939101907, 'epoch': 0.76}\u001b[0m\n",
            "{'loss': 2.3515, 'grad_norm': 1.1817413568496704, 'learning_rate': 0.0001376460939101907, 'epoch': 0.76}\n",
            " 38% 4150/10838 [10:42<16:58,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2909, 'grad_norm': 1.6986089944839478, 'learning_rate': 0.00013713348369899528, 'epoch': 0.77}\u001b[0m\n",
            "{'loss': 2.2909, 'grad_norm': 1.6986089944839478, 'learning_rate': 0.00013713348369899528, 'epoch': 0.77}\n",
            " 39% 4175/10838 [10:46<16:51,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:19\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5553, 'grad_norm': 2.022167682647705, 'learning_rate': 0.0001366208734877999, 'epoch': 0.77}\u001b[0m\n",
            "{'loss': 2.5553, 'grad_norm': 2.022167682647705, 'learning_rate': 0.0001366208734877999, 'epoch': 0.77}\n",
            " 39% 4200/10838 [10:49<16:47,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4647, 'grad_norm': 1.5439187288284302, 'learning_rate': 0.00013610826327660448, 'epoch': 0.78}\u001b[0m\n",
            "{'loss': 2.4647, 'grad_norm': 1.5439187288284302, 'learning_rate': 0.00013610826327660448, 'epoch': 0.78}\n",
            " 39% 4225/10838 [10:53<16:43,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6237, 'grad_norm': 1.6937751770019531, 'learning_rate': 0.00013559565306540906, 'epoch': 0.78}\u001b[0m\n",
            "{'loss': 2.6237, 'grad_norm': 1.6937751770019531, 'learning_rate': 0.00013559565306540906, 'epoch': 0.78}\n",
            " 39% 4250/10838 [10:57<16:39,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:31\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3318, 'grad_norm': 1.5143271684646606, 'learning_rate': 0.00013508304285421367, 'epoch': 0.78}\u001b[0m\n",
            "{'loss': 2.3318, 'grad_norm': 1.5143271684646606, 'learning_rate': 0.00013508304285421367, 'epoch': 0.78}\n",
            " 39% 4275/10838 [11:01<16:36,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4454, 'grad_norm': 2.0016257762908936, 'learning_rate': 0.00013457043264301826, 'epoch': 0.79}\u001b[0m\n",
            "{'loss': 2.4454, 'grad_norm': 2.0016257762908936, 'learning_rate': 0.00013457043264301826, 'epoch': 0.79}\n",
            " 40% 4300/10838 [11:05<16:31,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3169, 'grad_norm': 1.6728770732879639, 'learning_rate': 0.00013405782243182285, 'epoch': 0.79}\u001b[0m\n",
            "{'loss': 2.3169, 'grad_norm': 1.6728770732879639, 'learning_rate': 0.00013405782243182285, 'epoch': 0.79}\n",
            " 40% 4325/10838 [11:09<16:28,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4566, 'grad_norm': 1.8058689832687378, 'learning_rate': 0.00013354521222062743, 'epoch': 0.8}\u001b[0m\n",
            "{'loss': 2.4566, 'grad_norm': 1.8058689832687378, 'learning_rate': 0.00013354521222062743, 'epoch': 0.8}\n",
            " 40% 4350/10838 [11:13<16:26,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:46\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3907, 'grad_norm': 1.5653585195541382, 'learning_rate': 0.00013303260200943205, 'epoch': 0.8}\u001b[0m\n",
            "{'loss': 2.3907, 'grad_norm': 1.5653585195541382, 'learning_rate': 0.00013303260200943205, 'epoch': 0.8}\n",
            " 40% 4375/10838 [11:16<16:20,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:50\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2684, 'grad_norm': 2.693507432937622, 'learning_rate': 0.00013251999179823663, 'epoch': 0.81}\u001b[0m\n",
            "{'loss': 2.2684, 'grad_norm': 2.693507432937622, 'learning_rate': 0.00013251999179823663, 'epoch': 0.81}\n",
            " 41% 4400/10838 [11:20<16:17,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4949, 'grad_norm': 1.472434401512146, 'learning_rate': 0.00013200738158704122, 'epoch': 0.81}\u001b[0m\n",
            "{'loss': 2.4949, 'grad_norm': 1.472434401512146, 'learning_rate': 0.00013200738158704122, 'epoch': 0.81}\n",
            " 41% 4425/10838 [11:24<16:13,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:14:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3519, 'grad_norm': 1.316413402557373, 'learning_rate': 0.0001314947713758458, 'epoch': 0.82}\u001b[0m\n",
            "{'loss': 2.3519, 'grad_norm': 1.316413402557373, 'learning_rate': 0.0001314947713758458, 'epoch': 0.82}\n",
            " 41% 4450/10838 [11:28<16:12,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3551, 'grad_norm': 1.436477541923523, 'learning_rate': 0.00013098216116465042, 'epoch': 0.82}\u001b[0m\n",
            "{'loss': 2.3551, 'grad_norm': 1.436477541923523, 'learning_rate': 0.00013098216116465042, 'epoch': 0.82}\n",
            " 41% 4475/10838 [11:32<16:05,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3501, 'grad_norm': 1.8486865758895874, 'learning_rate': 0.00013046955095345498, 'epoch': 0.83}\u001b[0m\n",
            "{'loss': 2.3501, 'grad_norm': 1.8486865758895874, 'learning_rate': 0.00013046955095345498, 'epoch': 0.83}\n",
            " 42% 4500/10838 [11:36<16:01,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:09\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.466, 'grad_norm': 2.181619644165039, 'learning_rate': 0.0001299569407422596, 'epoch': 0.83}\u001b[0m\n",
            "{'loss': 2.466, 'grad_norm': 2.181619644165039, 'learning_rate': 0.0001299569407422596, 'epoch': 0.83}\n",
            " 42% 4525/10838 [11:39<15:58,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:13\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3178, 'grad_norm': 1.623288631439209, 'learning_rate': 0.0001294443305310642, 'epoch': 0.84}\u001b[0m\n",
            "{'loss': 2.3178, 'grad_norm': 1.623288631439209, 'learning_rate': 0.0001294443305310642, 'epoch': 0.84}\n",
            " 42% 4550/10838 [11:43<15:55,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:17\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1775, 'grad_norm': 1.851624608039856, 'learning_rate': 0.00012893172031986876, 'epoch': 0.84}\u001b[0m\n",
            "{'loss': 2.1775, 'grad_norm': 1.851624608039856, 'learning_rate': 0.00012893172031986876, 'epoch': 0.84}\n",
            " 42% 4575/10838 [11:47<15:50,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:21\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3615, 'grad_norm': 1.7794113159179688, 'learning_rate': 0.00012841911010867338, 'epoch': 0.84}\u001b[0m\n",
            "{'loss': 2.3615, 'grad_norm': 1.7794113159179688, 'learning_rate': 0.00012841911010867338, 'epoch': 0.84}\n",
            " 42% 4600/10838 [11:51<15:47,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:25\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4068, 'grad_norm': 1.8194113969802856, 'learning_rate': 0.00012790649989747796, 'epoch': 0.85}\u001b[0m\n",
            "{'loss': 2.4068, 'grad_norm': 1.8194113969802856, 'learning_rate': 0.00012790649989747796, 'epoch': 0.85}\n",
            " 43% 4625/10838 [11:55<15:43,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2027, 'grad_norm': 1.527309775352478, 'learning_rate': 0.00012739388968628258, 'epoch': 0.85}\u001b[0m\n",
            "{'loss': 2.2027, 'grad_norm': 1.527309775352478, 'learning_rate': 0.00012739388968628258, 'epoch': 0.85}\n",
            " 43% 4650/10838 [11:59<15:39,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:33\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2943, 'grad_norm': 1.509421944618225, 'learning_rate': 0.00012688127947508714, 'epoch': 0.86}\u001b[0m\n",
            "{'loss': 2.2943, 'grad_norm': 1.509421944618225, 'learning_rate': 0.00012688127947508714, 'epoch': 0.86}\n",
            " 43% 4675/10838 [12:03<15:35,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2914, 'grad_norm': 2.073530673980713, 'learning_rate': 0.00012636866926389175, 'epoch': 0.86}\u001b[0m\n",
            "{'loss': 2.2914, 'grad_norm': 2.073530673980713, 'learning_rate': 0.00012636866926389175, 'epoch': 0.86}\n",
            " 43% 4700/10838 [12:07<15:32,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.349, 'grad_norm': 1.76697838306427, 'learning_rate': 0.00012585605905269634, 'epoch': 0.87}\u001b[0m\n",
            "{'loss': 2.349, 'grad_norm': 1.76697838306427, 'learning_rate': 0.00012585605905269634, 'epoch': 0.87}\n",
            " 44% 4725/10838 [12:10<15:26,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:44\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.6073, 'grad_norm': 1.5176289081573486, 'learning_rate': 0.00012534344884150092, 'epoch': 0.87}\u001b[0m\n",
            "{'loss': 2.6073, 'grad_norm': 1.5176289081573486, 'learning_rate': 0.00012534344884150092, 'epoch': 0.87}\n",
            " 44% 4750/10838 [12:14<15:28,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:48\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1891, 'grad_norm': 1.2918956279754639, 'learning_rate': 0.0001248308386303055, 'epoch': 0.88}\u001b[0m\n",
            "{'loss': 2.1891, 'grad_norm': 1.2918956279754639, 'learning_rate': 0.0001248308386303055, 'epoch': 0.88}\n",
            " 44% 4775/10838 [12:18<15:22,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3602, 'grad_norm': 1.510186791419983, 'learning_rate': 0.00012431822841911012, 'epoch': 0.88}\u001b[0m\n",
            "{'loss': 2.3602, 'grad_norm': 1.510186791419983, 'learning_rate': 0.00012431822841911012, 'epoch': 0.88}\n",
            " 44% 4800/10838 [12:22<15:15,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:15:56\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4688, 'grad_norm': 1.6644868850708008, 'learning_rate': 0.0001238056182079147, 'epoch': 0.89}\u001b[0m\n",
            "{'loss': 2.4688, 'grad_norm': 1.6644868850708008, 'learning_rate': 0.0001238056182079147, 'epoch': 0.89}\n",
            " 45% 4825/10838 [12:26<15:14,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:00\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4275, 'grad_norm': 1.6234561204910278, 'learning_rate': 0.0001232930079967193, 'epoch': 0.89}\u001b[0m\n",
            "{'loss': 2.4275, 'grad_norm': 1.6234561204910278, 'learning_rate': 0.0001232930079967193, 'epoch': 0.89}\n",
            " 45% 4850/10838 [12:30<15:11,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:04\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1702, 'grad_norm': 1.2579511404037476, 'learning_rate': 0.0001227803977855239, 'epoch': 0.89}\u001b[0m\n",
            "{'loss': 2.1702, 'grad_norm': 1.2579511404037476, 'learning_rate': 0.0001227803977855239, 'epoch': 0.89}\n",
            " 45% 4875/10838 [12:34<15:04,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:07\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4004, 'grad_norm': 1.6969821453094482, 'learning_rate': 0.0001222677875743285, 'epoch': 0.9}\u001b[0m\n",
            "{'loss': 2.4004, 'grad_norm': 1.6969821453094482, 'learning_rate': 0.0001222677875743285, 'epoch': 0.9}\n",
            " 45% 4900/10838 [12:37<15:02,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2286, 'grad_norm': 1.5956913232803345, 'learning_rate': 0.0001217551773631331, 'epoch': 0.9}\u001b[0m\n",
            "{'loss': 2.2286, 'grad_norm': 1.5956913232803345, 'learning_rate': 0.0001217551773631331, 'epoch': 0.9}\n",
            " 45% 4925/10838 [12:41<14:58,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:15\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.5384, 'grad_norm': 1.465860366821289, 'learning_rate': 0.00012124256715193767, 'epoch': 0.91}\u001b[0m\n",
            "{'loss': 2.5384, 'grad_norm': 1.465860366821289, 'learning_rate': 0.00012124256715193767, 'epoch': 0.91}\n",
            " 46% 4950/10838 [12:45<14:55,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:19\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3257, 'grad_norm': 1.6090261936187744, 'learning_rate': 0.00012072995694074227, 'epoch': 0.91}\u001b[0m\n",
            "{'loss': 2.3257, 'grad_norm': 1.6090261936187744, 'learning_rate': 0.00012072995694074227, 'epoch': 0.91}\n",
            " 46% 4975/10838 [12:49<14:50,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3779, 'grad_norm': 1.451322078704834, 'learning_rate': 0.00012021734672954685, 'epoch': 0.92}\u001b[0m\n",
            "{'loss': 2.3779, 'grad_norm': 1.451322078704834, 'learning_rate': 0.00012021734672954685, 'epoch': 0.92}\n",
            " 46% 5000/10838 [12:53<14:47,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2161, 'grad_norm': 1.9379212856292725, 'learning_rate': 0.00011970473651835145, 'epoch': 0.92}\u001b[0m\n",
            "{'loss': 2.2161, 'grad_norm': 1.9379212856292725, 'learning_rate': 0.00011970473651835145, 'epoch': 0.92}\n",
            " 46% 5025/10838 [12:57<14:43,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:31\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2168, 'grad_norm': 1.8532997369766235, 'learning_rate': 0.00011919212630715604, 'epoch': 0.93}\u001b[0m\n",
            "{'loss': 2.2168, 'grad_norm': 1.8532997369766235, 'learning_rate': 0.00011919212630715604, 'epoch': 0.93}\n",
            " 47% 5050/10838 [13:01<14:40,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4127, 'grad_norm': 1.647437334060669, 'learning_rate': 0.00011867951609596064, 'epoch': 0.93}\u001b[0m\n",
            "{'loss': 2.4127, 'grad_norm': 1.647437334060669, 'learning_rate': 0.00011867951609596064, 'epoch': 0.93}\n",
            " 47% 5075/10838 [13:05<14:35,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4521, 'grad_norm': 1.3463828563690186, 'learning_rate': 0.00011816690588476522, 'epoch': 0.94}\u001b[0m\n",
            "{'loss': 2.4521, 'grad_norm': 1.3463828563690186, 'learning_rate': 0.00011816690588476522, 'epoch': 0.94}\n",
            " 47% 5100/10838 [13:08<14:30,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:42\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.4026, 'grad_norm': 1.5501136779785156, 'learning_rate': 0.00011765429567356982, 'epoch': 0.94}\u001b[0m\n",
            "{'loss': 2.4026, 'grad_norm': 1.5501136779785156, 'learning_rate': 0.00011765429567356982, 'epoch': 0.94}\n",
            " 47% 5125/10838 [13:12<14:27,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:46\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3976, 'grad_norm': 1.5533064603805542, 'learning_rate': 0.00011714168546237441, 'epoch': 0.95}\u001b[0m\n",
            "{'loss': 2.3976, 'grad_norm': 1.5533064603805542, 'learning_rate': 0.00011714168546237441, 'epoch': 0.95}\n",
            " 48% 5150/10838 [13:16<14:24,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:50\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3769, 'grad_norm': 1.5052615404129028, 'learning_rate': 0.00011662907525117901, 'epoch': 0.95}\u001b[0m\n",
            "{'loss': 2.3769, 'grad_norm': 1.5052615404129028, 'learning_rate': 0.00011662907525117901, 'epoch': 0.95}\n",
            " 48% 5175/10838 [13:20<14:22,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3056, 'grad_norm': 1.836876630783081, 'learning_rate': 0.00011611646503998361, 'epoch': 0.95}\u001b[0m\n",
            "{'loss': 2.3056, 'grad_norm': 1.836876630783081, 'learning_rate': 0.00011611646503998361, 'epoch': 0.95}\n",
            " 48% 5200/10838 [13:24<14:17,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:16:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3767, 'grad_norm': 1.3688116073608398, 'learning_rate': 0.0001156038548287882, 'epoch': 0.96}\u001b[0m\n",
            "{'loss': 2.3767, 'grad_norm': 1.3688116073608398, 'learning_rate': 0.0001156038548287882, 'epoch': 0.96}\n",
            " 48% 5225/10838 [13:28<14:15,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2568, 'grad_norm': 1.661211371421814, 'learning_rate': 0.0001150912446175928, 'epoch': 0.96}\u001b[0m\n",
            "{'loss': 2.2568, 'grad_norm': 1.661211371421814, 'learning_rate': 0.0001150912446175928, 'epoch': 0.96}\n",
            " 48% 5250/10838 [13:32<16:18,  5.71it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0461, 'grad_norm': 1.7009499073028564, 'learning_rate': 0.00011457863440639738, 'epoch': 0.97}\u001b[0m\n",
            "{'loss': 2.0461, 'grad_norm': 1.7009499073028564, 'learning_rate': 0.00011457863440639738, 'epoch': 0.97}\n",
            " 49% 5275/10838 [13:36<14:06,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.233, 'grad_norm': 1.5983742475509644, 'learning_rate': 0.00011406602419520198, 'epoch': 0.97}\u001b[0m\n",
            "{'loss': 2.233, 'grad_norm': 1.5983742475509644, 'learning_rate': 0.00011406602419520198, 'epoch': 0.97}\n",
            " 49% 5300/10838 [13:40<14:01,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:13\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3819, 'grad_norm': 1.7307186126708984, 'learning_rate': 0.00011355341398400657, 'epoch': 0.98}\u001b[0m\n",
            "{'loss': 2.3819, 'grad_norm': 1.7307186126708984, 'learning_rate': 0.00011355341398400657, 'epoch': 0.98}\n",
            " 49% 5325/10838 [13:43<14:00,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:17\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3237, 'grad_norm': 1.3197548389434814, 'learning_rate': 0.00011304080377281117, 'epoch': 0.98}\u001b[0m\n",
            "{'loss': 2.3237, 'grad_norm': 1.3197548389434814, 'learning_rate': 0.00011304080377281117, 'epoch': 0.98}\n",
            " 49% 5350/10838 [13:47<13:57,  6.55it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:21\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.317, 'grad_norm': 1.5859460830688477, 'learning_rate': 0.00011252819356161574, 'epoch': 0.99}\u001b[0m\n",
            "{'loss': 2.317, 'grad_norm': 1.5859460830688477, 'learning_rate': 0.00011252819356161574, 'epoch': 0.99}\n",
            " 50% 5375/10838 [13:51<13:51,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:25\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2929, 'grad_norm': 1.7177228927612305, 'learning_rate': 0.00011201558335042035, 'epoch': 0.99}\u001b[0m\n",
            "{'loss': 2.2929, 'grad_norm': 1.7177228927612305, 'learning_rate': 0.00011201558335042035, 'epoch': 0.99}\n",
            " 50% 5400/10838 [13:55<13:44,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.463, 'grad_norm': 1.6208949089050293, 'learning_rate': 0.00011150297313922493, 'epoch': 1.0}\u001b[0m\n",
            "{'loss': 2.463, 'grad_norm': 1.6208949089050293, 'learning_rate': 0.00011150297313922493, 'epoch': 1.0}\n",
            " 50% 5425/10838 [14:06<45:50,  1.97it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3645, 'grad_norm': 1.4512284994125366, 'learning_rate': 0.00011099036292802954, 'epoch': 1.0}\u001b[0m\n",
            "{'loss': 2.3645, 'grad_norm': 1.4512284994125366, 'learning_rate': 0.00011099036292802954, 'epoch': 1.0}\n",
            " 50% 5450/10838 [14:10<13:40,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:44\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8924, 'grad_norm': 1.726116418838501, 'learning_rate': 0.00011047775271683411, 'epoch': 1.01}\u001b[0m\n",
            "{'loss': 1.8924, 'grad_norm': 1.726116418838501, 'learning_rate': 0.00011047775271683411, 'epoch': 1.01}\n",
            " 51% 5475/10838 [14:14<13:33,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1101, 'grad_norm': 1.2219786643981934, 'learning_rate': 0.00010996514250563871, 'epoch': 1.01}\u001b[0m\n",
            "{'loss': 2.1101, 'grad_norm': 1.2219786643981934, 'learning_rate': 0.00010996514250563871, 'epoch': 1.01}\n",
            " 51% 5500/10838 [14:17<13:29,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:51\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1947, 'grad_norm': 1.4831534624099731, 'learning_rate': 0.0001094525322944433, 'epoch': 1.01}\u001b[0m\n",
            "{'loss': 2.1947, 'grad_norm': 1.4831534624099731, 'learning_rate': 0.0001094525322944433, 'epoch': 1.01}\n",
            " 51% 5525/10838 [14:21<13:30,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:55\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.209, 'grad_norm': 1.5442945957183838, 'learning_rate': 0.0001089399220832479, 'epoch': 1.02}\u001b[0m\n",
            "{'loss': 2.209, 'grad_norm': 1.5442945957183838, 'learning_rate': 0.0001089399220832479, 'epoch': 1.02}\n",
            " 51% 5550/10838 [14:25<13:23,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:17:59\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1597, 'grad_norm': 2.224853754043579, 'learning_rate': 0.00010842731187205251, 'epoch': 1.02}\u001b[0m\n",
            "{'loss': 2.1597, 'grad_norm': 2.224853754043579, 'learning_rate': 0.00010842731187205251, 'epoch': 1.02}\n",
            " 51% 5575/10838 [14:29<13:17,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:03\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0239, 'grad_norm': 1.4685598611831665, 'learning_rate': 0.00010791470166085709, 'epoch': 1.03}\u001b[0m\n",
            "{'loss': 2.0239, 'grad_norm': 1.4685598611831665, 'learning_rate': 0.00010791470166085709, 'epoch': 1.03}\n",
            " 52% 5600/10838 [14:33<13:15,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:07\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1913, 'grad_norm': 1.9340946674346924, 'learning_rate': 0.00010740209144966169, 'epoch': 1.03}\u001b[0m\n",
            "{'loss': 2.1913, 'grad_norm': 1.9340946674346924, 'learning_rate': 0.00010740209144966169, 'epoch': 1.03}\n",
            " 52% 5625/10838 [14:37<13:11,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2007, 'grad_norm': 2.8342645168304443, 'learning_rate': 0.00010688948123846627, 'epoch': 1.04}\u001b[0m\n",
            "{'loss': 2.2007, 'grad_norm': 2.8342645168304443, 'learning_rate': 0.00010688948123846627, 'epoch': 1.04}\n",
            " 52% 5650/10838 [14:41<13:09,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:15\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2824, 'grad_norm': 1.3501911163330078, 'learning_rate': 0.00010637687102727087, 'epoch': 1.04}\u001b[0m\n",
            "{'loss': 2.2824, 'grad_norm': 1.3501911163330078, 'learning_rate': 0.00010637687102727087, 'epoch': 1.04}\n",
            " 52% 5675/10838 [14:45<13:05,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3294, 'grad_norm': 1.4995099306106567, 'learning_rate': 0.00010586426081607546, 'epoch': 1.05}\u001b[0m\n",
            "{'loss': 2.3294, 'grad_norm': 1.4995099306106567, 'learning_rate': 0.00010586426081607546, 'epoch': 1.05}\n",
            " 53% 5700/10838 [14:48<13:00,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0666, 'grad_norm': 1.464556097984314, 'learning_rate': 0.00010535165060488006, 'epoch': 1.05}\u001b[0m\n",
            "{'loss': 2.0666, 'grad_norm': 1.464556097984314, 'learning_rate': 0.00010535165060488006, 'epoch': 1.05}\n",
            " 53% 5725/10838 [14:52<12:55,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2057, 'grad_norm': 1.7416380643844604, 'learning_rate': 0.00010483904039368464, 'epoch': 1.06}\u001b[0m\n",
            "{'loss': 2.2057, 'grad_norm': 1.7416380643844604, 'learning_rate': 0.00010483904039368464, 'epoch': 1.06}\n",
            " 53% 5750/10838 [14:56<12:55,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:30\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2002, 'grad_norm': 1.5230633020401, 'learning_rate': 0.00010432643018248924, 'epoch': 1.06}\u001b[0m\n",
            "{'loss': 2.2002, 'grad_norm': 1.5230633020401, 'learning_rate': 0.00010432643018248924, 'epoch': 1.06}\n",
            " 53% 5775/10838 [15:00<12:48,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:34\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0736, 'grad_norm': 1.8480249643325806, 'learning_rate': 0.00010381381997129383, 'epoch': 1.07}\u001b[0m\n",
            "{'loss': 2.0736, 'grad_norm': 1.8480249643325806, 'learning_rate': 0.00010381381997129383, 'epoch': 1.07}\n",
            " 54% 5800/10838 [15:04<12:45,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1085, 'grad_norm': 1.6102162599563599, 'learning_rate': 0.00010330120976009843, 'epoch': 1.07}\u001b[0m\n",
            "{'loss': 2.1085, 'grad_norm': 1.6102162599563599, 'learning_rate': 0.00010330120976009843, 'epoch': 1.07}\n",
            " 54% 5825/10838 [15:08<12:41,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0165, 'grad_norm': 1.5275218486785889, 'learning_rate': 0.000102788599548903, 'epoch': 1.07}\u001b[0m\n",
            "{'loss': 2.0165, 'grad_norm': 1.5275218486785889, 'learning_rate': 0.000102788599548903, 'epoch': 1.07}\n",
            " 54% 5850/10838 [15:12<12:39,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0559, 'grad_norm': 1.8340710401535034, 'learning_rate': 0.00010227598933770762, 'epoch': 1.08}\u001b[0m\n",
            "{'loss': 2.0559, 'grad_norm': 1.8340710401535034, 'learning_rate': 0.00010227598933770762, 'epoch': 1.08}\n",
            " 54% 5875/10838 [15:15<12:32,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2142, 'grad_norm': 1.7018392086029053, 'learning_rate': 0.00010176337912651222, 'epoch': 1.08}\u001b[0m\n",
            "{'loss': 2.2142, 'grad_norm': 1.7018392086029053, 'learning_rate': 0.00010176337912651222, 'epoch': 1.08}\n",
            " 54% 5900/10838 [15:19<12:44,  6.46it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1469, 'grad_norm': 1.4462571144104004, 'learning_rate': 0.0001012507689153168, 'epoch': 1.09}\u001b[0m\n",
            "{'loss': 2.1469, 'grad_norm': 1.4462571144104004, 'learning_rate': 0.0001012507689153168, 'epoch': 1.09}\n",
            " 55% 5925/10838 [15:23<12:26,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:18:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2024, 'grad_norm': 1.431517481803894, 'learning_rate': 0.0001007381587041214, 'epoch': 1.09}\u001b[0m\n",
            "{'loss': 2.2024, 'grad_norm': 1.431517481803894, 'learning_rate': 0.0001007381587041214, 'epoch': 1.09}\n",
            " 55% 5950/10838 [15:27<12:22,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1133, 'grad_norm': 1.516266942024231, 'learning_rate': 0.00010022554849292597, 'epoch': 1.1}\u001b[0m\n",
            "{'loss': 2.1133, 'grad_norm': 1.516266942024231, 'learning_rate': 0.00010022554849292597, 'epoch': 1.1}\n",
            " 55% 5975/10838 [15:31<12:18,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:05\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.188, 'grad_norm': 1.7490724325180054, 'learning_rate': 9.971293828173057e-05, 'epoch': 1.1}\u001b[0m\n",
            "{'loss': 2.188, 'grad_norm': 1.7490724325180054, 'learning_rate': 9.971293828173057e-05, 'epoch': 1.1}\n",
            " 55% 6000/10838 [15:35<12:16,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:09\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2171, 'grad_norm': 1.6427342891693115, 'learning_rate': 9.920032807053516e-05, 'epoch': 1.11}\u001b[0m\n",
            "{'loss': 2.2171, 'grad_norm': 1.6427342891693115, 'learning_rate': 9.920032807053516e-05, 'epoch': 1.11}\n",
            " 56% 6025/10838 [15:39<12:10,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:13\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0441, 'grad_norm': 1.462891697883606, 'learning_rate': 9.868771785933977e-05, 'epoch': 1.11}\u001b[0m\n",
            "{'loss': 2.0441, 'grad_norm': 1.462891697883606, 'learning_rate': 9.868771785933977e-05, 'epoch': 1.11}\n",
            " 56% 6050/10838 [15:43<12:07,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2715, 'grad_norm': 1.1835355758666992, 'learning_rate': 9.817510764814436e-05, 'epoch': 1.12}\u001b[0m\n",
            "{'loss': 2.2715, 'grad_norm': 1.1835355758666992, 'learning_rate': 9.817510764814436e-05, 'epoch': 1.12}\n",
            " 56% 6075/10838 [15:46<12:03,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1506, 'grad_norm': 1.4953067302703857, 'learning_rate': 9.766249743694895e-05, 'epoch': 1.12}\u001b[0m\n",
            "{'loss': 2.1506, 'grad_norm': 1.4953067302703857, 'learning_rate': 9.766249743694895e-05, 'epoch': 1.12}\n",
            " 56% 6100/10838 [15:50<12:00,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:24\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1148, 'grad_norm': 1.4289515018463135, 'learning_rate': 9.714988722575355e-05, 'epoch': 1.13}\u001b[0m\n",
            "{'loss': 2.1148, 'grad_norm': 1.4289515018463135, 'learning_rate': 9.714988722575355e-05, 'epoch': 1.13}\n",
            " 57% 6125/10838 [15:54<11:58,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1196, 'grad_norm': 1.230056881904602, 'learning_rate': 9.663727701455813e-05, 'epoch': 1.13}\u001b[0m\n",
            "{'loss': 2.1196, 'grad_norm': 1.230056881904602, 'learning_rate': 9.663727701455813e-05, 'epoch': 1.13}\n",
            " 57% 6150/10838 [15:58<11:53,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:32\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.178, 'grad_norm': 1.5941392183303833, 'learning_rate': 9.612466680336273e-05, 'epoch': 1.13}\u001b[0m\n",
            "{'loss': 2.178, 'grad_norm': 1.5941392183303833, 'learning_rate': 9.612466680336273e-05, 'epoch': 1.13}\n",
            " 57% 6175/10838 [16:02<11:48,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:36\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2835, 'grad_norm': 1.2673616409301758, 'learning_rate': 9.561205659216732e-05, 'epoch': 1.14}\u001b[0m\n",
            "{'loss': 2.2835, 'grad_norm': 1.2673616409301758, 'learning_rate': 9.561205659216732e-05, 'epoch': 1.14}\n",
            " 57% 6200/10838 [16:06<11:44,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1874, 'grad_norm': 1.662606954574585, 'learning_rate': 9.509944638097192e-05, 'epoch': 1.14}\u001b[0m\n",
            "{'loss': 2.1874, 'grad_norm': 1.662606954574585, 'learning_rate': 9.509944638097192e-05, 'epoch': 1.14}\n",
            " 57% 6225/10838 [16:10<11:48,  6.51it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:44\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1089, 'grad_norm': 1.3691703081130981, 'learning_rate': 9.45868361697765e-05, 'epoch': 1.15}\u001b[0m\n",
            "{'loss': 2.1089, 'grad_norm': 1.3691703081130981, 'learning_rate': 9.45868361697765e-05, 'epoch': 1.15}\n",
            " 58% 6250/10838 [16:14<11:38,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1162, 'grad_norm': 1.7473161220550537, 'learning_rate': 9.407422595858109e-05, 'epoch': 1.15}\u001b[0m\n",
            "{'loss': 2.1162, 'grad_norm': 1.7473161220550537, 'learning_rate': 9.407422595858109e-05, 'epoch': 1.15}\n",
            " 58% 6275/10838 [16:17<11:32,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:51\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3455, 'grad_norm': 1.405504584312439, 'learning_rate': 9.356161574738569e-05, 'epoch': 1.16}\u001b[0m\n",
            "{'loss': 2.3455, 'grad_norm': 1.405504584312439, 'learning_rate': 9.356161574738569e-05, 'epoch': 1.16}\n",
            " 58% 6300/10838 [16:21<11:29,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:55\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0539, 'grad_norm': 1.1481682062149048, 'learning_rate': 9.304900553619028e-05, 'epoch': 1.16}\u001b[0m\n",
            "{'loss': 2.0539, 'grad_norm': 1.1481682062149048, 'learning_rate': 9.304900553619028e-05, 'epoch': 1.16}\n",
            " 58% 6325/10838 [16:25<11:25,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:19:59\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.165, 'grad_norm': 1.29965341091156, 'learning_rate': 9.253639532499488e-05, 'epoch': 1.17}\u001b[0m\n",
            "{'loss': 2.165, 'grad_norm': 1.29965341091156, 'learning_rate': 9.253639532499488e-05, 'epoch': 1.17}\n",
            " 59% 6350/10838 [16:29<11:21,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:03\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0202, 'grad_norm': 1.5807956457138062, 'learning_rate': 9.202378511379948e-05, 'epoch': 1.17}\u001b[0m\n",
            "{'loss': 2.0202, 'grad_norm': 1.5807956457138062, 'learning_rate': 9.202378511379948e-05, 'epoch': 1.17}\n",
            " 59% 6375/10838 [16:33<11:17,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:07\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0732, 'grad_norm': 1.184226632118225, 'learning_rate': 9.151117490260406e-05, 'epoch': 1.18}\u001b[0m\n",
            "{'loss': 2.0732, 'grad_norm': 1.184226632118225, 'learning_rate': 9.151117490260406e-05, 'epoch': 1.18}\n",
            " 59% 6400/10838 [16:37<11:14,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2423, 'grad_norm': 1.5212806463241577, 'learning_rate': 9.099856469140866e-05, 'epoch': 1.18}\u001b[0m\n",
            "{'loss': 2.2423, 'grad_norm': 1.5212806463241577, 'learning_rate': 9.099856469140866e-05, 'epoch': 1.18}\n",
            " 59% 6425/10838 [16:41<11:09,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:15\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0324, 'grad_norm': 1.554770588874817, 'learning_rate': 9.048595448021325e-05, 'epoch': 1.19}\u001b[0m\n",
            "{'loss': 2.0324, 'grad_norm': 1.554770588874817, 'learning_rate': 9.048595448021325e-05, 'epoch': 1.19}\n",
            " 60% 6450/10838 [16:45<11:06,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0759, 'grad_norm': 1.3594744205474854, 'learning_rate': 8.997334426901785e-05, 'epoch': 1.19}\u001b[0m\n",
            "{'loss': 2.0759, 'grad_norm': 1.3594744205474854, 'learning_rate': 8.997334426901785e-05, 'epoch': 1.19}\n",
            " 60% 6475/10838 [16:48<11:06,  6.55it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0378, 'grad_norm': 1.643194317817688, 'learning_rate': 8.946073405782243e-05, 'epoch': 1.19}\u001b[0m\n",
            "{'loss': 2.0378, 'grad_norm': 1.643194317817688, 'learning_rate': 8.946073405782243e-05, 'epoch': 1.19}\n",
            " 60% 6500/10838 [16:52<10:58,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0974, 'grad_norm': 1.4403473138809204, 'learning_rate': 8.894812384662703e-05, 'epoch': 1.2}\u001b[0m\n",
            "{'loss': 2.0974, 'grad_norm': 1.4403473138809204, 'learning_rate': 8.894812384662703e-05, 'epoch': 1.2}\n",
            " 60% 6525/10838 [16:56<10:55,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:30\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2553, 'grad_norm': 2.3894007205963135, 'learning_rate': 8.843551363543162e-05, 'epoch': 1.2}\u001b[0m\n",
            "{'loss': 2.2553, 'grad_norm': 2.3894007205963135, 'learning_rate': 8.843551363543162e-05, 'epoch': 1.2}\n",
            " 60% 6550/10838 [17:00<10:50,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:34\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3184, 'grad_norm': 1.8158880472183228, 'learning_rate': 8.792290342423621e-05, 'epoch': 1.21}\u001b[0m\n",
            "{'loss': 2.3184, 'grad_norm': 1.8158880472183228, 'learning_rate': 8.792290342423621e-05, 'epoch': 1.21}\n",
            " 61% 6575/10838 [17:04<10:48,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1633, 'grad_norm': 1.3928414583206177, 'learning_rate': 8.741029321304081e-05, 'epoch': 1.21}\u001b[0m\n",
            "{'loss': 2.1633, 'grad_norm': 1.3928414583206177, 'learning_rate': 8.741029321304081e-05, 'epoch': 1.21}\n",
            " 61% 6600/10838 [17:08<10:43,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:42\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9998, 'grad_norm': 1.5166120529174805, 'learning_rate': 8.68976830018454e-05, 'epoch': 1.22}\u001b[0m\n",
            "{'loss': 1.9998, 'grad_norm': 1.5166120529174805, 'learning_rate': 8.68976830018454e-05, 'epoch': 1.22}\n",
            " 61% 6625/10838 [17:12<10:39,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9227, 'grad_norm': 1.5284086465835571, 'learning_rate': 8.638507279064999e-05, 'epoch': 1.22}\u001b[0m\n",
            "{'loss': 1.9227, 'grad_norm': 1.5284086465835571, 'learning_rate': 8.638507279064999e-05, 'epoch': 1.22}\n",
            " 61% 6650/10838 [17:15<10:34,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0564, 'grad_norm': 1.287213683128357, 'learning_rate': 8.587246257945458e-05, 'epoch': 1.23}\u001b[0m\n",
            "{'loss': 2.0564, 'grad_norm': 1.287213683128357, 'learning_rate': 8.587246257945458e-05, 'epoch': 1.23}\n",
            " 62% 6675/10838 [17:19<10:31,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0924, 'grad_norm': 1.8068379163742065, 'learning_rate': 8.535985236825918e-05, 'epoch': 1.23}\u001b[0m\n",
            "{'loss': 2.0924, 'grad_norm': 1.8068379163742065, 'learning_rate': 8.535985236825918e-05, 'epoch': 1.23}\n",
            " 62% 6700/10838 [17:23<10:27,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:20:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0814, 'grad_norm': 1.5662423372268677, 'learning_rate': 8.484724215706378e-05, 'epoch': 1.24}\u001b[0m\n",
            "{'loss': 2.0814, 'grad_norm': 1.5662423372268677, 'learning_rate': 8.484724215706378e-05, 'epoch': 1.24}\n",
            " 62% 6725/10838 [17:27<10:23,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1483, 'grad_norm': 1.7715239524841309, 'learning_rate': 8.433463194586837e-05, 'epoch': 1.24}\u001b[0m\n",
            "{'loss': 2.1483, 'grad_norm': 1.7715239524841309, 'learning_rate': 8.433463194586837e-05, 'epoch': 1.24}\n",
            " 62% 6750/10838 [17:31<10:21,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:05\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9991, 'grad_norm': 1.4995903968811035, 'learning_rate': 8.382202173467297e-05, 'epoch': 1.25}\u001b[0m\n",
            "{'loss': 1.9991, 'grad_norm': 1.4995903968811035, 'learning_rate': 8.382202173467297e-05, 'epoch': 1.25}\n",
            " 63% 6775/10838 [17:35<10:16,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.919, 'grad_norm': 1.7468044757843018, 'learning_rate': 8.330941152347755e-05, 'epoch': 1.25}\u001b[0m\n",
            "{'loss': 1.919, 'grad_norm': 1.7468044757843018, 'learning_rate': 8.330941152347755e-05, 'epoch': 1.25}\n",
            " 63% 6800/10838 [17:38<10:11,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2199, 'grad_norm': 1.5261034965515137, 'learning_rate': 8.279680131228215e-05, 'epoch': 1.25}\u001b[0m\n",
            "{'loss': 2.2199, 'grad_norm': 1.5261034965515137, 'learning_rate': 8.279680131228215e-05, 'epoch': 1.25}\n",
            " 63% 6825/10838 [17:42<10:09,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0356, 'grad_norm': 1.648384690284729, 'learning_rate': 8.228419110108674e-05, 'epoch': 1.26}\u001b[0m\n",
            "{'loss': 2.0356, 'grad_norm': 1.648384690284729, 'learning_rate': 8.228419110108674e-05, 'epoch': 1.26}\n",
            " 63% 6850/10838 [17:46<10:03,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0055, 'grad_norm': 1.4742999076843262, 'learning_rate': 8.177158088989132e-05, 'epoch': 1.26}\u001b[0m\n",
            "{'loss': 2.0055, 'grad_norm': 1.4742999076843262, 'learning_rate': 8.177158088989132e-05, 'epoch': 1.26}\n",
            " 63% 6875/10838 [17:50<09:59,  6.61it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:24\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0957, 'grad_norm': 1.4308347702026367, 'learning_rate': 8.125897067869592e-05, 'epoch': 1.27}\u001b[0m\n",
            "{'loss': 2.0957, 'grad_norm': 1.4308347702026367, 'learning_rate': 8.125897067869592e-05, 'epoch': 1.27}\n",
            " 64% 6900/10838 [17:54<09:57,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2338, 'grad_norm': 1.1799482107162476, 'learning_rate': 8.074636046750051e-05, 'epoch': 1.27}\u001b[0m\n",
            "{'loss': 2.2338, 'grad_norm': 1.1799482107162476, 'learning_rate': 8.074636046750051e-05, 'epoch': 1.27}\n",
            " 64% 6925/10838 [17:58<09:53,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:32\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1063, 'grad_norm': 1.9463752508163452, 'learning_rate': 8.023375025630511e-05, 'epoch': 1.28}\u001b[0m\n",
            "{'loss': 2.1063, 'grad_norm': 1.9463752508163452, 'learning_rate': 8.023375025630511e-05, 'epoch': 1.28}\n",
            " 64% 6950/10838 [18:02<09:48,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0497, 'grad_norm': 1.6777325868606567, 'learning_rate': 7.97211400451097e-05, 'epoch': 1.28}\u001b[0m\n",
            "{'loss': 2.0497, 'grad_norm': 1.6777325868606567, 'learning_rate': 7.97211400451097e-05, 'epoch': 1.28}\n",
            " 64% 6975/10838 [18:05<09:47,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0616, 'grad_norm': 1.150146484375, 'learning_rate': 7.92085298339143e-05, 'epoch': 1.29}\u001b[0m\n",
            "{'loss': 2.0616, 'grad_norm': 1.150146484375, 'learning_rate': 7.92085298339143e-05, 'epoch': 1.29}\n",
            " 65% 7000/10838 [18:09<09:41,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1802, 'grad_norm': 1.3642274141311646, 'learning_rate': 7.869591962271888e-05, 'epoch': 1.29}\u001b[0m\n",
            "{'loss': 2.1802, 'grad_norm': 1.3642274141311646, 'learning_rate': 7.869591962271888e-05, 'epoch': 1.29}\n",
            " 65% 7025/10838 [18:13<09:37,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1769, 'grad_norm': 1.6397024393081665, 'learning_rate': 7.818330941152348e-05, 'epoch': 1.3}\u001b[0m\n",
            "{'loss': 2.1769, 'grad_norm': 1.6397024393081665, 'learning_rate': 7.818330941152348e-05, 'epoch': 1.3}\n",
            " 65% 7050/10838 [18:17<13:54,  4.54it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:51\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1681, 'grad_norm': 1.4219344854354858, 'learning_rate': 7.767069920032808e-05, 'epoch': 1.3}\u001b[0m\n",
            "{'loss': 2.1681, 'grad_norm': 1.4219344854354858, 'learning_rate': 7.767069920032808e-05, 'epoch': 1.3}\n",
            " 65% 7075/10838 [18:21<09:30,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:55\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0355, 'grad_norm': 1.9040498733520508, 'learning_rate': 7.715808898913267e-05, 'epoch': 1.31}\u001b[0m\n",
            "{'loss': 2.0355, 'grad_norm': 1.9040498733520508, 'learning_rate': 7.715808898913267e-05, 'epoch': 1.31}\n",
            " 66% 7100/10838 [18:25<09:27,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:21:59\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1196, 'grad_norm': 1.714077115058899, 'learning_rate': 7.664547877793727e-05, 'epoch': 1.31}\u001b[0m\n",
            "{'loss': 2.1196, 'grad_norm': 1.714077115058899, 'learning_rate': 7.664547877793727e-05, 'epoch': 1.31}\n",
            " 66% 7125/10838 [18:29<09:24,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:03\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2251, 'grad_norm': 1.2729657888412476, 'learning_rate': 7.613286856674185e-05, 'epoch': 1.31}\u001b[0m\n",
            "{'loss': 2.2251, 'grad_norm': 1.2729657888412476, 'learning_rate': 7.613286856674185e-05, 'epoch': 1.31}\n",
            " 66% 7150/10838 [18:33<09:20,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2188, 'grad_norm': 1.5964434146881104, 'learning_rate': 7.562025835554645e-05, 'epoch': 1.32}\u001b[0m\n",
            "{'loss': 2.2188, 'grad_norm': 1.5964434146881104, 'learning_rate': 7.562025835554645e-05, 'epoch': 1.32}\n",
            " 66% 7175/10838 [18:36<09:18,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9983, 'grad_norm': 2.639751434326172, 'learning_rate': 7.510764814435104e-05, 'epoch': 1.32}\u001b[0m\n",
            "{'loss': 1.9983, 'grad_norm': 2.639751434326172, 'learning_rate': 7.510764814435104e-05, 'epoch': 1.32}\n",
            " 66% 7200/10838 [18:40<09:11,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0466, 'grad_norm': 1.5835354328155518, 'learning_rate': 7.459503793315563e-05, 'epoch': 1.33}\u001b[0m\n",
            "{'loss': 2.0466, 'grad_norm': 1.5835354328155518, 'learning_rate': 7.459503793315563e-05, 'epoch': 1.33}\n",
            " 67% 7225/10838 [18:44<09:06,  6.61it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1115, 'grad_norm': 1.6026721000671387, 'learning_rate': 7.408242772196023e-05, 'epoch': 1.33}\u001b[0m\n",
            "{'loss': 2.1115, 'grad_norm': 1.6026721000671387, 'learning_rate': 7.408242772196023e-05, 'epoch': 1.33}\n",
            " 67% 7250/10838 [18:48<09:02,  6.61it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1752, 'grad_norm': 1.3854984045028687, 'learning_rate': 7.356981751076481e-05, 'epoch': 1.34}\u001b[0m\n",
            "{'loss': 2.1752, 'grad_norm': 1.3854984045028687, 'learning_rate': 7.356981751076481e-05, 'epoch': 1.34}\n",
            " 67% 7275/10838 [18:52<09:03,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0748, 'grad_norm': 1.5277602672576904, 'learning_rate': 7.305720729956941e-05, 'epoch': 1.34}\u001b[0m\n",
            "{'loss': 2.0748, 'grad_norm': 1.5277602672576904, 'learning_rate': 7.305720729956941e-05, 'epoch': 1.34}\n",
            " 67% 7300/10838 [18:56<08:55,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1372, 'grad_norm': 1.52317476272583, 'learning_rate': 7.2544597088374e-05, 'epoch': 1.35}\u001b[0m\n",
            "{'loss': 2.1372, 'grad_norm': 1.52317476272583, 'learning_rate': 7.2544597088374e-05, 'epoch': 1.35}\n",
            " 68% 7325/10838 [18:59<08:51,  6.61it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:33\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9458, 'grad_norm': 1.7347947359085083, 'learning_rate': 7.20319868771786e-05, 'epoch': 1.35}\u001b[0m\n",
            "{'loss': 1.9458, 'grad_norm': 1.7347947359085083, 'learning_rate': 7.20319868771786e-05, 'epoch': 1.35}\n",
            " 68% 7350/10838 [19:03<08:50,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9472, 'grad_norm': 1.7945715188980103, 'learning_rate': 7.151937666598318e-05, 'epoch': 1.36}\u001b[0m\n",
            "{'loss': 1.9472, 'grad_norm': 1.7945715188980103, 'learning_rate': 7.151937666598318e-05, 'epoch': 1.36}\n",
            " 68% 7375/10838 [19:07<08:44,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1621, 'grad_norm': 1.3563584089279175, 'learning_rate': 7.100676645478778e-05, 'epoch': 1.36}\u001b[0m\n",
            "{'loss': 2.1621, 'grad_norm': 1.3563584089279175, 'learning_rate': 7.100676645478778e-05, 'epoch': 1.36}\n",
            " 68% 7400/10838 [19:11<08:41,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3675, 'grad_norm': 1.4478176832199097, 'learning_rate': 7.049415624359238e-05, 'epoch': 1.37}\u001b[0m\n",
            "{'loss': 2.3675, 'grad_norm': 1.4478176832199097, 'learning_rate': 7.049415624359238e-05, 'epoch': 1.37}\n",
            " 69% 7425/10838 [19:15<08:38,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0755, 'grad_norm': 1.837411642074585, 'learning_rate': 6.998154603239697e-05, 'epoch': 1.37}\u001b[0m\n",
            "{'loss': 2.0755, 'grad_norm': 1.837411642074585, 'learning_rate': 6.998154603239697e-05, 'epoch': 1.37}\n",
            " 69% 7450/10838 [19:19<08:34,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0943, 'grad_norm': 2.1808815002441406, 'learning_rate': 6.946893582120157e-05, 'epoch': 1.37}\u001b[0m\n",
            "{'loss': 2.0943, 'grad_norm': 2.1808815002441406, 'learning_rate': 6.946893582120157e-05, 'epoch': 1.37}\n",
            " 69% 7475/10838 [19:23<08:29,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:22:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9835, 'grad_norm': 1.7273961305618286, 'learning_rate': 6.895632561000616e-05, 'epoch': 1.38}\u001b[0m\n",
            "{'loss': 1.9835, 'grad_norm': 1.7273961305618286, 'learning_rate': 6.895632561000616e-05, 'epoch': 1.38}\n",
            " 69% 7500/10838 [19:27<08:26,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:00\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1467, 'grad_norm': 1.463138222694397, 'learning_rate': 6.844371539881074e-05, 'epoch': 1.38}\u001b[0m\n",
            "{'loss': 2.1467, 'grad_norm': 1.463138222694397, 'learning_rate': 6.844371539881074e-05, 'epoch': 1.38}\n",
            " 69% 7525/10838 [19:30<08:22,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:04\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9182, 'grad_norm': 1.1773990392684937, 'learning_rate': 6.793110518761534e-05, 'epoch': 1.39}\u001b[0m\n",
            "{'loss': 1.9182, 'grad_norm': 1.1773990392684937, 'learning_rate': 6.793110518761534e-05, 'epoch': 1.39}\n",
            " 70% 7550/10838 [19:34<08:18,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1116, 'grad_norm': 1.3818504810333252, 'learning_rate': 6.741849497641993e-05, 'epoch': 1.39}\u001b[0m\n",
            "{'loss': 2.1116, 'grad_norm': 1.3818504810333252, 'learning_rate': 6.741849497641993e-05, 'epoch': 1.39}\n",
            " 70% 7575/10838 [19:38<08:15,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1677, 'grad_norm': 1.7316409349441528, 'learning_rate': 6.690588476522453e-05, 'epoch': 1.4}\u001b[0m\n",
            "{'loss': 2.1677, 'grad_norm': 1.7316409349441528, 'learning_rate': 6.690588476522453e-05, 'epoch': 1.4}\n",
            " 70% 7600/10838 [19:42<08:10,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9694, 'grad_norm': 1.5427007675170898, 'learning_rate': 6.639327455402911e-05, 'epoch': 1.4}\u001b[0m\n",
            "{'loss': 1.9694, 'grad_norm': 1.5427007675170898, 'learning_rate': 6.639327455402911e-05, 'epoch': 1.4}\n",
            " 70% 7625/10838 [19:46<08:07,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.165, 'grad_norm': 1.7166774272918701, 'learning_rate': 6.588066434283371e-05, 'epoch': 1.41}\u001b[0m\n",
            "{'loss': 2.165, 'grad_norm': 1.7166774272918701, 'learning_rate': 6.588066434283371e-05, 'epoch': 1.41}\n",
            " 71% 7650/10838 [19:50<08:03,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0408, 'grad_norm': 1.353545069694519, 'learning_rate': 6.53680541316383e-05, 'epoch': 1.41}\u001b[0m\n",
            "{'loss': 2.0408, 'grad_norm': 1.353545069694519, 'learning_rate': 6.53680541316383e-05, 'epoch': 1.41}\n",
            " 71% 7675/10838 [19:53<08:01,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2384, 'grad_norm': 1.6298905611038208, 'learning_rate': 6.485544392044289e-05, 'epoch': 1.42}\u001b[0m\n",
            "{'loss': 2.2384, 'grad_norm': 1.6298905611038208, 'learning_rate': 6.485544392044289e-05, 'epoch': 1.42}\n",
            " 71% 7700/10838 [19:58<08:08,  6.43it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:31\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1092, 'grad_norm': 1.6501963138580322, 'learning_rate': 6.43428337092475e-05, 'epoch': 1.42}\u001b[0m\n",
            "{'loss': 2.1092, 'grad_norm': 1.6501963138580322, 'learning_rate': 6.43428337092475e-05, 'epoch': 1.42}\n",
            " 71% 7725/10838 [20:01<07:51,  6.61it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9733, 'grad_norm': 1.5012238025665283, 'learning_rate': 6.383022349805209e-05, 'epoch': 1.43}\u001b[0m\n",
            "{'loss': 1.9733, 'grad_norm': 1.5012238025665283, 'learning_rate': 6.383022349805209e-05, 'epoch': 1.43}\n",
            " 72% 7750/10838 [20:05<07:48,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.986, 'grad_norm': 1.410312294960022, 'learning_rate': 6.331761328685669e-05, 'epoch': 1.43}\u001b[0m\n",
            "{'loss': 1.986, 'grad_norm': 1.410312294960022, 'learning_rate': 6.331761328685669e-05, 'epoch': 1.43}\n",
            " 72% 7775/10838 [20:09<07:44,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0988, 'grad_norm': 1.4649931192398071, 'learning_rate': 6.280500307566127e-05, 'epoch': 1.43}\u001b[0m\n",
            "{'loss': 2.0988, 'grad_norm': 1.4649931192398071, 'learning_rate': 6.280500307566127e-05, 'epoch': 1.43}\n",
            " 72% 7800/10838 [20:13<07:40,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1046, 'grad_norm': 1.3046531677246094, 'learning_rate': 6.229239286446586e-05, 'epoch': 1.44}\u001b[0m\n",
            "{'loss': 2.1046, 'grad_norm': 1.3046531677246094, 'learning_rate': 6.229239286446586e-05, 'epoch': 1.44}\n",
            " 72% 7825/10838 [20:17<07:36,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:51\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1702, 'grad_norm': 1.4659799337387085, 'learning_rate': 6.177978265327046e-05, 'epoch': 1.44}\u001b[0m\n",
            "{'loss': 2.1702, 'grad_norm': 1.4659799337387085, 'learning_rate': 6.177978265327046e-05, 'epoch': 1.44}\n",
            " 72% 7850/10838 [20:21<07:33,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1383, 'grad_norm': 1.4866681098937988, 'learning_rate': 6.126717244207505e-05, 'epoch': 1.45}\u001b[0m\n",
            "{'loss': 2.1383, 'grad_norm': 1.4866681098937988, 'learning_rate': 6.126717244207505e-05, 'epoch': 1.45}\n",
            " 73% 7875/10838 [20:24<07:29,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:23:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2563, 'grad_norm': 1.489152431488037, 'learning_rate': 6.075456223087964e-05, 'epoch': 1.45}\u001b[0m\n",
            "{'loss': 2.2563, 'grad_norm': 1.489152431488037, 'learning_rate': 6.075456223087964e-05, 'epoch': 1.45}\n",
            " 73% 7900/10838 [20:29<07:33,  6.49it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.997, 'grad_norm': 1.2320350408554077, 'learning_rate': 6.024195201968423e-05, 'epoch': 1.46}\u001b[0m\n",
            "{'loss': 1.997, 'grad_norm': 1.2320350408554077, 'learning_rate': 6.024195201968423e-05, 'epoch': 1.46}\n",
            " 73% 7925/10838 [20:32<07:21,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0976, 'grad_norm': 1.5384382009506226, 'learning_rate': 5.9729341808488824e-05, 'epoch': 1.46}\u001b[0m\n",
            "{'loss': 2.0976, 'grad_norm': 1.5384382009506226, 'learning_rate': 5.9729341808488824e-05, 'epoch': 1.46}\n",
            " 73% 7950/10838 [20:36<07:17,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0418, 'grad_norm': 1.599068522453308, 'learning_rate': 5.921673159729342e-05, 'epoch': 1.47}\u001b[0m\n",
            "{'loss': 2.0418, 'grad_norm': 1.599068522453308, 'learning_rate': 5.921673159729342e-05, 'epoch': 1.47}\n",
            " 74% 7975/10838 [20:40<07:13,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1634, 'grad_norm': 1.5017516613006592, 'learning_rate': 5.870412138609801e-05, 'epoch': 1.47}\u001b[0m\n",
            "{'loss': 2.1634, 'grad_norm': 1.5017516613006592, 'learning_rate': 5.870412138609801e-05, 'epoch': 1.47}\n",
            " 74% 8000/10838 [20:44<07:11,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8594, 'grad_norm': 1.538203477859497, 'learning_rate': 5.8191511174902604e-05, 'epoch': 1.48}\u001b[0m\n",
            "{'loss': 1.8594, 'grad_norm': 1.538203477859497, 'learning_rate': 5.8191511174902604e-05, 'epoch': 1.48}\n",
            " 74% 8025/10838 [20:48<07:07,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0071, 'grad_norm': 1.4987212419509888, 'learning_rate': 5.7678900963707203e-05, 'epoch': 1.48}\u001b[0m\n",
            "{'loss': 2.0071, 'grad_norm': 1.4987212419509888, 'learning_rate': 5.7678900963707203e-05, 'epoch': 1.48}\n",
            " 74% 8050/10838 [20:52<07:03,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:25\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1011, 'grad_norm': 1.5712438821792603, 'learning_rate': 5.7166290752511796e-05, 'epoch': 1.49}\u001b[0m\n",
            "{'loss': 2.1011, 'grad_norm': 1.5712438821792603, 'learning_rate': 5.7166290752511796e-05, 'epoch': 1.49}\n",
            " 75% 8075/10838 [20:55<07:01,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.17, 'grad_norm': 1.5779762268066406, 'learning_rate': 5.665368054131639e-05, 'epoch': 1.49}\u001b[0m\n",
            "{'loss': 2.17, 'grad_norm': 1.5779762268066406, 'learning_rate': 5.665368054131639e-05, 'epoch': 1.49}\n",
            " 75% 8100/10838 [20:59<06:55,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:33\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0994, 'grad_norm': 1.656765103340149, 'learning_rate': 5.614107033012098e-05, 'epoch': 1.49}\u001b[0m\n",
            "{'loss': 2.0994, 'grad_norm': 1.656765103340149, 'learning_rate': 5.614107033012098e-05, 'epoch': 1.49}\n",
            " 75% 8125/10838 [21:03<06:52,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0132, 'grad_norm': 1.3729451894760132, 'learning_rate': 5.5628460118925576e-05, 'epoch': 1.5}\u001b[0m\n",
            "{'loss': 2.0132, 'grad_norm': 1.3729451894760132, 'learning_rate': 5.5628460118925576e-05, 'epoch': 1.5}\n",
            " 75% 8150/10838 [21:07<06:47,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9821, 'grad_norm': 1.613499641418457, 'learning_rate': 5.511584990773017e-05, 'epoch': 1.5}\u001b[0m\n",
            "{'loss': 1.9821, 'grad_norm': 1.613499641418457, 'learning_rate': 5.511584990773017e-05, 'epoch': 1.5}\n",
            " 75% 8175/10838 [21:11<06:43,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:45\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2612, 'grad_norm': 1.604637622833252, 'learning_rate': 5.4603239696534755e-05, 'epoch': 1.51}\u001b[0m\n",
            "{'loss': 2.2612, 'grad_norm': 1.604637622833252, 'learning_rate': 5.4603239696534755e-05, 'epoch': 1.51}\n",
            " 76% 8200/10838 [21:15<06:40,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.7975, 'grad_norm': 1.6151601076126099, 'learning_rate': 5.409062948533935e-05, 'epoch': 1.51}\u001b[0m\n",
            "{'loss': 1.7975, 'grad_norm': 1.6151601076126099, 'learning_rate': 5.409062948533935e-05, 'epoch': 1.51}\n",
            " 76% 8225/10838 [21:19<06:35,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0712, 'grad_norm': 1.3248430490493774, 'learning_rate': 5.357801927414394e-05, 'epoch': 1.52}\u001b[0m\n",
            "{'loss': 2.0712, 'grad_norm': 1.3248430490493774, 'learning_rate': 5.357801927414394e-05, 'epoch': 1.52}\n",
            " 76% 8250/10838 [21:22<06:32,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:24:56\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1372, 'grad_norm': 1.6898072957992554, 'learning_rate': 5.3065409062948534e-05, 'epoch': 1.52}\u001b[0m\n",
            "{'loss': 2.1372, 'grad_norm': 1.6898072957992554, 'learning_rate': 5.3065409062948534e-05, 'epoch': 1.52}\n",
            " 76% 8275/10838 [21:26<06:30,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:00\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8352, 'grad_norm': 1.1562252044677734, 'learning_rate': 5.255279885175313e-05, 'epoch': 1.53}\u001b[0m\n",
            "{'loss': 1.8352, 'grad_norm': 1.1562252044677734, 'learning_rate': 5.255279885175313e-05, 'epoch': 1.53}\n",
            " 77% 8300/10838 [21:30<06:24,  6.61it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:04\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.3302, 'grad_norm': 1.763776183128357, 'learning_rate': 5.204018864055772e-05, 'epoch': 1.53}\u001b[0m\n",
            "{'loss': 2.3302, 'grad_norm': 1.763776183128357, 'learning_rate': 5.204018864055772e-05, 'epoch': 1.53}\n",
            " 77% 8325/10838 [21:34<06:20,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:08\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1339, 'grad_norm': 1.2445091009140015, 'learning_rate': 5.152757842936231e-05, 'epoch': 1.54}\u001b[0m\n",
            "{'loss': 2.1339, 'grad_norm': 1.2445091009140015, 'learning_rate': 5.152757842936231e-05, 'epoch': 1.54}\n",
            " 77% 8350/10838 [21:38<06:20,  6.54it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:12\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.976, 'grad_norm': 1.1395108699798584, 'learning_rate': 5.1014968218166906e-05, 'epoch': 1.54}\u001b[0m\n",
            "{'loss': 1.976, 'grad_norm': 1.1395108699798584, 'learning_rate': 5.1014968218166906e-05, 'epoch': 1.54}\n",
            " 77% 8375/10838 [21:42<06:13,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:15\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1422, 'grad_norm': 1.3899834156036377, 'learning_rate': 5.0502358006971506e-05, 'epoch': 1.55}\u001b[0m\n",
            "{'loss': 2.1422, 'grad_norm': 1.3899834156036377, 'learning_rate': 5.0502358006971506e-05, 'epoch': 1.55}\n",
            " 78% 8400/10838 [21:45<06:09,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:19\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0647, 'grad_norm': 2.2342112064361572, 'learning_rate': 4.998974779577609e-05, 'epoch': 1.55}\u001b[0m\n",
            "{'loss': 2.0647, 'grad_norm': 2.2342112064361572, 'learning_rate': 4.998974779577609e-05, 'epoch': 1.55}\n",
            " 78% 8425/10838 [21:49<06:05,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0391, 'grad_norm': 1.5261443853378296, 'learning_rate': 4.9477137584580685e-05, 'epoch': 1.55}\u001b[0m\n",
            "{'loss': 2.0391, 'grad_norm': 1.5261443853378296, 'learning_rate': 4.9477137584580685e-05, 'epoch': 1.55}\n",
            " 78% 8450/10838 [21:53<06:01,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2866, 'grad_norm': 1.3679262399673462, 'learning_rate': 4.8964527373385285e-05, 'epoch': 1.56}\u001b[0m\n",
            "{'loss': 2.2866, 'grad_norm': 1.3679262399673462, 'learning_rate': 4.8964527373385285e-05, 'epoch': 1.56}\n",
            " 78% 8475/10838 [21:57<05:58,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:31\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.153, 'grad_norm': 1.2243249416351318, 'learning_rate': 4.845191716218988e-05, 'epoch': 1.56}\u001b[0m\n",
            "{'loss': 2.153, 'grad_norm': 1.2243249416351318, 'learning_rate': 4.845191716218988e-05, 'epoch': 1.56}\n",
            " 78% 8500/10838 [22:01<05:54,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0609, 'grad_norm': 1.3697794675827026, 'learning_rate': 4.7939306950994464e-05, 'epoch': 1.57}\u001b[0m\n",
            "{'loss': 2.0609, 'grad_norm': 1.3697794675827026, 'learning_rate': 4.7939306950994464e-05, 'epoch': 1.57}\n",
            " 79% 8525/10838 [22:05<05:50,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9191, 'grad_norm': 1.2176729440689087, 'learning_rate': 4.742669673979906e-05, 'epoch': 1.57}\u001b[0m\n",
            "{'loss': 1.9191, 'grad_norm': 1.2176729440689087, 'learning_rate': 4.742669673979906e-05, 'epoch': 1.57}\n",
            " 79% 8550/10838 [22:09<05:47,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:42\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.993, 'grad_norm': 1.6533970832824707, 'learning_rate': 4.691408652860365e-05, 'epoch': 1.58}\u001b[0m\n",
            "{'loss': 1.993, 'grad_norm': 1.6533970832824707, 'learning_rate': 4.691408652860365e-05, 'epoch': 1.58}\n",
            " 79% 8575/10838 [22:12<05:44,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:46\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0278, 'grad_norm': 1.4367449283599854, 'learning_rate': 4.6401476317408243e-05, 'epoch': 1.58}\u001b[0m\n",
            "{'loss': 2.0278, 'grad_norm': 1.4367449283599854, 'learning_rate': 4.6401476317408243e-05, 'epoch': 1.58}\n",
            " 79% 8600/10838 [22:16<05:43,  6.52it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:50\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0711, 'grad_norm': 1.6946383714675903, 'learning_rate': 4.5888866106212837e-05, 'epoch': 1.59}\u001b[0m\n",
            "{'loss': 2.0711, 'grad_norm': 1.6946383714675903, 'learning_rate': 4.5888866106212837e-05, 'epoch': 1.59}\n",
            " 80% 8625/10838 [22:20<05:35,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0235, 'grad_norm': 1.8105099201202393, 'learning_rate': 4.5376255895017436e-05, 'epoch': 1.59}\u001b[0m\n",
            "{'loss': 2.0235, 'grad_norm': 1.8105099201202393, 'learning_rate': 4.5376255895017436e-05, 'epoch': 1.59}\n",
            " 80% 8650/10838 [22:24<05:33,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:25:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2231, 'grad_norm': 1.5020288228988647, 'learning_rate': 4.486364568382202e-05, 'epoch': 1.6}\u001b[0m\n",
            "{'loss': 2.2231, 'grad_norm': 1.5020288228988647, 'learning_rate': 4.486364568382202e-05, 'epoch': 1.6}\n",
            " 80% 8675/10838 [22:28<05:28,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2181, 'grad_norm': 1.5851376056671143, 'learning_rate': 4.4351035472626616e-05, 'epoch': 1.6}\u001b[0m\n",
            "{'loss': 2.2181, 'grad_norm': 1.5851376056671143, 'learning_rate': 4.4351035472626616e-05, 'epoch': 1.6}\n",
            " 80% 8700/10838 [22:32<05:23,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0509, 'grad_norm': 1.8596419095993042, 'learning_rate': 4.383842526143121e-05, 'epoch': 1.61}\u001b[0m\n",
            "{'loss': 2.0509, 'grad_norm': 1.8596419095993042, 'learning_rate': 4.383842526143121e-05, 'epoch': 1.61}\n",
            " 81% 8725/10838 [22:36<05:22,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1166, 'grad_norm': 1.6594916582107544, 'learning_rate': 4.33258150502358e-05, 'epoch': 1.61}\u001b[0m\n",
            "{'loss': 2.1166, 'grad_norm': 1.6594916582107544, 'learning_rate': 4.33258150502358e-05, 'epoch': 1.61}\n",
            " 81% 8750/10838 [22:40<05:16,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:13\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9011, 'grad_norm': 1.6210870742797852, 'learning_rate': 4.2813204839040395e-05, 'epoch': 1.61}\u001b[0m\n",
            "{'loss': 1.9011, 'grad_norm': 1.6210870742797852, 'learning_rate': 4.2813204839040395e-05, 'epoch': 1.61}\n",
            " 81% 8775/10838 [22:43<05:12,  6.61it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:17\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9845, 'grad_norm': 1.4963338375091553, 'learning_rate': 4.230059462784499e-05, 'epoch': 1.62}\u001b[0m\n",
            "{'loss': 1.9845, 'grad_norm': 1.4963338375091553, 'learning_rate': 4.230059462784499e-05, 'epoch': 1.62}\n",
            " 81% 8800/10838 [22:47<05:10,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:21\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0413, 'grad_norm': 1.4030988216400146, 'learning_rate': 4.178798441664958e-05, 'epoch': 1.62}\u001b[0m\n",
            "{'loss': 2.0413, 'grad_norm': 1.4030988216400146, 'learning_rate': 4.178798441664958e-05, 'epoch': 1.62}\n",
            " 81% 8825/10838 [22:51<05:05,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:25\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1679, 'grad_norm': 1.6565676927566528, 'learning_rate': 4.1275374205454174e-05, 'epoch': 1.63}\u001b[0m\n",
            "{'loss': 2.1679, 'grad_norm': 1.6565676927566528, 'learning_rate': 4.1275374205454174e-05, 'epoch': 1.63}\n",
            " 82% 8850/10838 [22:55<05:01,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9665, 'grad_norm': 1.4007428884506226, 'learning_rate': 4.076276399425877e-05, 'epoch': 1.63}\u001b[0m\n",
            "{'loss': 1.9665, 'grad_norm': 1.4007428884506226, 'learning_rate': 4.076276399425877e-05, 'epoch': 1.63}\n",
            " 82% 8875/10838 [22:59<04:58,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:33\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0008, 'grad_norm': 1.3937209844589233, 'learning_rate': 4.025015378306336e-05, 'epoch': 1.64}\u001b[0m\n",
            "{'loss': 2.0008, 'grad_norm': 1.3937209844589233, 'learning_rate': 4.025015378306336e-05, 'epoch': 1.64}\n",
            " 82% 8900/10838 [23:03<04:53,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:36\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9822, 'grad_norm': 1.2680338621139526, 'learning_rate': 3.973754357186795e-05, 'epoch': 1.64}\u001b[0m\n",
            "{'loss': 1.9822, 'grad_norm': 1.2680338621139526, 'learning_rate': 3.973754357186795e-05, 'epoch': 1.64}\n",
            " 82% 8925/10838 [23:06<04:52,  6.53it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.925, 'grad_norm': 1.5208139419555664, 'learning_rate': 3.9224933360672546e-05, 'epoch': 1.65}\u001b[0m\n",
            "{'loss': 1.925, 'grad_norm': 1.5208139419555664, 'learning_rate': 3.9224933360672546e-05, 'epoch': 1.65}\n",
            " 83% 8950/10838 [23:10<04:46,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:44\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0186, 'grad_norm': 1.5772924423217773, 'learning_rate': 3.871232314947714e-05, 'epoch': 1.65}\u001b[0m\n",
            "{'loss': 2.0186, 'grad_norm': 1.5772924423217773, 'learning_rate': 3.871232314947714e-05, 'epoch': 1.65}\n",
            " 83% 8975/10838 [23:14<05:12,  5.96it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:48\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2, 'grad_norm': 1.8831510543823242, 'learning_rate': 3.819971293828173e-05, 'epoch': 1.66}\u001b[0m\n",
            "{'loss': 2.2, 'grad_norm': 1.8831510543823242, 'learning_rate': 3.819971293828173e-05, 'epoch': 1.66}\n",
            " 83% 9000/10838 [23:18<04:38,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9221, 'grad_norm': 1.2405734062194824, 'learning_rate': 3.7687102727086325e-05, 'epoch': 1.66}\u001b[0m\n",
            "{'loss': 1.9221, 'grad_norm': 1.2405734062194824, 'learning_rate': 3.7687102727086325e-05, 'epoch': 1.66}\n",
            " 83% 9025/10838 [23:22<04:35,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:26:56\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8903, 'grad_norm': 1.7561025619506836, 'learning_rate': 3.717449251589092e-05, 'epoch': 1.67}\u001b[0m\n",
            "{'loss': 1.8903, 'grad_norm': 1.7561025619506836, 'learning_rate': 3.717449251589092e-05, 'epoch': 1.67}\n",
            " 84% 9050/10838 [23:26<04:31,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:00\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1212, 'grad_norm': 1.3541616201400757, 'learning_rate': 3.666188230469551e-05, 'epoch': 1.67}\u001b[0m\n",
            "{'loss': 2.1212, 'grad_norm': 1.3541616201400757, 'learning_rate': 3.666188230469551e-05, 'epoch': 1.67}\n",
            " 84% 9075/10838 [23:30<04:27,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:04\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9324, 'grad_norm': 1.6807340383529663, 'learning_rate': 3.6149272093500104e-05, 'epoch': 1.67}\u001b[0m\n",
            "{'loss': 1.9324, 'grad_norm': 1.6807340383529663, 'learning_rate': 3.6149272093500104e-05, 'epoch': 1.67}\n",
            " 84% 9100/10838 [23:34<04:23,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:07\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9093, 'grad_norm': 1.529238224029541, 'learning_rate': 3.56366618823047e-05, 'epoch': 1.68}\u001b[0m\n",
            "{'loss': 1.9093, 'grad_norm': 1.529238224029541, 'learning_rate': 3.56366618823047e-05, 'epoch': 1.68}\n",
            " 84% 9125/10838 [23:37<04:20,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0672, 'grad_norm': 1.6763207912445068, 'learning_rate': 3.512405167110929e-05, 'epoch': 1.68}\u001b[0m\n",
            "{'loss': 2.0672, 'grad_norm': 1.6763207912445068, 'learning_rate': 3.512405167110929e-05, 'epoch': 1.68}\n",
            " 84% 9150/10838 [23:41<04:15,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:15\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0165, 'grad_norm': 1.315595269203186, 'learning_rate': 3.4611441459913883e-05, 'epoch': 1.69}\u001b[0m\n",
            "{'loss': 2.0165, 'grad_norm': 1.315595269203186, 'learning_rate': 3.4611441459913883e-05, 'epoch': 1.69}\n",
            " 85% 9175/10838 [23:45<04:12,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:19\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0071, 'grad_norm': 1.5795037746429443, 'learning_rate': 3.4098831248718476e-05, 'epoch': 1.69}\u001b[0m\n",
            "{'loss': 2.0071, 'grad_norm': 1.5795037746429443, 'learning_rate': 3.4098831248718476e-05, 'epoch': 1.69}\n",
            " 85% 9200/10838 [23:49<04:08,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8447, 'grad_norm': 1.7302483320236206, 'learning_rate': 3.358622103752307e-05, 'epoch': 1.7}\u001b[0m\n",
            "{'loss': 1.8447, 'grad_norm': 1.7302483320236206, 'learning_rate': 3.358622103752307e-05, 'epoch': 1.7}\n",
            " 85% 9225/10838 [23:53<04:04,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.049, 'grad_norm': 1.4750596284866333, 'learning_rate': 3.307361082632766e-05, 'epoch': 1.7}\u001b[0m\n",
            "{'loss': 2.049, 'grad_norm': 1.4750596284866333, 'learning_rate': 3.307361082632766e-05, 'epoch': 1.7}\n",
            " 85% 9250/10838 [23:57<04:01,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:31\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9213, 'grad_norm': 1.7130542993545532, 'learning_rate': 3.2561000615132256e-05, 'epoch': 1.71}\u001b[0m\n",
            "{'loss': 1.9213, 'grad_norm': 1.7130542993545532, 'learning_rate': 3.2561000615132256e-05, 'epoch': 1.71}\n",
            " 86% 9275/10838 [24:01<03:56,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0389, 'grad_norm': 1.4814610481262207, 'learning_rate': 3.204839040393685e-05, 'epoch': 1.71}\u001b[0m\n",
            "{'loss': 2.0389, 'grad_norm': 1.4814610481262207, 'learning_rate': 3.204839040393685e-05, 'epoch': 1.71}\n",
            " 86% 9300/10838 [24:05<03:53,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8701, 'grad_norm': 1.7092698812484741, 'learning_rate': 3.153578019274144e-05, 'epoch': 1.72}\u001b[0m\n",
            "{'loss': 1.8701, 'grad_norm': 1.7092698812484741, 'learning_rate': 3.153578019274144e-05, 'epoch': 1.72}\n",
            " 86% 9325/10838 [24:09<03:49,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:42\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8621, 'grad_norm': 1.2405740022659302, 'learning_rate': 3.1023169981546035e-05, 'epoch': 1.72}\u001b[0m\n",
            "{'loss': 1.8621, 'grad_norm': 1.2405740022659302, 'learning_rate': 3.1023169981546035e-05, 'epoch': 1.72}\n",
            " 86% 9350/10838 [24:12<03:45,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:46\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0823, 'grad_norm': 1.4412875175476074, 'learning_rate': 3.0510559770350628e-05, 'epoch': 1.73}\u001b[0m\n",
            "{'loss': 2.0823, 'grad_norm': 1.4412875175476074, 'learning_rate': 3.0510559770350628e-05, 'epoch': 1.73}\n",
            " 87% 9375/10838 [24:16<03:42,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:50\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8583, 'grad_norm': 1.7666916847229004, 'learning_rate': 2.999794955915522e-05, 'epoch': 1.73}\u001b[0m\n",
            "{'loss': 1.8583, 'grad_norm': 1.7666916847229004, 'learning_rate': 2.999794955915522e-05, 'epoch': 1.73}\n",
            " 87% 9400/10838 [24:20<03:38,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.089, 'grad_norm': 1.486109733581543, 'learning_rate': 2.948533934795981e-05, 'epoch': 1.73}\u001b[0m\n",
            "{'loss': 2.089, 'grad_norm': 1.486109733581543, 'learning_rate': 2.948533934795981e-05, 'epoch': 1.73}\n",
            " 87% 9425/10838 [24:24<03:34,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:27:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9019, 'grad_norm': 1.183690071105957, 'learning_rate': 2.8972729136764403e-05, 'epoch': 1.74}\u001b[0m\n",
            "{'loss': 1.9019, 'grad_norm': 1.183690071105957, 'learning_rate': 2.8972729136764403e-05, 'epoch': 1.74}\n",
            " 87% 9450/10838 [24:28<03:30,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9246, 'grad_norm': 1.188186764717102, 'learning_rate': 2.8460118925568996e-05, 'epoch': 1.74}\u001b[0m\n",
            "{'loss': 1.9246, 'grad_norm': 1.188186764717102, 'learning_rate': 2.8460118925568996e-05, 'epoch': 1.74}\n",
            " 87% 9475/10838 [24:32<03:27,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:06\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0121, 'grad_norm': 1.417944312095642, 'learning_rate': 2.7947508714373593e-05, 'epoch': 1.75}\u001b[0m\n",
            "{'loss': 2.0121, 'grad_norm': 1.417944312095642, 'learning_rate': 2.7947508714373593e-05, 'epoch': 1.75}\n",
            " 88% 9500/10838 [24:36<03:23,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9728, 'grad_norm': 1.7223502397537231, 'learning_rate': 2.7434898503178186e-05, 'epoch': 1.75}\u001b[0m\n",
            "{'loss': 1.9728, 'grad_norm': 1.7223502397537231, 'learning_rate': 2.7434898503178186e-05, 'epoch': 1.75}\n",
            " 88% 9525/10838 [24:40<03:19,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:13\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0946, 'grad_norm': 1.4925771951675415, 'learning_rate': 2.692228829198278e-05, 'epoch': 1.76}\u001b[0m\n",
            "{'loss': 2.0946, 'grad_norm': 1.4925771951675415, 'learning_rate': 2.692228829198278e-05, 'epoch': 1.76}\n",
            " 88% 9550/10838 [24:43<03:15,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:17\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9598, 'grad_norm': 1.3234599828720093, 'learning_rate': 2.640967808078737e-05, 'epoch': 1.76}\u001b[0m\n",
            "{'loss': 1.9598, 'grad_norm': 1.3234599828720093, 'learning_rate': 2.640967808078737e-05, 'epoch': 1.76}\n",
            " 88% 9575/10838 [24:47<03:11,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:21\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9697, 'grad_norm': 1.5919023752212524, 'learning_rate': 2.589706786959196e-05, 'epoch': 1.77}\u001b[0m\n",
            "{'loss': 1.9697, 'grad_norm': 1.5919023752212524, 'learning_rate': 2.589706786959196e-05, 'epoch': 1.77}\n",
            " 89% 9600/10838 [24:51<03:07,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:25\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1508, 'grad_norm': 1.5617986917495728, 'learning_rate': 2.5384457658396555e-05, 'epoch': 1.77}\u001b[0m\n",
            "{'loss': 2.1508, 'grad_norm': 1.5617986917495728, 'learning_rate': 2.5384457658396555e-05, 'epoch': 1.77}\n",
            " 89% 9625/10838 [24:55<03:03,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1065, 'grad_norm': 1.425535798072815, 'learning_rate': 2.4871847447201148e-05, 'epoch': 1.78}\u001b[0m\n",
            "{'loss': 2.1065, 'grad_norm': 1.425535798072815, 'learning_rate': 2.4871847447201148e-05, 'epoch': 1.78}\n",
            " 89% 9650/10838 [24:59<02:59,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:33\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.029, 'grad_norm': 1.5581982135772705, 'learning_rate': 2.435923723600574e-05, 'epoch': 1.78}\u001b[0m\n",
            "{'loss': 2.029, 'grad_norm': 1.5581982135772705, 'learning_rate': 2.435923723600574e-05, 'epoch': 1.78}\n",
            " 89% 9675/10838 [25:03<02:56,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:36\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1855, 'grad_norm': 1.280192255973816, 'learning_rate': 2.3846627024810337e-05, 'epoch': 1.79}\u001b[0m\n",
            "{'loss': 2.1855, 'grad_norm': 1.280192255973816, 'learning_rate': 2.3846627024810337e-05, 'epoch': 1.79}\n",
            " 89% 9700/10838 [25:06<02:52,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1656, 'grad_norm': 1.9387494325637817, 'learning_rate': 2.3334016813614927e-05, 'epoch': 1.79}\u001b[0m\n",
            "{'loss': 2.1656, 'grad_norm': 1.9387494325637817, 'learning_rate': 2.3334016813614927e-05, 'epoch': 1.79}\n",
            " 90% 9725/10838 [25:10<02:48,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:44\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.7799, 'grad_norm': 2.786313533782959, 'learning_rate': 2.282140660241952e-05, 'epoch': 1.79}\u001b[0m\n",
            "{'loss': 1.7799, 'grad_norm': 2.786313533782959, 'learning_rate': 2.282140660241952e-05, 'epoch': 1.79}\n",
            " 90% 9750/10838 [25:14<02:44,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:48\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0824, 'grad_norm': 1.756433129310608, 'learning_rate': 2.2308796391224116e-05, 'epoch': 1.8}\u001b[0m\n",
            "{'loss': 2.0824, 'grad_norm': 1.756433129310608, 'learning_rate': 2.2308796391224116e-05, 'epoch': 1.8}\n",
            " 90% 9775/10838 [25:18<02:41,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9668, 'grad_norm': 1.4787044525146484, 'learning_rate': 2.1796186180028706e-05, 'epoch': 1.8}\u001b[0m\n",
            "{'loss': 1.9668, 'grad_norm': 1.4787044525146484, 'learning_rate': 2.1796186180028706e-05, 'epoch': 1.8}\n",
            " 90% 9800/10838 [25:22<02:37,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:28:56\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0067, 'grad_norm': 1.7201576232910156, 'learning_rate': 2.12835759688333e-05, 'epoch': 1.81}\u001b[0m\n",
            "{'loss': 2.0067, 'grad_norm': 1.7201576232910156, 'learning_rate': 2.12835759688333e-05, 'epoch': 1.81}\n",
            " 91% 9825/10838 [25:26<02:33,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:00\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0617, 'grad_norm': 1.1912171840667725, 'learning_rate': 2.0770965757637892e-05, 'epoch': 1.81}\u001b[0m\n",
            "{'loss': 2.0617, 'grad_norm': 1.1912171840667725, 'learning_rate': 2.0770965757637892e-05, 'epoch': 1.81}\n",
            " 91% 9850/10838 [25:30<02:29,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:03\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1218, 'grad_norm': 1.4808132648468018, 'learning_rate': 2.0258355546442485e-05, 'epoch': 1.82}\u001b[0m\n",
            "{'loss': 2.1218, 'grad_norm': 1.4808132648468018, 'learning_rate': 2.0258355546442485e-05, 'epoch': 1.82}\n",
            " 91% 9875/10838 [25:33<02:27,  6.54it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:07\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.965, 'grad_norm': 1.347101092338562, 'learning_rate': 1.9745745335247078e-05, 'epoch': 1.82}\u001b[0m\n",
            "{'loss': 1.965, 'grad_norm': 1.347101092338562, 'learning_rate': 1.9745745335247078e-05, 'epoch': 1.82}\n",
            " 91% 9900/10838 [25:37<02:22,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9501, 'grad_norm': 1.547278881072998, 'learning_rate': 1.923313512405167e-05, 'epoch': 1.83}\u001b[0m\n",
            "{'loss': 1.9501, 'grad_norm': 1.547278881072998, 'learning_rate': 1.923313512405167e-05, 'epoch': 1.83}\n",
            " 92% 9925/10838 [25:41<02:18,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:15\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.919, 'grad_norm': 2.114248514175415, 'learning_rate': 1.8720524912856268e-05, 'epoch': 1.83}\u001b[0m\n",
            "{'loss': 1.919, 'grad_norm': 2.114248514175415, 'learning_rate': 1.8720524912856268e-05, 'epoch': 1.83}\n",
            " 92% 9950/10838 [25:45<02:14,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:19\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9598, 'grad_norm': 0.9955512881278992, 'learning_rate': 1.8207914701660857e-05, 'epoch': 1.84}\u001b[0m\n",
            "{'loss': 1.9598, 'grad_norm': 0.9955512881278992, 'learning_rate': 1.8207914701660857e-05, 'epoch': 1.84}\n",
            " 92% 9975/10838 [25:49<02:11,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9967, 'grad_norm': 1.5742689371109009, 'learning_rate': 1.769530449046545e-05, 'epoch': 1.84}\u001b[0m\n",
            "{'loss': 1.9967, 'grad_norm': 1.5742689371109009, 'learning_rate': 1.769530449046545e-05, 'epoch': 1.84}\n",
            " 92% 10000/10838 [25:53<02:07,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0655, 'grad_norm': 1.473862886428833, 'learning_rate': 1.7182694279270047e-05, 'epoch': 1.85}\u001b[0m\n",
            "{'loss': 2.0655, 'grad_norm': 1.473862886428833, 'learning_rate': 1.7182694279270047e-05, 'epoch': 1.85}\n",
            " 92% 10025/10838 [25:56<02:03,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:30\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0971, 'grad_norm': 1.502433180809021, 'learning_rate': 1.6670084068074636e-05, 'epoch': 1.85}\u001b[0m\n",
            "{'loss': 2.0971, 'grad_norm': 1.502433180809021, 'learning_rate': 1.6670084068074636e-05, 'epoch': 1.85}\n",
            " 93% 10050/10838 [26:00<01:59,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:34\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9923, 'grad_norm': 1.386839509010315, 'learning_rate': 1.615747385687923e-05, 'epoch': 1.85}\u001b[0m\n",
            "{'loss': 1.9923, 'grad_norm': 1.386839509010315, 'learning_rate': 1.615747385687923e-05, 'epoch': 1.85}\n",
            " 93% 10075/10838 [26:04<01:56,  6.56it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9756, 'grad_norm': 1.5415966510772705, 'learning_rate': 1.5644863645683822e-05, 'epoch': 1.86}\u001b[0m\n",
            "{'loss': 1.9756, 'grad_norm': 1.5415966510772705, 'learning_rate': 1.5644863645683822e-05, 'epoch': 1.86}\n",
            " 93% 10100/10838 [26:08<01:52,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:42\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8754, 'grad_norm': 1.4895548820495605, 'learning_rate': 1.5132253434488417e-05, 'epoch': 1.86}\u001b[0m\n",
            "{'loss': 1.8754, 'grad_norm': 1.4895548820495605, 'learning_rate': 1.5132253434488417e-05, 'epoch': 1.86}\n",
            " 93% 10125/10838 [26:12<01:47,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:46\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0876, 'grad_norm': 1.4344974756240845, 'learning_rate': 1.4619643223293009e-05, 'epoch': 1.87}\u001b[0m\n",
            "{'loss': 2.0876, 'grad_norm': 1.4344974756240845, 'learning_rate': 1.4619643223293009e-05, 'epoch': 1.87}\n",
            " 94% 10150/10838 [26:16<01:44,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:50\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2196, 'grad_norm': 1.6876246929168701, 'learning_rate': 1.4107033012097602e-05, 'epoch': 1.87}\u001b[0m\n",
            "{'loss': 2.2196, 'grad_norm': 1.6876246929168701, 'learning_rate': 1.4107033012097602e-05, 'epoch': 1.87}\n",
            " 94% 10175/10838 [26:20<01:40,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9563, 'grad_norm': 1.6622951030731201, 'learning_rate': 1.3594422800902196e-05, 'epoch': 1.88}\u001b[0m\n",
            "{'loss': 1.9563, 'grad_norm': 1.6622951030731201, 'learning_rate': 1.3594422800902196e-05, 'epoch': 1.88}\n",
            " 94% 10200/10838 [26:24<01:36,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:29:57\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1239, 'grad_norm': 1.3691599369049072, 'learning_rate': 1.3081812589706788e-05, 'epoch': 1.88}\u001b[0m\n",
            "{'loss': 2.1239, 'grad_norm': 1.3691599369049072, 'learning_rate': 1.3081812589706788e-05, 'epoch': 1.88}\n",
            " 94% 10225/10838 [26:27<01:32,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:01\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9533, 'grad_norm': 1.6137388944625854, 'learning_rate': 1.256920237851138e-05, 'epoch': 1.89}\u001b[0m\n",
            "{'loss': 1.9533, 'grad_norm': 1.6137388944625854, 'learning_rate': 1.256920237851138e-05, 'epoch': 1.89}\n",
            " 95% 10250/10838 [26:31<01:29,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:05\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1337, 'grad_norm': 1.793202519416809, 'learning_rate': 1.2056592167315974e-05, 'epoch': 1.89}\u001b[0m\n",
            "{'loss': 2.1337, 'grad_norm': 1.793202519416809, 'learning_rate': 1.2056592167315974e-05, 'epoch': 1.89}\n",
            " 95% 10275/10838 [26:35<01:25,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:09\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1509, 'grad_norm': 1.5586117506027222, 'learning_rate': 1.1543981956120567e-05, 'epoch': 1.9}\u001b[0m\n",
            "{'loss': 2.1509, 'grad_norm': 1.5586117506027222, 'learning_rate': 1.1543981956120567e-05, 'epoch': 1.9}\n",
            " 95% 10300/10838 [26:39<01:21,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:13\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.2299, 'grad_norm': 1.4061479568481445, 'learning_rate': 1.103137174492516e-05, 'epoch': 1.9}\u001b[0m\n",
            "{'loss': 2.2299, 'grad_norm': 1.4061479568481445, 'learning_rate': 1.103137174492516e-05, 'epoch': 1.9}\n",
            " 95% 10325/10838 [26:43<01:17,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:17\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0431, 'grad_norm': 1.7566570043563843, 'learning_rate': 1.0518761533729753e-05, 'epoch': 1.91}\u001b[0m\n",
            "{'loss': 2.0431, 'grad_norm': 1.7566570043563843, 'learning_rate': 1.0518761533729753e-05, 'epoch': 1.91}\n",
            " 95% 10350/10838 [26:47<01:13,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:21\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9666, 'grad_norm': 1.5137085914611816, 'learning_rate': 1.0006151322534344e-05, 'epoch': 1.91}\u001b[0m\n",
            "{'loss': 1.9666, 'grad_norm': 1.5137085914611816, 'learning_rate': 1.0006151322534344e-05, 'epoch': 1.91}\n",
            " 96% 10375/10838 [26:51<01:10,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:24\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9877, 'grad_norm': 1.4955209493637085, 'learning_rate': 9.493541111338939e-06, 'epoch': 1.91}\u001b[0m\n",
            "{'loss': 1.9877, 'grad_norm': 1.4955209493637085, 'learning_rate': 9.493541111338939e-06, 'epoch': 1.91}\n",
            " 96% 10400/10838 [26:54<01:06,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1451, 'grad_norm': 1.5582772493362427, 'learning_rate': 8.980930900143532e-06, 'epoch': 1.92}\u001b[0m\n",
            "{'loss': 2.1451, 'grad_norm': 1.5582772493362427, 'learning_rate': 8.980930900143532e-06, 'epoch': 1.92}\n",
            " 96% 10425/10838 [26:58<01:02,  6.61it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:32\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0532, 'grad_norm': 1.2338931560516357, 'learning_rate': 8.468320688948123e-06, 'epoch': 1.92}\u001b[0m\n",
            "{'loss': 2.0532, 'grad_norm': 1.2338931560516357, 'learning_rate': 8.468320688948123e-06, 'epoch': 1.92}\n",
            " 96% 10450/10838 [27:02<00:58,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:36\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1354, 'grad_norm': 1.510611891746521, 'learning_rate': 7.955710477752718e-06, 'epoch': 1.93}\u001b[0m\n",
            "{'loss': 2.1354, 'grad_norm': 1.510611891746521, 'learning_rate': 7.955710477752718e-06, 'epoch': 1.93}\n",
            " 97% 10475/10838 [27:06<00:55,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0083, 'grad_norm': 1.3762843608856201, 'learning_rate': 7.443100266557309e-06, 'epoch': 1.93}\u001b[0m\n",
            "{'loss': 2.0083, 'grad_norm': 1.3762843608856201, 'learning_rate': 7.443100266557309e-06, 'epoch': 1.93}\n",
            " 97% 10500/10838 [27:10<00:51,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:44\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0538, 'grad_norm': 1.8271384239196777, 'learning_rate': 6.930490055361903e-06, 'epoch': 1.94}\u001b[0m\n",
            "{'loss': 2.0538, 'grad_norm': 1.8271384239196777, 'learning_rate': 6.930490055361903e-06, 'epoch': 1.94}\n",
            " 97% 10525/10838 [27:14<00:47,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:48\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0201, 'grad_norm': 1.5763059854507446, 'learning_rate': 6.417879844166496e-06, 'epoch': 1.94}\u001b[0m\n",
            "{'loss': 2.0201, 'grad_norm': 1.5763059854507446, 'learning_rate': 6.417879844166496e-06, 'epoch': 1.94}\n",
            " 97% 10550/10838 [27:18<00:43,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8421, 'grad_norm': 1.161217451095581, 'learning_rate': 5.9052696329710885e-06, 'epoch': 1.95}\u001b[0m\n",
            "{'loss': 1.8421, 'grad_norm': 1.161217451095581, 'learning_rate': 5.9052696329710885e-06, 'epoch': 1.95}\n",
            " 98% 10575/10838 [27:22<00:39,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:55\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0329, 'grad_norm': 1.0366628170013428, 'learning_rate': 5.392659421775682e-06, 'epoch': 1.95}\u001b[0m\n",
            "{'loss': 2.0329, 'grad_norm': 1.0366628170013428, 'learning_rate': 5.392659421775682e-06, 'epoch': 1.95}\n",
            " 98% 10600/10838 [27:25<00:36,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:30:59\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8717, 'grad_norm': 1.5982272624969482, 'learning_rate': 4.8800492105802755e-06, 'epoch': 1.96}\u001b[0m\n",
            "{'loss': 1.8717, 'grad_norm': 1.5982272624969482, 'learning_rate': 4.8800492105802755e-06, 'epoch': 1.96}\n",
            " 98% 10625/10838 [27:29<00:32,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:03\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8514, 'grad_norm': 1.6390588283538818, 'learning_rate': 4.367438999384868e-06, 'epoch': 1.96}\u001b[0m\n",
            "{'loss': 1.8514, 'grad_norm': 1.6390588283538818, 'learning_rate': 4.367438999384868e-06, 'epoch': 1.96}\n",
            " 98% 10650/10838 [27:33<00:28,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:07\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.8779, 'grad_norm': 1.5819393396377563, 'learning_rate': 3.854828788189461e-06, 'epoch': 1.97}\u001b[0m\n",
            "{'loss': 1.8779, 'grad_norm': 1.5819393396377563, 'learning_rate': 3.854828788189461e-06, 'epoch': 1.97}\n",
            " 98% 10675/10838 [27:37<00:24,  6.58it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9855, 'grad_norm': 1.6205073595046997, 'learning_rate': 3.3422185769940537e-06, 'epoch': 1.97}\u001b[0m\n",
            "{'loss': 1.9855, 'grad_norm': 1.6205073595046997, 'learning_rate': 3.3422185769940537e-06, 'epoch': 1.97}\n",
            " 99% 10700/10838 [27:41<00:20,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:15\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 1.9308, 'grad_norm': 1.804917573928833, 'learning_rate': 2.8296083657986468e-06, 'epoch': 1.97}\u001b[0m\n",
            "{'loss': 1.9308, 'grad_norm': 1.804917573928833, 'learning_rate': 2.8296083657986468e-06, 'epoch': 1.97}\n",
            " 99% 10725/10838 [27:45<00:17,  6.59it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:18\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1329, 'grad_norm': 1.4745981693267822, 'learning_rate': 2.31699815460324e-06, 'epoch': 1.98}\u001b[0m\n",
            "{'loss': 2.1329, 'grad_norm': 1.4745981693267822, 'learning_rate': 2.31699815460324e-06, 'epoch': 1.98}\n",
            " 99% 10750/10838 [27:48<00:13,  6.57it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:22\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1048, 'grad_norm': 1.5380487442016602, 'learning_rate': 1.8043879434078328e-06, 'epoch': 1.98}\u001b[0m\n",
            "{'loss': 2.1048, 'grad_norm': 1.5380487442016602, 'learning_rate': 1.8043879434078328e-06, 'epoch': 1.98}\n",
            " 99% 10775/10838 [27:53<00:11,  5.70it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1316, 'grad_norm': 1.0970693826675415, 'learning_rate': 1.2917777322124257e-06, 'epoch': 1.99}\u001b[0m\n",
            "{'loss': 2.1316, 'grad_norm': 1.0970693826675415, 'learning_rate': 1.2917777322124257e-06, 'epoch': 1.99}\n",
            "100% 10800/10838 [27:56<00:05,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:30\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.0924, 'grad_norm': 1.1377179622650146, 'learning_rate': 7.791675210170187e-07, 'epoch': 1.99}\u001b[0m\n",
            "{'loss': 2.0924, 'grad_norm': 1.1377179622650146, 'learning_rate': 7.791675210170187e-07, 'epoch': 1.99}\n",
            "100% 10825/10838 [28:00<00:01,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:34\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'loss': 2.1066, 'grad_norm': 1.5534616708755493, 'learning_rate': 2.6655730982161164e-07, 'epoch': 2.0}\u001b[0m\n",
            "{'loss': 2.1066, 'grad_norm': 1.5534616708755493, 'learning_rate': 2.6655730982161164e-07, 'epoch': 2.0}\n",
            "100% 10838/10838 [28:02<00:00,  6.60it/s]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1m{'train_runtime': 1686.5381, 'train_samples_per_second': 6.426, 'train_steps_per_second': 6.426, 'train_loss': 2.6003007557938123, 'epoch': 2.0}\u001b[0m\n",
            "{'train_runtime': 1686.5381, 'train_samples_per_second': 6.426, 'train_steps_per_second': 6.426, 'train_loss': 2.6003007557938123, 'epoch': 2.0}\n",
            "100% 10838/10838 [28:06<00:00,  6.43it/s]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:40\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-08 13:31:41\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m580\u001b[0m - \u001b[1mPushing model to hub...\u001b[0m\n",
            "model.safetensors:   0% 0.00/498M [00:00<?, ?B/s]\n",
            "optimizer.pt:   0% 0.00/996M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "rng_state.pth:   0% 0.00/14.2k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "scheduler.pt:   0% 0.00/1.06k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "training_args.bin:   0% 0.00/4.98k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 16.4k/498M [00:00<1:23:26, 99.4kB/s]\n",
            "\n",
            "\n",
            "scheduler.pt: 100% 1.06k/1.06k [00:00<00:00, 6.69kB/s]\u001b[A\u001b[A\u001b[A\n",
            "optimizer.pt:   0% 16.4k/996M [00:00<2:48:23, 98.5kB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "training_args.bin: 100% 4.98k/4.98k [00:00<00:00, 25.8kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "scheduler.pt: 100% 1.06k/1.06k [00:00<00:00, 3.74kB/s]\n",
            "\n",
            "rng_state.pth: 100% 14.2k/14.2k [00:00<00:00, 34.1kB/s]\n",
            "model.safetensors:   1% 4.47M/498M [00:00<00:42, 11.6MB/s]\n",
            "\n",
            "model.safetensors:   0% 0.00/498M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "training_args.bin: 100% 4.98k/4.98k [00:00<00:00, 9.01kB/s]\n",
            "model.safetensors:   2% 7.85M/498M [00:00<00:28, 17.0MB/s]\n",
            "optimizer.pt:   1% 8.40M/996M [00:00<01:10, 14.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "training_args.bin:   0% 0.00/4.98k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   1% 4.85M/498M [00:00<00:16, 30.5MB/s]\u001b[A\u001b[A\n",
            "training_args.bin: 100% 4.98k/4.98k [00:00<00:00, 33.3kB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   3% 13.5M/498M [00:00<00:31, 15.4MB/s]\n",
            "\n",
            "model.safetensors:   2% 10.3M/498M [00:00<00:25, 19.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   3% 14.8M/498M [00:00<00:18, 26.3MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:   2% 18.8M/996M [00:01<00:56, 17.3MB/s]\u001b[A\n",
            "model.safetensors:   3% 16.0M/498M [00:01<00:48, 9.84MB/s]\n",
            "optimizer.pt:   3% 28.4M/996M [00:01<00:38, 25.3MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:   6% 28.2M/498M [00:01<00:18, 25.9MB/s]\n",
            "\n",
            "model.safetensors:   4% 21.7M/498M [00:01<00:26, 18.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   8% 38.6M/498M [00:01<00:16, 28.6MB/s]\n",
            "optimizer.pt:   3% 32.0M/996M [00:01<01:03, 15.1MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:   6% 27.6M/498M [00:01<00:25, 18.2MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:   4% 38.5M/996M [00:02<00:46, 20.5MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:   9% 42.9M/498M [00:02<00:20, 22.5MB/s]\n",
            "model.safetensors:   9% 47.0M/498M [00:02<00:18, 24.5MB/s]\n",
            "optimizer.pt:   5% 45.8M/996M [00:02<00:47, 20.0MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:   7% 34.1M/498M [00:02<00:36, 12.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  12% 62.2M/498M [00:02<00:13, 31.1MB/s]\n",
            "\n",
            "model.safetensors:   9% 43.2M/498M [00:02<00:26, 17.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   9% 46.9M/498M [00:02<00:23, 19.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  14% 67.5M/498M [00:03<00:17, 24.1MB/s]\n",
            "model.safetensors:  15% 72.9M/498M [00:03<00:15, 28.1MB/s]\n",
            "\n",
            "model.safetensors:  10% 49.2M/498M [00:02<00:35, 12.7MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:   7% 67.4M/996M [00:03<00:44, 21.0MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  16% 80.0M/498M [00:03<00:15, 26.4MB/s]\n",
            "model.safetensors:  17% 84.1M/498M [00:03<00:14, 27.6MB/s]\n",
            "\n",
            "model.safetensors:  18% 89.3M/498M [00:03<00:15, 26.6MB/s]\n",
            "optimizer.pt:   8% 75.5M/996M [00:03<00:44, 20.7MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  16% 77.9M/498M [00:03<00:11, 35.9MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:   8% 78.7M/996M [00:04<00:45, 20.1MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  17% 83.5M/498M [00:03<00:13, 31.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  19% 92.6M/498M [00:04<00:22, 18.0MB/s]\n",
            "optimizer.pt:   8% 81.5M/996M [00:04<01:01, 14.9MB/s]\u001b[A\n",
            "optimizer.pt:   9% 93.9M/996M [00:04<00:30, 29.4MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  20% 100M/498M [00:04<00:11, 33.7MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  19% 96.0M/498M [00:04<00:30, 13.2MB/s]\n",
            "model.safetensors:  22% 108M/498M [00:04<00:15, 25.4MB/s] \n",
            "\n",
            "model.safetensors:  23% 116M/498M [00:04<00:10, 36.8MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  11% 105M/996M [00:05<00:30, 28.9MB/s] \u001b[A\n",
            "\n",
            "model.safetensors:  25% 122M/498M [00:04<00:09, 40.4MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  23% 113M/498M [00:05<00:19, 20.0MB/s]\n",
            "optimizer.pt:  11% 113M/996M [00:05<00:36, 24.1MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  25% 124M/498M [00:05<00:12, 30.4MB/s]\n",
            "optimizer.pt:  12% 121M/996M [00:05<00:26, 33.1MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  27% 135M/498M [00:05<00:10, 35.8MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  13% 126M/996M [00:05<00:24, 35.0MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  26% 130M/498M [00:05<00:15, 23.0MB/s]\n",
            "\n",
            "model.safetensors:  29% 145M/498M [00:05<00:12, 28.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  27% 136M/498M [00:06<00:13, 27.0MB/s]\n",
            "\n",
            "model.safetensors:  30% 152M/498M [00:05<00:10, 34.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  28% 140M/498M [00:06<00:14, 25.5MB/s]\n",
            "\n",
            "model.safetensors:  31% 156M/498M [00:06<00:17, 19.8MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  14% 138M/996M [00:06<00:53, 15.9MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  32% 159M/498M [00:06<00:17, 19.8MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  30% 151M/498M [00:06<00:16, 20.7MB/s]\n",
            "\n",
            "model.safetensors:  31% 155M/498M [00:07<00:18, 18.8MB/s]\n",
            "\n",
            "model.safetensors:  35% 175M/498M [00:06<00:11, 28.4MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  32% 158M/498M [00:07<00:16, 20.2MB/s]\n",
            "optimizer.pt:  15% 153M/996M [00:07<00:41, 20.4MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  36% 180M/498M [00:06<00:11, 27.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  37% 184M/498M [00:07<00:10, 29.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  32% 161M/498M [00:07<00:22, 14.7MB/s]\n",
            "model.safetensors:  34% 169M/498M [00:07<00:14, 22.4MB/s]\n",
            "\n",
            "model.safetensors:  38% 188M/498M [00:07<00:13, 22.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  38% 191M/498M [00:07<00:12, 23.6MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  37% 186M/498M [00:08<00:08, 35.4MB/s]\n",
            "\n",
            "model.safetensors:  39% 195M/498M [00:07<00:19, 15.4MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  39% 192M/498M [00:08<00:10, 30.4MB/s]\n",
            "\n",
            "model.safetensors:  41% 202M/498M [00:08<00:12, 23.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  40% 198M/498M [00:08<00:09, 32.8MB/s]\n",
            "model.safetensors:  41% 202M/498M [00:08<00:08, 33.5MB/s]\n",
            "\n",
            "model.safetensors:  42% 208M/498M [00:08<00:13, 21.3MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  21% 212M/996M [00:08<00:23, 34.0MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  42% 208M/498M [00:09<00:09, 29.3MB/s]\n",
            "optimizer.pt:  22% 218M/996M [00:09<00:20, 38.7MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  45% 224M/498M [00:08<00:07, 37.2MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  45% 223M/498M [00:09<00:06, 44.2MB/s]\n",
            "\n",
            "model.safetensors:  46% 229M/498M [00:08<00:08, 32.3MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  23% 228M/996M [00:09<00:22, 33.6MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  48% 237M/498M [00:08<00:06, 38.6MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  47% 233M/498M [00:09<00:07, 36.6MB/s]\n",
            "\n",
            "model.safetensors:  49% 242M/498M [00:09<00:09, 27.5MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  24% 240M/996M [00:09<00:27, 27.1MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  48% 240M/498M [00:09<00:08, 28.8MB/s]\n",
            "model.safetensors:  49% 246M/498M [00:10<00:07, 33.0MB/s]\n",
            "\n",
            "model.safetensors:  52% 258M/498M [00:09<00:07, 32.6MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  26% 256M/996M [00:10<00:23, 31.0MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  54% 269M/498M [00:09<00:05, 44.0MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  51% 256M/498M [00:10<00:07, 30.4MB/s]\n",
            "\n",
            "model.safetensors:  54% 270M/498M [00:10<00:04, 46.2MB/s]\n",
            "\n",
            "model.safetensors:  57% 282M/498M [00:10<00:05, 42.1MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  27% 272M/996M [00:10<00:22, 32.7MB/s]\u001b[A\n",
            "model.safetensors:  56% 277M/498M [00:10<00:06, 35.4MB/s]\n",
            "\n",
            "model.safetensors:  57% 285M/498M [00:11<00:05, 42.1MB/s]\n",
            "\n",
            "model.safetensors:  60% 298M/498M [00:10<00:04, 44.3MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  29% 289M/996M [00:11<00:21, 33.0MB/s]\u001b[A\n",
            "model.safetensors:  58% 291M/498M [00:11<00:05, 35.2MB/s]\n",
            "\n",
            "model.safetensors:  59% 295M/498M [00:11<00:05, 35.6MB/s]\n",
            "\n",
            "model.safetensors:  63% 315M/498M [00:10<00:03, 47.6MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  60% 300M/498M [00:11<00:05, 34.8MB/s]\n",
            "optimizer.pt:  32% 318M/996M [00:11<00:14, 46.2MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  64% 321M/498M [00:11<00:04, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  61% 304M/498M [00:11<00:07, 24.9MB/s]\n",
            "optimizer.pt:  33% 324M/996M [00:11<00:17, 38.7MB/s]\u001b[A\n",
            "model.safetensors:  64% 318M/498M [00:12<00:04, 36.8MB/s]\n",
            "\n",
            "model.safetensors:  68% 339M/498M [00:11<00:04, 36.7MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  34% 337M/996M [00:12<00:17, 37.0MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  70% 348M/498M [00:11<00:03, 45.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  65% 323M/498M [00:12<00:06, 26.0MB/s]\n",
            "\n",
            "model.safetensors:  67% 332M/498M [00:12<00:04, 35.6MB/s]\n",
            "\n",
            "model.safetensors:  73% 362M/498M [00:12<00:03, 43.4MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  68% 337M/498M [00:12<00:05, 27.9MB/s]\n",
            "optimizer.pt:  37% 367M/996M [00:12<00:14, 44.7MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  69% 343M/498M [00:13<00:04, 32.7MB/s]\n",
            "\n",
            "model.safetensors:  70% 348M/498M [00:13<00:04, 33.8MB/s]\n",
            "optimizer.pt:  38% 374M/996M [00:13<00:16, 37.3MB/s]\u001b[A\n",
            "optimizer.pt:  38% 382M/996M [00:13<00:14, 43.8MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  77% 384M/498M [00:12<00:03, 34.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  71% 352M/498M [00:13<00:06, 23.9MB/s]\n",
            "model.safetensors:  73% 363M/498M [00:13<00:03, 36.1MB/s]\n",
            "model.safetensors:  74% 368M/498M [00:13<00:03, 36.7MB/s]\n",
            "\n",
            "model.safetensors:  81% 406M/498M [00:13<00:02, 40.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  75% 372M/498M [00:13<00:04, 29.5MB/s]\n",
            "\n",
            "model.safetensors:  80% 398M/498M [00:14<00:02, 48.3MB/s]\n",
            "optimizer.pt:  40% 400M/996M [00:14<00:32, 18.3MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  87% 432M/498M [00:14<00:02, 32.8MB/s]\u001b[A\u001b[A\n",
            "optimizer.pt:  42% 415M/996M [00:14<00:19, 30.5MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  83% 414M/498M [00:14<00:01, 42.7MB/s]\n",
            "optimizer.pt:  42% 421M/996M [00:14<00:20, 28.7MB/s]\u001b[A\n",
            "optimizer.pt:  43% 429M/996M [00:14<00:16, 34.4MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  90% 448M/498M [00:14<00:01, 33.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  86% 430M/498M [00:15<00:01, 44.0MB/s]\n",
            "\n",
            "model.safetensors:  93% 464M/498M [00:14<00:00, 35.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  88% 436M/498M [00:15<00:01, 36.6MB/s]\n",
            "\n",
            "model.safetensors:  93% 462M/498M [00:15<00:00, 50.7MB/s]\n",
            "optimizer.pt:  44% 434M/996M [00:15<00:35, 15.9MB/s]\u001b[A\n",
            "\n",
            "model.safetensors: 100% 496M/498M [00:15<00:00, 38.2MB/s]\u001b[A\u001b[A\n",
            "model.safetensors: 100% 498M/498M [00:15<00:00, 31.4MB/s]\n",
            "\n",
            "optimizer.pt:  45% 448M/996M [00:16<00:27, 20.1MB/s]\u001b[A\n",
            "model.safetensors: 100% 495M/498M [00:16<00:00, 50.6MB/s]\n",
            "optimizer.pt:  47% 470M/996M [00:16<00:16, 31.3MB/s]\u001b[A\n",
            "optimizer.pt:  48% 480M/996M [00:17<00:15, 32.6MB/s]\u001b[A\n",
            "model.safetensors: 100% 498M/498M [00:17<00:00, 28.8MB/s]\n",
            "\n",
            "optimizer.pt:  50% 502M/996M [00:17<00:12, 40.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 7 LFS files:  14% 1/7 [00:17<01:45, 17.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "optimizer.pt:  51% 512M/996M [00:17<00:14, 34.3MB/s]\u001b[A\n",
            "optimizer.pt:  53% 527M/996M [00:17<00:09, 48.6MB/s]\u001b[A\n",
            "optimizer.pt:  54% 534M/996M [00:18<00:11, 41.5MB/s]\u001b[A\n",
            "optimizer.pt:  55% 544M/996M [00:18<00:12, 36.0MB/s]\u001b[A\n",
            "optimizer.pt:  56% 558M/996M [00:18<00:08, 50.1MB/s]\u001b[A\n",
            "optimizer.pt:  57% 566M/996M [00:19<00:10, 39.3MB/s]\u001b[A\n",
            "optimizer.pt:  58% 576M/996M [00:19<00:11, 35.8MB/s]\u001b[A\n",
            "optimizer.pt:  59% 590M/996M [00:19<00:08, 49.5MB/s]\u001b[A\n",
            "optimizer.pt:  60% 598M/996M [00:19<00:08, 44.8MB/s]\u001b[A\n",
            "optimizer.pt:  61% 608M/996M [00:20<00:09, 39.1MB/s]\u001b[A\n",
            "optimizer.pt:  63% 622M/996M [00:20<00:06, 53.6MB/s]\u001b[A\n",
            "optimizer.pt:  63% 630M/996M [00:20<00:11, 32.5MB/s]\u001b[A\n",
            "optimizer.pt:  64% 640M/996M [00:21<00:10, 32.4MB/s]\u001b[A\n",
            "optimizer.pt:  66% 654M/996M [00:21<00:07, 45.4MB/s]\u001b[A\n",
            "optimizer.pt:  66% 662M/996M [00:21<00:08, 37.7MB/s]\u001b[A\n",
            "optimizer.pt:  67% 672M/996M [00:21<00:09, 34.0MB/s]\u001b[A\n",
            "optimizer.pt:  69% 686M/996M [00:21<00:06, 47.5MB/s]\u001b[A\n",
            "optimizer.pt:  70% 694M/996M [00:22<00:07, 38.7MB/s]\u001b[A\n",
            "optimizer.pt:  71% 704M/996M [00:22<00:07, 36.5MB/s]\u001b[A\n",
            "optimizer.pt:  72% 718M/996M [00:22<00:05, 50.4MB/s]\u001b[A\n",
            "optimizer.pt:  73% 726M/996M [00:22<00:06, 43.1MB/s]\u001b[A\n",
            "optimizer.pt:  74% 736M/996M [00:23<00:06, 39.5MB/s]\u001b[A\n",
            "optimizer.pt:  75% 750M/996M [00:23<00:04, 54.1MB/s]\u001b[A\n",
            "optimizer.pt:  76% 758M/996M [00:23<00:05, 43.1MB/s]\u001b[A\n",
            "optimizer.pt:  77% 768M/996M [00:23<00:05, 38.3MB/s]\u001b[A\n",
            "optimizer.pt:  79% 782M/996M [00:24<00:04, 52.4MB/s]\u001b[A\n",
            "optimizer.pt:  79% 790M/996M [00:24<00:04, 46.0MB/s]\u001b[A\n",
            "optimizer.pt:  80% 800M/996M [00:24<00:04, 39.7MB/s]\u001b[A\n",
            "optimizer.pt:  82% 814M/996M [00:24<00:03, 54.2MB/s]\u001b[A\n",
            "optimizer.pt:  83% 822M/996M [00:25<00:04, 37.0MB/s]\u001b[A\n",
            "optimizer.pt:  84% 832M/996M [00:25<00:04, 35.4MB/s]\u001b[A\n",
            "optimizer.pt:  85% 846M/996M [00:25<00:03, 49.0MB/s]\u001b[A\n",
            "optimizer.pt:  86% 854M/996M [00:25<00:03, 42.8MB/s]\u001b[A\n",
            "optimizer.pt:  87% 864M/996M [00:26<00:03, 39.6MB/s]\u001b[A\n",
            "optimizer.pt:  88% 878M/996M [00:26<00:02, 54.0MB/s]\u001b[A\n",
            "optimizer.pt:  89% 886M/996M [00:26<00:02, 48.6MB/s]\u001b[A\n",
            "optimizer.pt:  90% 896M/996M [00:26<00:02, 40.4MB/s]\u001b[A\n",
            "optimizer.pt:  91% 910M/996M [00:26<00:01, 54.9MB/s]\u001b[A\n",
            "optimizer.pt:  92% 918M/996M [00:27<00:02, 30.0MB/s]\u001b[A\n",
            "optimizer.pt:  93% 928M/996M [00:27<00:02, 31.2MB/s]\u001b[A\n",
            "optimizer.pt:  95% 942M/996M [00:27<00:01, 43.9MB/s]\u001b[A\n",
            "optimizer.pt:  95% 950M/996M [00:28<00:01, 37.4MB/s]\u001b[A\n",
            "optimizer.pt:  96% 960M/996M [00:28<00:01, 34.7MB/s]\u001b[A\n",
            "optimizer.pt:  98% 974M/996M [00:28<00:00, 48.2MB/s]\u001b[A\n",
            "optimizer.pt:  99% 982M/996M [00:29<00:00, 37.8MB/s]\u001b[A\n",
            "optimizer.pt: 100% 996M/996M [00:29<00:00, 33.5MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 7 LFS files: 100% 7/7 [00:30<00:00,  4.29s/it]\n"
          ]
        }
      ],
      "source": [
        "!autotrain llm \\\n",
        "  --train \\\n",
        "  --project-name \"gpt2-autotrain-llm-finetuned-vff\" \\\n",
        "  --model gpt2 \\\n",
        "  --data-path timdettmers/openassistant-guanaco \\\n",
        "  --lr 2e-4 \\\n",
        "  --batch-size 1 \\\n",
        "  --epochs 2 \\\n",
        "  --trainer sft \\\n",
        "  --model_max_length 1024 \\\n",
        "  --push-to-hub  \\\n",
        "  --repo-id \"kr-manish/gpt2-autotrain-finetuned-vff\" \\\n",
        "  --token \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Load the fine-tuned model and tokenizer from the Hugging Face Model Hub\n",
        "model_name = \"kr-manish/gpt2-autotrain-finetuned-vff\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Input text\n",
        "input_text = \"explain the difference between GAN and generative ai?\"\n",
        "\n",
        "# Tokenize input text\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# Generate output text\n",
        "output = model.generate(input_ids, max_length=100, num_return_sequences=1, do_sample=True)\n",
        "\n",
        "# Decode and print output\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True, src_lang=\"en\")\n",
        "print(generated_text)\n",
        "\n",
        "#explain the difference between GAN and generative ai?### Assistant: GAN is a deep learning model that uses neural networks to learn natural language and generate text. Generative ai works by training the model on a set of natural tasks, such as recognizing faces or playing games, to generate a complete model of language. GAN trains on two inputs: a set of tokens for words and input images into a GAN tree, which represents the learning process. GAN then trains on\n"
      ],
      "metadata": {
        "id": "eHzvlkMe7V6Z",
        "outputId": "3e877df4-6178-4a15-9b55-faff5ba2ba99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "explain the difference between GAN and generative ai?### Assistant: GAN is a deep learning model that uses neural networks to learn natural language and generate text. Generative ai works by training the model on a set of natural tasks, such as recognizing faces or playing games, to generate a complete model of language. GAN trains on two inputs: a set of tokens for words and input images into a GAN tree, which represents the learning process. GAN then trains on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LV6_NcU9EpCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70cceeb8f9164c84b5f08961c0f74eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8506762658714888b29fdbea67d6a224",
              "IPY_MODEL_1d043460adb840098744f3df8d09d90e",
              "IPY_MODEL_01d819b8f45f4c40bf8bbf8a483b5d2c",
              "IPY_MODEL_05a172bc5c394827845392e69c758ca4"
            ],
            "layout": "IPY_MODEL_29ca8dea1d63478f99f256b572d8b3ae"
          }
        },
        "55fc4d9933e04a06a7c0899f3741cf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ce8cac112ee4ac79ef31e3fe6f9ad55",
            "placeholder": "​",
            "style": "IPY_MODEL_a0425bdfe66a4456a307093608ffa621",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "a4b9f38eba0643ca80ee81b6200096fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c854be8fdbf7413c854ea0ebc552c09f",
            "placeholder": "​",
            "style": "IPY_MODEL_7814eb59f914422e974a0f2e051f3a20",
            "value": ""
          }
        },
        "c61310e1a19a4a3aa0445951226b8583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_08f182e28379494b91dc5ceb58147736",
            "style": "IPY_MODEL_76a0ac00684e4da08f9d621271be3d73",
            "value": true
          }
        },
        "79be5252f8fa40bea365d2f1dcc0f66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_64bb59c6f18c434795981f0a1be06113",
            "style": "IPY_MODEL_cc74a5d835e54d5b90c0214245eb45ca",
            "tooltip": ""
          }
        },
        "0703f2c9a55b41aca8c8bf5563a8782a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc57280ca6d4524adc17d354991862f",
            "placeholder": "​",
            "style": "IPY_MODEL_c450ad6f522e4440b1b1ff09a8f93702",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "29ca8dea1d63478f99f256b572d8b3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "1ce8cac112ee4ac79ef31e3fe6f9ad55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0425bdfe66a4456a307093608ffa621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c854be8fdbf7413c854ea0ebc552c09f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7814eb59f914422e974a0f2e051f3a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08f182e28379494b91dc5ceb58147736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a0ac00684e4da08f9d621271be3d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64bb59c6f18c434795981f0a1be06113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc74a5d835e54d5b90c0214245eb45ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2cc57280ca6d4524adc17d354991862f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c450ad6f522e4440b1b1ff09a8f93702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97d286db544b458aaa28f755edaf0868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c1d04d13ce0424a8cd5a6a3a3a5ba26",
            "placeholder": "​",
            "style": "IPY_MODEL_f3f3e3ca4d6a4e858ecfaf5aa6e61703",
            "value": "Connecting..."
          }
        },
        "9c1d04d13ce0424a8cd5a6a3a3a5ba26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f3e3ca4d6a4e858ecfaf5aa6e61703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8506762658714888b29fdbea67d6a224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_196bb75d83224f7cb7ebe3d019b6b938",
            "placeholder": "​",
            "style": "IPY_MODEL_443b366c8fe34b98af83dbe99a94b165",
            "value": "Token is valid (permission: write)."
          }
        },
        "1d043460adb840098744f3df8d09d90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3b3ba27c88746bcbd5999828b6dd38c",
            "placeholder": "​",
            "style": "IPY_MODEL_7f46fc6e8f5548638cd1ff3b8f73fd5c",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "01d819b8f45f4c40bf8bbf8a483b5d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28955f7e28e8401b82abb617b0ae312e",
            "placeholder": "​",
            "style": "IPY_MODEL_7487ef2396884ae2b1b9153eb9e7cb67",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "05a172bc5c394827845392e69c758ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aeaf6457b174988befa7b1155fd6681",
            "placeholder": "​",
            "style": "IPY_MODEL_5f67c00dc95d40dc81cbe598f35d5966",
            "value": "Login successful"
          }
        },
        "196bb75d83224f7cb7ebe3d019b6b938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443b366c8fe34b98af83dbe99a94b165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b3ba27c88746bcbd5999828b6dd38c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f46fc6e8f5548638cd1ff3b8f73fd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28955f7e28e8401b82abb617b0ae312e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7487ef2396884ae2b1b9153eb9e7cb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aeaf6457b174988befa7b1155fd6681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f67c00dc95d40dc81cbe598f35d5966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}